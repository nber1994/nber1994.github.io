<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sysDesign on jingtianyou&#39;s blog</title>
    <link>http://nber1994.github.io/tags/sysdesign/</link>
    <description>Recent content in sysDesign on jingtianyou&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 09 Aug 2019 00:00:00 +0000</lastBuildDate><atom:link href="http://nber1994.github.io/tags/sysdesign/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>sysDesign-分布式事务</title>
      <link>http://nber1994.github.io/posts/sysdesign-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/sysdesign-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</guid>
      <description>sysDesign-分布式事务 分布式事务-掘金 分布式事务的解决方案有很多种， 一致性从强到弱，性能开销从从多到少：三阶段，二阶段，TCC，saga 一致性保障的基本思路，协调者掌握多个子流程的执行过程信息，协调者负责根据子流程执行信息作出决策
分布式事务产生的原因  不同的service节点  一个事务流程需要调用不同的服务执行不同的子任务   不同的resource节点  一个事务会调用不同的数据来源，例如mysql的分库操作    分布式事务的原则 CAP原则  CAP的解释  C 一致性原则，此处值得是读取到的数据都是事务完成之后和事务完成之前的数据，对于数据事务的中间状态时不可见的 A 可用性，非故障节点在合理的合理的时间内返回合理的响应 P 分区容错性，当出现网络分区后，仍能继续工作。例如某个节点故障了之后，集群仍能继续工作   对于CAP原则，P是大前提，因此CAP解释成，当P发生时，A和C只能选一个，假设节点1和节点2正好处于网络分区的两侧，例如节点1网络正常，而节点2网络故障。这时，一个事务请求到达集群，节点2一定是不能正常处理的，节点1对于该事务请求  如果节点1也对该事务不执行，这保证了C，但是违背了A 如果节点1对该事务执行，这保证了A，但是违背了C    BASE原则  BASE指的是，基本可用，软状态和最终一致性，是对AP的一种扩展 BASE允许存在中间状态，牺牲了一致性而保证了可用性，但是必须是强一致的状态  解决方案 2PC 两阶段提交协议  存在一个协调者，多个参与者 步骤：  第一阶段：  协调者想参与者发出投票，等待各个参与者的响应 各个参与者执行事务，并写入redo log和undo log（此时资源还未释放） 参与者响应协调者发起的投票，若事务执行成功，则响应同意，若执行失败，则响应终止   第二阶段  当所有的参与者都同意时，  协调者向参与者发送正式提交的请求 参与者收到后，完成事务的提交，并释放占用的资源 向协调者发送完成响应 协调者收到所有完成响应后，完成事务   当存在终止响应时，  协调者向参与者发出回滚请求 参与者利用undo log将事务回滚，并释放资源 参与者向协调者发送回滚完成 协调者等待所有的回滚完成后，结束事务       会存在很多的问题  所有参与者对资源的占用都是阻塞的 协调者要对参与者设定超时机制 太依赖协调者，一旦宕机，会导致整个事务阻塞    3PC 三阶段提交协议  引入超时机制，同时将准备阶段一分为二 步骤  canCommit  协调者向参与者发送canCommit请求，并等待响应 参与者接收到请求后，如果认为自己可以执行，则返回YES，否则NO   preCommit  如果参与者响应都是YES  向参与者发送preCommit请求 参与者进行事务的执行，并进行redo log，undo log的落地 如果成功执行了指令，则返回ack响应，同时开始等待最终指令   如果存在一个NO，或者存在超时  向参与者发送中断请求 参与者接收到了abort请求之后，或则超时未收到协调者的请求，会将事务中断     doCommit  若接收到了所有参与者的ack之后，  向所有的参与者发送doCommit请求 参与者接收到了请求后，执行事务并释放资源，发送ack给协调者 协调者接收到所有的ack之后，完成事务   若未收到所有的ack或者存在超时响应  向所有的参与者发送abort请求 参与者收到后根据之前的undo log进行回滚操作，并释放所有资源 想协调者发送ack响应 协调者收到ack后，终止事务        TCC模型 （两阶段型，补偿型）  TCC为Try Confirm Cancel  Try尝试待执行的业务  并未执行业务，只进行一致性检查，但是预留资源   Confirm执行业务  直接执行，使用第一步预留的资源   Cancel取消执行的业务  如果业务失败，则进行资源的回滚，释放占用资源     TCC必须基于本地事务 必须提供幂等性保障  会存在一些超时重试补偿机制    saga模型  每个Saga由一系列sub-transaction Ti 组成 每个Ti 都有对应的补偿动作Ci，补偿动作用于撤销Ti造成的结果,这里的每个T，都是一个本地事务。 可以看到，和TCC相比，Saga没有“预留 try”动作，它的Ti就是直接提交到库。 Saga的执行顺序有两种：  T1, T2, T3, &amp;hellip;, Tn T1, T2, &amp;hellip;, Tj, Cj,&amp;hellip;, C2, C1，其中0 &amp;lt; j &amp;lt; n   Saga定义了两种恢复策略：  向后恢复，即上面提到的第二种执行顺序，其中j是发生错误的sub-transaction，这种做法的效果是撤销掉之前所有成功的sub-transation，使得整个Saga的执行结果撤销。 向前恢复，适用于必须要成功的场景，执行顺序是类似于这样的：T1, T2, &amp;hellip;, Tj(失败), Tj(重试),&amp;hellip;, Tn，其中j是发生错误的sub-transaction。该情况下不需要Ci。   这里要注意的是，在saga模式中不能保证隔离性，因为没有锁住资源，其他事务依然可以覆盖或者影响当前事务。   还是拿100元买一瓶水的例子来说，这里定义 T1=扣100元 T2=给用户加一瓶水 T3=减库存一瓶水 C1=加100元 C2=给用户减一瓶水 C3=给库存加一瓶水 我们一次进行T1,T2，T3如果发生问题，就执行发生问题的C操作的反向。 上面说到的隔离性的问题会出现在，如果执行到T3这个时候需要执行回滚，但是这个用户已经把水喝了(另外一个事务)，回滚的时候就会发现，无法给用户减一瓶水了。这就是事务之间没有隔离性的问题</description>
    </item>
    
    <item>
      <title>sysDesign-分布式锁</title>
      <link>http://nber1994.github.io/posts/sysdesign-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/sysdesign-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</guid>
      <description>sysDesign-分布式锁 分布式锁的一些原则  互斥性 最基本的 可重入性 同一个节点对于同一资源可以多次获取 锁超时 避免死锁  常见实现方式  mysql redis  mysql实现 CREATE TABLE `resourceLock` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `resource_name` varchar(128) NOT NULL DEFAULT &amp;#39;&amp;#39; COMMENT &amp;#39;资源名字&amp;#39;, `node_info` varchar(128) DEFAULT NULL COMMENT &amp;#39;节点信息&amp;#39;, `count` int(11) NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;锁的次数 （可重入）&amp;#39;, `desc` varchar(128) DEFAULT NULL COMMENT &amp;#39;资源描述&amp;#39;, `mtime` timestamp NULL DEFAULT NULL, `ctime` timestamp NULL DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `uniq_resource` (`resource_name`) ) ENGINE=InnoDB DEFAULT CAHRSET=utf8mb4; 加锁 查询xxx资源是否是当前节点所有，如果有的话则增加count</description>
    </item>
    
    <item>
      <title>sysDesign-短连接</title>
      <link>http://nber1994.github.io/posts/sysdesign-%E7%9F%AD%E8%BF%9E%E6%8E%A5/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/sysdesign-%E7%9F%AD%E8%BF%9E%E6%8E%A5/</guid>
      <description>sysDesign-短连接 要求  尽可能的短  方案 短网址的长度  我们可以用英文字母和数字来组合，一共有62种，所以长度为n的短网址的个数为62^n 我们选用7 远远大于互联网的所有连接的总和 我们选用长度为7的连接，由大小写字母和数字组成  一对一还是一对多映射 原网址对应多个短网址，一个短网址的记录会包含诸如访问用户，http的user-agent信息等
以供后续做大数据分析，挖掘数据的价值
如何计算短网址 假设我们的短网址服务是一个7长度的，我们如何计算得到这个短网址呢？
最容易想到的就是使用一个64位整数来通过62位进制的转换来获取，怎么生成这个整数，则就需要用到发号器
怎么存储 存储可以使用mysql和redis都可
跳转301或者302 301永久重定向，短网址会永久重定向到原网址，这对于搜索引擎来说会直接展示原网址
所以使用302临时重定向
预防攻击  hacker短时间内向tinyUrl服务发送请求，会迅速消耗光url  每个ip限制单日请求数量，每个ip每天分配的短url有上限   hacker使用大量肉鸡来进行攻击  redis作为缓存，存储长连接与ID的关系，使用LRU来维护，遇到相同的url直接返回id    参考  短url-知乎 tinyUrl  </description>
    </item>
    
    <item>
      <title>sysDesign-缓存和DB的数据一致性</title>
      <link>http://nber1994.github.io/posts/sysdesign-%E7%BC%93%E5%AD%98%E5%92%8Cdb%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/sysdesign-%E7%BC%93%E5%AD%98%E5%92%8Cdb%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7/</guid>
      <description>sysDesign-缓存和DB的数据一致性  这个问题给我印象很深
 引用  缓存和DB一致性  </description>
    </item>
    
    <item>
      <title>sysDesign-缓存的常见问题</title>
      <link>http://nber1994.github.io/posts/sysdesign-%E7%BC%93%E5%AD%98%E7%9A%84%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/sysdesign-%E7%BC%93%E5%AD%98%E7%9A%84%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</guid>
      <description>sysDesign-缓存的常见问题  缓存常见的问题  缓存穿透 缓存雪崩 缓存击穿（热点key）    缓存穿透 现象 缓存穿透问题是指，请求了一个一定不会请求到的数据，这个时候，一定会穿透缓存到达DB，如果量十分大的话，会对DB性能造成影响（攻击）
解决  使用布隆过滤器，添加入所有的可能查询，对请求进行过滤，如果不存在的直接过滤 空值缓存，对于拿到为空的请求，加入缓存设置空值，并给与很短的失效时间，因为可能这个值不一定是攻击，故不必存储太久  缓存雪崩 现象 缓存在同一时间大量失效，DB可能在突增的压力下崩溃
解决  使用互斥锁来保证只有单个线程可以对DB进行请求，该方法会降低QPS 种缓存时将超时时间错开，可以随机加一个秒数  缓存击穿（热点key） 现象 对于一些热点key，在他失效的那一段时间内，会有大量的请求走DB，对DB造成很大的压力
解决方案  二级缓存，不同等级的缓存设置不同的失效时间 互斥锁，限制只有一个线程对DB进行请求 永不过期，后台异步线程去定时的刷新缓存  </description>
    </item>
    
    <item>
      <title>sysDesign-缓存管理策略</title>
      <link>http://nber1994.github.io/posts/sysdesign-%E7%BC%93%E5%AD%98%E7%AE%A1%E7%90%86%E7%AD%96%E7%95%A5/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/sysdesign-%E7%BC%93%E5%AD%98%E7%AE%A1%E7%90%86%E7%AD%96%E7%95%A5/</guid>
      <description>sysDesign-缓存管理策略 常见的缓存管理策略 LRU算法  最近最少使用算法，一般使用一个链表，最新访问的数据会移动至首部，当链表到达容量时淘汰尾部的节点     LRU-K  相对于LRU，多了一个记录访问次数的链表，这个链表里记录的是每个key对应的访问次数，当访问次数达到k时，才会到达LRU链表中 这个设计保证了偶然的数据访问造成命中率降低，如果某个数据到达尾部即将被淘汰，此时有一个请求，使之到达首部，但是后续可能再没有访问      实施流程  当有访问来时，左边链表会记录每个key被访问的次数，并且按照FIFO淘汰 当某个值访问次数达到了K，会将该key移动到右边的LRU队列 当右边的某个key被访问后，移动至队列首部 当队列满后，淘汰对尾的key    LFU  最近最长使用，使用的频率越高，越排在队列前面，当队列满了之后淘汰对尾元素      步骤  新数据进入队列，引用计数为1，重新排列队列 如果相同的引用计数，则按照时间排序 整体按照引用计数排序    </description>
    </item>
    
    <item>
      <title>sysDesign-进程平滑重启</title>
      <link>http://nber1994.github.io/posts/sysdesign-%E8%BF%9B%E7%A8%8B%E5%B9%B3%E6%BB%91%E9%87%8D%E5%90%AF/</link>
      <pubDate>Fri, 31 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/sysdesign-%E8%BF%9B%E7%A8%8B%E5%B9%B3%E6%BB%91%E9%87%8D%E5%90%AF/</guid>
      <description>sysDesign-进程平滑重启 </description>
    </item>
    
    <item>
      <title>sysDesign-布隆过滤器</title>
      <link>http://nber1994.github.io/posts/sysdesign-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/sysdesign-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/</guid>
      <description>sysDesign-布隆过滤器 布隆过滤器(Bloom Filter)的原理和实现 什么情况下需要布隆过滤器？   先来看几个比较常见的例子
  字处理软件中，需要检查一个英语单词是否拼写正确
  在 FBI，一个嫌疑人的名字是否已经在嫌疑名单上
  在网络爬虫里，一个网址是否被访问过
  yahoo, gmail等邮箱垃圾邮件过滤功能 这几个例子有一个共同的特点： 如何判断一个元素是否存在一个集合中？
  常规思路 数组
链表
树、平衡二叉树、Trie
Map (红黑树)
哈希表
虽然上面描述的这几种数据结构配合常见的排序、二分搜索可以快速高效的处理绝大部分判断元素是否存在集合中的需求。
但是当集合里面的元素数量足够大，如果有500万条记录甚至1亿条记录呢？这个时候常规的数据结构的问题就凸显出来了。
数组、链表、树等数据结构会存储元素的内容，一旦数据量过大，消耗的内存也会呈现线性增长，最终达到瓶颈。
有的同学可能会问，哈希表不是效率很高吗？查询效率可以达到O(1)。但是哈希表需要消耗的内存依然很高。
使用哈希表存储一亿 个垃圾 email 地址的消耗？哈希表的做法：首先，哈希函数将一个email地址映射成8字节信息指纹；考虑到哈希表存储效率通常小于50%（哈希冲突）；因此消耗的内存：8 * 2 * 1亿 字节 = 1.6G 内存，普通计算机是无法提供如此大的内存。
这个时候，布隆过滤器（Bloom Filter）就应运而生。在继续介绍布隆过滤器的原理时，先讲解下关于哈希函数的预备知识。
哈希函数 哈希函数的概念是：将任意大小的数据转换成特定大小的数据的函数，转换后的数据称为哈希值或哈希编码。下面是一幅示意图：
  可以明显的看到，原始数据经过哈希函数的映射后称为了一个个的哈希编码，数据得到压缩。哈希函数是实现哈希表和布隆过滤器的基础。
布隆过滤器介绍  巴顿.布隆于一九七零年提出 一个很长的二进制向量 （位数组） 一系列随机函数 (哈希) 空间效率和查询效率高 有一定的误判率（哈希表是精确匹配）  布隆过滤器原理  布隆过滤器（Bloom Filter）的核心实现是一个超大的位数组和几个哈希函数。假设位数组的长度为m，哈希函数的个数为k
    以上图为例，具体的操作流程：</description>
    </item>
    
    <item>
      <title>sysDesign-秒杀系统</title>
      <link>http://nber1994.github.io/posts/sysdesign-%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/sysdesign-%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/</guid>
      <description>sysDesign-秒杀系统  秒杀系统主要解决两个问题，一个是并发写，一个是并发读 首先需要和常规的电商系统隔离，避免影响正常的业务流程 同时还需要注意系统的高性能，高扩展，高可用，以及数据一致性（减库存）  秒杀架构的原则  请求数据要尽量少 请求数要尽量少 路径要尽量短 依赖要尽量少 不要存在单点  实现 实现动静分离  所谓动态数据就是指页面输出数据是否和url，浏览者，时间地域等有关系 静态数据是指不变的数据， 静态数据直接上CDN，请求不到后端服务  削峰  排队  队列来承接流量的冲击，但是达到队列的处理瓶颈后，会有请求丢失   答题  防刷 分散请求   分层过滤  从每一层都拦截或者丢弃（当处理能力达到瓶颈时）一部分的流量来进行请求的削峰    减库存  下单减库存  很多下单后没有付款，导致其他人不能正常购买   付款减库存  下单数多于库存，导致一些付款无法成功   预扣库存 例如库存预留十分钟时间，当真实付款时检查是否过期，如果过期则就去减库存，如果没有库存则付款失败  同样会存在作弊行为    </description>
    </item>
    
    <item>
      <title>sysDesign-分库分表分区</title>
      <link>http://nber1994.github.io/posts/sysdesign-%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%88%86%E5%8C%BA/</link>
      <pubDate>Wed, 09 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/sysdesign-%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%88%86%E5%8C%BA/</guid>
      <description>sysDesign-分库分表分区 要求 mysql数据库在什么情况下需要进行分库分表分区
基础概念  分表 能够解决单表数据量过大带来的查询效率下降的问题 分库 面对高并发的读写访问，master无法应对写操作的压力时，需要分库来提高数据库的并发访问能力  分库分表场景  单表数据达到千万 数据库面临高并发访问  实现策略 对关键字取模，实现对数据访问路由
分库  按照功能分  比如用户，订单等   按照地区分  北京，上海   带来的问题  跨库join问题  全局表 数据冗余 应用层组装      分表 水平分表  解决的问题  单表过大的问题   方法 一般都是按照某个字段hash取模  按照某个字段分  比如status状态1 2 3，分到三个不同的表中   按照日期分表    垂直分表  解决的问题  实现冷热数据分离 减少数据行大小，避免跨页问题，提高查询性能   方法  把不常用的字段单独放在一张表 打字单单独拆分出来放在附件表中 经常组合查询的在一张表    分区 水平分区 mysql仅仅支持水平分区</description>
    </item>
    
    <item>
      <title>sysDesign-发号器</title>
      <link>http://nber1994.github.io/posts/sysdesign-%E5%8F%91%E5%8F%B7%E5%99%A8/</link>
      <pubDate>Wed, 09 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/sysdesign-%E5%8F%91%E5%8F%B7%E5%99%A8/</guid>
      <description>ID生成器 要求 ID一定要是全局有序的，再者因为有诸如按照时间排序的场景，所以要求按照时间有序。同时要求尽可能的短
 按照时间粗略有序 尽可能短  方案 1.使用数据库的auto_increment生成全局递增ID 优点：
 简单 能够全局唯一 时间严格递增 缺点： 可用性难以保持，主库挂了就挂了 扩展性差，主库写性能为上限，难以扩展  2.数据库集群 一共有n个节点，每个节点设置不同的auto_increment初始值，已经相同的增长步长
 优点：  具有较高的可用性和扩展性   缺点：  并不是根据时间严格递增    3.uuid 数据库生成ID方法，都需要有远程调用。uuid的方法是在本地生成唯一ID
 4个字节标识unix timestamp 3个字节标识机器ID 2个字节标识进程ID 3个字节标识计数器 优点：  高性能，生成很快，不会重复   缺点：  较长，查询效率较低 同时不失严格的按照时间有序    4.snowflake 核心思想：一个long的ID，41bit作为毫秒数，10bit作为机器编号，12bit作为毫秒内序列号 理论上每秒能生成：1000*2^12个大约400w的ID
 实现自己的分布式算法  单机并发量 多少个机房 每个机房机器数量 几个业务线 需要几年     假设一个64bit的int值，如果系统预计运行10年，至少需要10365246060*1000来算出大致需要多少位 单机的峰值10w，也就是每毫秒大概是100，则需要预留7bit给毫秒内序列号 机房和机器数也按照该规则      优点：  ID唯一 毫秒在高位，时间递增    参考  沈剑-发号器  </description>
    </item>
    
  </channel>
</rss>
