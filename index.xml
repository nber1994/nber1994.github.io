<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>jingtianyou&#39;s blog</title>
    <link>http://nber1994.github.io/</link>
    <description>Recent content on jingtianyou&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 15 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="http://nber1994.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>golang同步机制的实现</title>
      <link>http://nber1994.github.io/posts/golang%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Sat, 15 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/golang%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/</guid>
      <description>原文转载至：https://ga0.github.io/golang/2015/10/11/golang-sync.html
 Golang的提供的同步机制有sync模块下的Mutex、WaitGroup以及语言自身提供的chan等。 这些同步的方法都是以runtime中实现的底层同步机制（cas、atomic、spinlock、sem）为基础的， 本文主要探讨Golang底层的同步机制如何实现。
1 cas、atomic cas(Compare And Swap)和原子运算是其他同步机制的基础， 在runtime/asm_xxx.s(xxx代表系统架构，比如amd64)中实现。amd64架构的系统中， 主要通过两条汇编语句来实现，一个是LOCK、一个是CMPXCHG。
LOCK是一个指令前缀，其后必须跟一条“读-改-写”的指令，比如INC、XCHG、CMPXCHG等。 这条指令对CPU缓存的访问将是排他的。
CMPXCHG是完成CAS动作的指令。 把LOCK和CMPXCHG一起使用，就达到了原子CAS的功能。
atomic操作也是通过LOCK和其他算术操作（XADD、ORB等）组合来实现。
2 自旋锁 Golang中的自旋锁用来实现其他类型的锁，自旋锁的作用和互斥量类似，不同点在于， 它不是通过休眠来使进程阻塞，而是在获得锁之前一直处于忙等状态（自旋），从而避免了进程（或者
和自旋锁相关的函数有sync_runtime_canSpin和sync_runtime_doSpin， 前者用来判断当前是否可以进行自旋，后者执行自旋操作。二者通常一起使用。
sync_runtime_canSpin函数中在以下四种情况返回false
 已经执行了很多次 是单核CPU 没有其他正在运行的P 当前P的G队列不为空  条件1避免长时间自旋浪费CPU的情况。
条件2、3用来保证除了当前在运行的Goroutine之外，还有其他Goroutine在运行。
条件4是避免自旋锁等待的条件是由当前P的其他G来触发，这样会导致 在自旋变得没有意义，因为条件永远无法触发。
sync_runtime_doSpin会调用procyield函数，该函数也是汇编语言实现。 函数内部循环调用PAUSE指令。PAUSE指令什么都不做，但是会消耗CPU时间，在执行PAUSE指令时， CPU不会对他做不必要的优化。
3 信号量 按照runtime/sema.go中的注释：
Think of them as a way to implement sleep and wakeup Golang中的sema，提供了休眠和唤醒Goroutine的功能。
semacquire函数首先检查信号量是否为0：如果大于0，让信号量减一，返回； 如果等于0，就调用goparkunlock函数，把当前Goroutine放入该sema的等待队列，并把他设为等待状态。
semrelease函数首先让信号量加一，然后检查是否有正在等待的Goroutine： 如果没有，直接返回；如果有，调用goready函数唤醒一个Goroutine。
4 sync/Mutex Mutex拥有Lock、Unlock两个方法，主要的实现思想都体现在Lock函数中。
Lock执行时，分三种情况：
 无冲突 通过CAS操作把当前状态设置为加锁状态； 有冲突 开始自旋，并等待锁释放，如果其他Goroutine在这段时间内释放了该锁， 直接获得该锁；如果没有释放，进入3； 有冲突，且已经过了自旋阶段 通过调用semacquire函数来让当前Goroutine进入等待状态。  无冲突时是最简单的情况；有冲突时，首先进行自旋，是从效率方面考虑的， 因为大多数的Mutex保护的代码段都很短，经过短暂的自旋就可以获得；如果自旋等待无果，就只好通过信号量来让当前 Goroutine进入等待了。</description>
    </item>
    
    <item>
      <title>go-scheduler 上</title>
      <link>http://nber1994.github.io/posts/scheduler-%E4%B8%8A/</link>
      <pubDate>Thu, 25 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/scheduler-%E4%B8%8A/</guid>
      <description>写在开头：
本文仅科普性质分享，旨在为大家构建一个go scheduler发展大纲性的印象，会丢失很多代码以及设计细节，对于这方面的内容还需要读者自己去深挖代码补充完整:P
 一、计算机发展简史 1. 远古时代  一切要从1946年说起，当世界第一台计算机问世时，世界拥有了第一台计算机。（废话文学）
 当时的埃尼阿克(eniac)是为了计算炮弹轨迹而发明的，将你要计算的程序打到纸带上，接通电源，等待执行结果。期间不能暂停，也不能做其他任何事情。它上面没有操作系统，更别提进程、线程和协程了。
2. 单进程时代 后来，现代化的计算机有了操作系统，操作系统上可以安装多个应用，每个应用程序都包装为一个进程。它主要包括两部分：
 私有数据 指令流  但是，当时的操作系统在一段时间只能运行一个进程，直到这个进程运行完，才能运行下一个进程，这个时期可以称为单进程时代——串行时代。
和ENIAC相比，单进程时代运行速度已有了几万倍的提度，但依然是太慢了，比如进程要读数据阻塞了，CPU就在那里浪费着，程序员们就想了，不能浪费啊，怎么才能充分的利用CPU呢？ 如果在cpu等待时，切换到另外的进程进行执行，CPU的效率就提高上来了。
3. 多进程时代  从这个节点开始，人类在追求高并发的道路上一去不复返了
 后来操作系统就具有了最早的并发能力：多进程并发，当一个进程阻塞的时候，切换到另外等待执行的进程，这样就能尽量把CPU利用起来，CPU就不浪费了。
给用户造成的假象就是，A B C三个进程同时在运行着。然而，为了实现这个目标，操作系统变得格外的复杂。
实现多进程并发首先我们需要保障的有两点：
 实现进程间数据完全隔离 实现进程间指令流的安全切换  具体如何实现的呢：
3.1 虚拟内存 操作系统引入了虚拟内存，来做到进程间数据的隔离。
进程启动时，操作系统会为进程分配一块虚拟内存空间，每个进程拿到的 虚拟内存空间布局是相同的，且大小等于机器实际物理内存大小，但是实际上这块连续的内存空间对应机器内存中是一块块的内存碎片，这个假象是由虚拟内存技术实现的。
进程需要访问某个地址时，例如0x004005，都会先去查询页表，定位到对应的PTE（页表项），PTE记录着对应的真实的物理内存地址，继而再对这个真实地址进行访问。
每个进程都会有相同的页表，且内存结构也相同，对于每个进程来说都认为自己占用了机器全部的内存，操作系统在做虚拟内存映射时保证一个物理地址只会分配给一个进程（共享内存区域 &amp;amp; 内核区域除外），这样就保证了进程间的内存数据是隔离的。
3.2 进程内存结构 32位机器：
从低位向高位看：
 代码段总是从地址0x400000开始的，存储着用户程序的代码，字面量等 然后是数据段，存储用户程序的一些宏，全局变量，代码等 之后是堆，程序运行过程中产生的变量等都会存放在堆中，且堆空间向高位地址延伸 在用户栈和堆之间存在一块为共享库分配的内存空间，这里存储着例如.so动态链接文件等 再之后是用户栈，函数调用的入参，临时变量，以及调用信息等存放于此 内存最高位则是内核内存空间，用户栈是从2^48-1处开始向下延伸的，这段空间固定映射到一部分连续的物理地址上  所以，每个进程的程序指令流都会存在该进程的内存空间中，保证了进程的指令流完全隔离
可以看到，当前进程的指令流是存在于本进程的内存中，所以，在切换进程之前，我们把当前运行到的pc位置做保存现场，再次切换到本进程时继续已之前的pc处开始执行即可。
3.3 进程控制块 PCB 内核为每个进程维护了一个pcb的结构，主要用于记录进程状态，在Linux中，PCB结构为task_struct；
task_struct是Linux内核的一种数据结构，它会被装载到RAM里并且包含进程的信息，每个进程都把它的信息放在task_struct这个数据结构里。那么这个结构体里存了哪些数据呢：
1.进程状态：是调度和兑换的依据
   linux进程的状态      内核表示 含义   TASK_RUNNING 可运行   TASK_INTERRUPTIBLE 可中断的等待状态   TASK_UNINTERRUPTIBLE 不可中断的等待状态   TASK_ZOMBIE 僵死   TASK_STOPPED 暂停   TASK_SWAPPING 换入/换出    2.</description>
    </item>
    
    <item>
      <title>go-scheduler 下</title>
      <link>http://nber1994.github.io/posts/scheduler-%E4%B8%8B/</link>
      <pubDate>Thu, 25 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/scheduler-%E4%B8%8B/</guid>
      <description>三、调度器 Scheduler 3. 任务窃取调度器 · 1.1 2012 年 Google 的工程师 Dmitry Vyukov 在 Scalable Go Scheduler Design Doc 中指出了现有多线程调度器的问题，并且针对出现的问题，针对性的进行了改进设计。
我们来回顾下GM模型带来的问题：
 mcache泛滥 资源竞争严重 Goroutine传递问题 频繁的线程阻塞/解阻塞  下面我们分开来看，为了解决各个问题，分别引入了哪些设计
1. mcache泛滥 - 引入中间层P 在Goroutine和线程之间引入了中间层P，其数量对应于机器的核数，且只有P持有mcache，并且P托管了M运行所需的上下文。每个M都需要绑定到P上才能够获得G。
这样一来，每个M做到了减重，M变成了一个很干净的系统线程封装。减少了很多冗余的mcache。
type p struct { lock mutex id int32 // p的状态  status uint32 // one of pidle/prunning/...  // 下一个p的地址，可参考 g.schedlink  link puintptr // p所关联的m  m muintptr // back-link to associated m (nil if idle)  // 内存分配的时候用的，p所属的m的mcache用的也是这个  mcache *mcache // Cache of goroutine ids, amortizes accesses to runtime·sched.</description>
    </item>
    
    <item>
      <title>如何获取php引用的所有脚本</title>
      <link>http://nber1994.github.io/posts/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96php%E5%BC%95%E7%94%A8%E7%9A%84%E6%89%80%E6%9C%89%E8%84%9A%E6%9C%AC/</link>
      <pubDate>Tue, 24 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96php%E5%BC%95%E7%94%A8%E7%9A%84%E6%89%80%E6%9C%89%E8%84%9A%E6%9C%AC/</guid>
      <description>获取所有的引入文件，一般这句放在controller的结束位置
$included_files = get_included_files(); file_put_contents(&#39;/tmp/xxx&#39;,implode(&amp;quot;\r\n&amp;quot;, $included_files)); </description>
    </item>
    
    <item>
      <title>channel &amp; selelct</title>
      <link>http://nber1994.github.io/posts/channel-select/</link>
      <pubDate>Mon, 23 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/channel-select/</guid>
      <description>并发编程模型 并发编程的意义，这个不需要多说了，大流量，高并发全靠它，性能上来了，稳定性也就不言而喻了
并发的两个基础部分：
 并发调度单位，concurrency unit 并发模型，concurrency model  Concurrency unit 并发调度单位讲究 轻！快！
unit占用轻！unit切换快！
进程作为Unit 进程拥有独占的内存和指令流，是一个应用的包装，但是进程作为并发基本单元有如下问题：
 资源占用过大  每个进程占用的内存太大了，进程携带了自己的虚拟内存页表，文件描述符等   不能发挥多核的性能  进程不能很好的发挥多核机器的性能，常常出现一个核跑，多个核看的现象     进程切换消耗过大  进程切换需要进行系统调用，涉及到内存从用户态拷贝至内核态 保存当前进程的现场，并且恢复下一个进程    线程作为Unit 线程较轻量级，一个进程可以包含多个线程，则每个最小并发粒度的资源占用要小很多，且同一个进程内线程间切换只需要对指令流进行切换即可。
但是，进程间切换仍需要进入内核进行，仍然存在大量的并发切换消耗
协程作为Unit 协程，也叫做用户态线程，它规避了最后一个问题，切换消耗过大的问题，无需通过系统调用进入内核进行切换，协程所有的生命周期均发生在用户态。
因为协程的优点，协程类编程也开始越来越火了。比较有代表性的有Go的goroutine、Erlang的Erlang进程、Scala的actor、windows下的fibre（纤程）等，一些动态语言像Python、Ruby、Lua也慢慢支持协程。
但是 语言引入协程作为并发调度单位，需要实现自己的协程调度器、并提供协程间通信的方式等一系列支持模块，相较于传统的基于进程线程的并发方式，需要实现很多额外的功能组件。实现较复杂。
Concurrency model 总体来看，目前能找到的最轻量的调度单元就是协程了，虽然实现起来有些麻烦，但是现代语言也越来越多的引入协程了。
那么解决了并发单元的问题后，我们再研究下并发模型，为什么需要并发模型呢，因为并发就意味着竞争：对内存的竞争，对算力的竞争等，那么如何降低竞争带来的性能损耗，就需要并发模型的设计了。简单来说，并发模型就是指导并发单元以何种方式处理竞争，尽量减少竞争带来的性能损耗。简单来说，就是定义了并发单元间的通信方式。
共享内存+锁 最经典的模型，通过锁来保护资源，多个并发单元访问资源前首先争夺锁，然后再去访问资源。没抢到锁的unit则阻塞等待。
这个应该是目前最常用的了，也最符合直觉，但是可以明显看到，在竞争时会产生阻塞耗时。
这就是常说的使用共享内存来进行通信
函数式编程 既然基于共享内存通信会产生大量的竞争，那么函数式编程的通信思想是，在并发单元执行过程中不进行通信，只在最后大家都执行完后统一对结果做收集和汇总
函数式编程的特性：
 不可变数据，默认是变量是不可变的，如果你要改变变量，你需要把变量copy出去 函数对于Input A一定会返回Output B，即函数内部没有状态，不会对全局变量进行修改，运行时涉及的变量都是局部变量 这么一来，每个函数对输入负责，只会访问局部变量，全局不存在资源竞争  基于函数式编程模型作为并发模型的话，性能会很高，但是会产生额外的大量的局部变量
代表语言：clojure
举个例子： s3e在设计之初，提供了一套SDK，目的是帮助业务建模和模型可视化，大体是这样的，将一个业务功能节点抽象为了workflow，workflow中的每个task state对应一个函数，为了降低使用成本，各个函数的签名都是一致的
func Action(ctx context.Context, db *Databus) (*Databus, error) 每个函数都会对Databus做一些自己的修改，这个修改是全局Action可见的（因为Databus传的是指针类型），因此如果存在并发的节点，会存在对全局变量的锁竞争。</description>
    </item>
    
    <item>
      <title>lsp配置相关</title>
      <link>http://nber1994.github.io/posts/lsp%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Mon, 23 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/lsp%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE/</guid>
      <description>set number set relativenumber set nocompatible set showmode set showcmd set encoding=utf-8 set tabstop=4 set shiftwidth=4 set expandtab set softtabstop=4 set wrap set linebreak set showmatch set hlsearch set incsearch set ignorecase set undofile set backupdir=~/.vim/.backup// set directory=~/.vim/.swp// set undodir=~/.vim/.undo// &amp;#34;set autochdir set noerrorbells set history=100 set autoread set wildmenu set wildmode=longest:list,full set cul cabbrev E Explore set laststatus=2 &amp;#34; 总是显示状态栏 highlight StatusLine cterm=bold ctermfg=black ctermbg=red set statusline=%F set autoindent &amp;#34;最大化 function!</description>
    </item>
    
    <item>
      <title>my配色</title>
      <link>http://nber1994.github.io/posts/my%E9%85%8D%E8%89%B2/</link>
      <pubDate>Mon, 23 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/my%E9%85%8D%E8%89%B2/</guid>
      <description>&amp;#34; Vim color file &amp;#34; Maintainer: Hans Fugal &amp;lt;hans@fugal.net&amp;gt; &amp;#34; Last Change: $Date: 2004/06/13 19:30:30 $ &amp;#34; Last Change: $Date: 2004/06/13 19:30:30 $ &amp;#34; URL: http://hans.fugal.net/vim/colors/desert.vim &amp;#34; Version: $Id: desert.vim,v 1.1 2004/06/13 19:30:30 vimboss Exp $ &amp;#34; cool help screens &amp;#34; :he group-name &amp;#34; :he highlight-groups &amp;#34; :he cterm-colors set background=dark if version &amp;gt; 580 &amp;#34; no guarantees for version 5.8 and below, but this makes it stop &amp;#34; complaining hi clear if exists(&amp;#34;syntax_on&amp;#34;) syntax reset endif endif let g:colors_name=&amp;#34;my&amp;#34; hi Normal guifg=White guibg=grey20 &amp;#34; highlight groups hi Cursor guibg=khaki guifg=slategrey &amp;#34;hi CursorIM &amp;#34;hi Directory &amp;#34;hi DiffAdd &amp;#34;hi DiffChange &amp;#34;hi DiffDelete &amp;#34;hi DiffText &amp;#34;hi ErrorMsg hi VertSplit guibg=#c2bfa5 guifg=grey50 gui=none hi Folded guibg=grey30 guifg=gold hi FoldColumn guibg=grey30 guifg=tan hi IncSearch guifg=slategrey guibg=khaki &amp;#34;hi LineNr hi ModeMsg guifg=goldenrod hi MoreMsg guifg=SeaGreen hi NonText guifg=LightBlue guibg=grey30 hi Question guifg=springgreen hi Search guibg=peru guifg=wheat hi SpecialKey guifg=yellowgreen hi StatusLine guibg=#c2bfa5 guifg=black gui=none hi StatusLineNC guibg=#c2bfa5 guifg=grey50 gui=none hi Title guifg=indianred hi Visual gui=none guifg=khaki guibg=olivedrab &amp;#34;hi VisualNOS hi WarningMsg guifg=salmon &amp;#34;hi WildMenu &amp;#34;hi Menu &amp;#34;hi Scrollbar &amp;#34;hi Tooltip &amp;#34; syntax highlighting groups hi Comment guifg=SkyBlue hi Constant guifg=#ffa0a0 hi Identifier guifg=palegreen hi Statement guifg=khaki hi PreProc guifg=indianred hi Type guifg=darkkhaki hi Special guifg=navajowhite &amp;#34;hi Underlined hi Ignore guifg=grey40 &amp;#34;hi Error hi Todo guifg=orangered guibg=yellow2 &amp;#34; color terminal definitions hi SpecialKey ctermfg=cyan hi NonText cterm=bold ctermfg=darkblue hi Directory ctermfg=darkcyan hi ErrorMsg cterm=bold ctermfg=7 ctermbg=1 hi IncSearch cterm=NONE ctermfg=yellow ctermbg=green hi Search cterm=NONE ctermfg=grey ctermbg=yellow hi MoreMsg ctermfg=darkgreen hi ModeMsg cterm=NONE ctermfg=brown hi LineNr ctermfg=3 hi Question ctermfg=green hi StatusLine cterm=bold,reverse hi StatusLineNC cterm=reverse hi VertSplit cterm=reverse hi Title ctermfg=5 hi Visual cterm=reverse hi VisualNOS cterm=bold,underline hi WarningMsg ctermfg=1 hi WildMenu ctermfg=0 ctermbg=3 hi Folded ctermfg=darkgrey ctermbg=NONE hi FoldColumn ctermfg=darkgrey ctermbg=NONE hi DiffAdd ctermbg=4 hi DiffChange ctermbg=5 hi DiffDelete cterm=bold ctermfg=4 ctermbg=6 hi DiffText cterm=bold ctermbg=1 hi Comment ctermfg=brown hi Constant ctermfg=darkcyan hi Special ctermfg=5 hi Identifier ctermfg=1 hi Statement ctermfg=3 hi PreProc ctermfg=5 hi Type ctermfg=2 hi Underlined cterm=underline ctermfg=5 hi Ignore cterm=bold ctermfg=7 hi Ignore ctermfg=darkgrey hi Error cterm=bold ctermfg=7 ctermbg=1 &amp;#34;vim: sw=4 </description>
    </item>
    
    <item>
      <title>整理键盘</title>
      <link>http://nber1994.github.io/posts/%E6%95%B4%E7%90%86%E9%94%AE%E7%9B%98/</link>
      <pubDate>Mon, 23 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E6%95%B4%E7%90%86%E9%94%AE%E7%9B%98/</guid>
      <description>整理下键盘</description>
    </item>
    
    <item>
      <title>IBM_Model_f</title>
      <link>http://nber1994.github.io/posts/ibm_model_f/</link>
      <pubDate>Thu, 09 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/ibm_model_f/</guid>
      <description>pic-IBM_Model_f 新入手IBM Model f键盘 产于1989年</description>
    </item>
    
    <item>
      <title>SilverBullet</title>
      <link>http://nber1994.github.io/posts/silverbullet/</link>
      <pubDate>Thu, 09 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/silverbullet/</guid>
      <description>mysql  讲一讲myisam和innodb的区别  锁 事务 。。。   讲讲innodb的索引   索引结构 索引
 为什么innodb的索引是用B+树实现  平衡二叉树 叶子节点相连，范围 。。。   B+树的什么性质影响着查询性能  层高   innodb的辅助索引的叶子节点存储的是什么 为什么这么存储，有什么优劣  主键索引变动对索引的影响小 但是查询速度会编码，引入自适应hash索引   索引的最左前缀匹配原则 abc联合索引，说明什么查询条件能命中索引   事务
 讲一讲innodb的事务 事务隔离级别，分别会出现什么问题  脏读 幻读 不可重复读   innodb默认是哪种隔离级别，如何解决上述问题  mvcc next-key锁   innodb如何解决幻读，如何解决不可重复读 幻读和不可重复读分别对应什么场景  幻读insert 不可重复读update   快照度和当前度，innodb中，事务中的读是快照读，怎么强制读到当前的数据  sql+for update强制读当前   innodb中的锁你了解吗  行 意向 gap next-key   innodb支持哪种锁 为什么会引入next-key锁，为了解决什么问题  幻读   innodb的持久化你知道吗 redo log和undo log分别有什么作用  redo log持久化 undo log快照度，事务回滚   innodb的double-buffer-wirte你知道吗，为什么要引入这个机制 你是怎么优化sql的   sql军规</description>
    </item>
    
    <item>
      <title>go-GMP模型</title>
      <link>http://nber1994.github.io/posts/gmp%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/gmp%E6%A8%A1%E5%9E%8B/</guid>
      <description>上古时代  一切要从1946年说起，当世界第一台计算机问世时，世界拥有了第一台计算机。（废话文学）
 当时的埃尼阿克(eniac)是为了计算炮弹轨迹而发明的，将你要计算的程序打到纸带上，接通电源，等待执行结果。期间不能暂停，也不能做其他任何事情。它上面没有操作系统，更别提进程、线程和协程了。
进程时代 单进程时代 后来，现代化的计算机有了操作系统，每个程序都是一个进程，但是操作系统在一段时间只能运行一个进程，直到这个进程运行完，才能运行下一个进程，这个时期可以成为单进程时代——串行时代。
和ENIAC相比，单进程是有了几万倍的提度，但依然是太慢了，比如进程要读数据阻塞了，CPU就在哪浪费着，伟大的程序员们就想了，不能浪费啊，怎么才能充分的利用CPU呢？
多进程时代 后来操作系统就具有了最早的并发能力：多进程并发，当一个进程阻塞的时候，切换到另外等待执行的进程，这样就能尽量把CPU利用起来，CPU就不浪费了。
线程时代 多进程真实个好东西，有了对进程的调度能力之后，伟大的程序员又发现，进程拥有太多资源，在创建、切换和销毁的时候，都会占用很长的时间，CPU虽然利用起来了，但CPU有很大的一部分都被用来进行进程调度了，怎么才能提高CPU的利用率呢？
大家希望能有一种轻量级的进程，调度不怎么花时间，这样CPU就有更多的时间用在执行任务上。
后来，操作系统支持了线程，线程在进程里面，线程运行所需要资源比进程少多了，跟进程比起来，切换简直是“不算事”。
一个进程可以有多个线程，CPU在执行调度的时候切换的是线程，如果下一个线程也是当前进程的，就只有线程切换，“很快”就能完成，如果下一个线程不是当前的进程，就需要切换进程，这就得费点时间了。
这个时代，CPU的调度切换的是进程和线程。多线程看起来很美好，但实际多线程编程却像一坨屎，一是由于线程的设计本身有点复杂，而是由于需要考虑很多底层细节，比如锁和冲突检测。
进程 &amp;amp; 线程的问题 从一道面试题谈起  进程和线程的分别是什么？
  对于操作系统层面，标准的回答是：进程是资源分配的最小单位，线程是cpu调度的最小单位。
 进程 简而言之，进程是资源分配的最小单位，且是一个应用的实例，为了保证进程间不互相影响，各搞各的，进程间：
 数据完全隔离 指令流完全隔离  具体怎么实现的：
虚拟内存 进程启动时，操作系统会为进程分配一块内存空间，进程的视角看这块内存是连续的，但是实际上在机器内存中是一块块的内存碎片，这个假象是由虚拟内存技术实现的。这么做是为了方便编译链接，内存隔离等。
进程需要访问某个地址时，例如0x004005，都会先去查询页表，定位到对应的PTE（页表项），PTE记录着对应的真实的物理内存地址，继而再对这个真实地址进行访问。
每个进程都会有相同的页表，且内存结构也相同，对于每个进程来说都认为自己占用了机器全部的内存，操作系统使用虚拟内存保证进程间的内存是隔离的。
进程内存地址空间 32位机器：
从低位向高位看：
 代码段总是从地址0x400000开始的，存储着用户程序的代码，字面量等 然后是数据段，存储用户程序的一些宏，全局变量，代码等 之后是堆，程序运行过程中产生的变量等都会存放在堆中，且堆空间向高位地址延伸 在用户栈和堆之间存在一块为共享库分配的内存空间，这里存储着例如.so动态链接文件等 再之后是用户栈，函数调用的入参，临时变量，以及调用信息等存放于此 内存最高位则是内核内存空间，用户栈是从2^48-1处开始向下延伸的，这段空间固定映射到一部分连续的物理地址上  进程控制块 PCB 内核为每个进程维护了一个pcb的结构，主要用于记录进程状态，在Linux中，PCB结构为task_struct；
task_struct是Linux内核的一种数据结构，它会被装载到RAM里并且包含进程的信息，每个进程都把它的信息放在task_struct这个数据结构里。那么这个结构体里存了哪些数据呢：
1.进程状态：是调度和兑换的依据
   linux进程的状态      内核表示 含义   TASK_RUNNING 可运行   TASK_INTERRUPTIBLE 可中断的等待状态   TASK_UNINTERRUPTIBLE 不可中断的等待状态   TASK_ZOMBIE 僵死   TASK_STOPPED 暂停   TASK_SWAPPING 换入/换出    2.</description>
    </item>
    
    <item>
      <title>go-实现一个简单的DSL解释器</title>
      <link>http://nber1994.github.io/posts/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84dsl%E8%A7%A3%E9%87%8A%E5%99%A8/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84dsl%E8%A7%A3%E9%87%8A%E5%99%A8/</guid>
      <description>什么是DSL DSL 是 Domain Specific Language 的缩写，中文翻译为领域特定语言（下简称 DSL）；而与 DSL 相对的就是 GPL，这里的 GPL 并不是我们知道的开源许可证，而是 General Purpose Language 的简称，即通用编程语言，也就是我们非常熟悉的 Objective-C、Java、Python 以及 C 语言等等。
简单说，就是为了解决某一类任务而专门设计的计算机语言。
 Regex SQL HTML&amp;amp;CSS  共同特点 没有计算和执行的概念；
 其本身并不需要直接表示计算； 使用时只需要声明规则、事实以及某些元素之间的层级和关系； 总结起来一句话：表达能力有限，通过在表达能力上做的妥协换取在某一领域内的高效 那么DSL解释器的主要功能是解释执行DSL  设计原则 实现DSL总共需要完成两部分工作：
设计语法和语义，定义 DSL 中的元素是什么样的，元素代表什么意思 实现 parser，对 DSL 解析，最终通过解释器来执行 那么我们可以得到DSL的设计原则：
简单  学习成本低，DSL语法最好和部门主要技术栈语言保持一致（go，php） 语法简单，删减了golang大部分的语法，只支持最基本的  数据格式， 二元运算符， 控制语句 少量的语法糖    嵌入式DSL  DSL需要嵌入到现有的编程语言中，发挥其实时解释执行且部署灵活的特点 使用json类型的context与外部系统进行通信，且提供与context操作相关的语法糖  解释器工作流程 大部分编译器的工作可以被分解为三个主要阶段：解析（Parsing），转化（Transformation）以及 代码生成（Code Generation）
 解析 将源代码转换为一个更抽象的形式。 转换 接受解析产生的抽象形式并且操纵这些抽象形式做任何编译器想让它们做的事。 代码生成 基于转换后的代码表现形式（code representation）生成目标代码。  解析  词法分析 —— tokenizer 通过一个叫做tokenizer（词素生成器，也叫lexer）的工具将源代码分解成一个个词素。（词素是描述编程语言语法的对象。它可以描述数字，标识符，标点符号，运算符等等。） 语法分析 —— parser 接收词素并将它们组合成一个描述了源代码各部分之间关系的中间表达形式：抽象语法树。（抽象语法树是一个深度嵌套的对象，这个对象以一种既能够简单地操作又提供很多关于源代码信息的形式，来展现代码。）  转换  这个过程接收解析生成的抽象语法树并对它做出改动 转换阶段可以改变抽象语法树使代码保持在同一个语言，或者编译成另外一门语言。  代码生成  生成新的代码，一般是二进制或者汇编  aki-DSL解释器设计原理 解析源代码生成AST 那么想要实现一个脚本解释器的话，就需要实现上面的三个步骤，而且我们发现，承上启下的是AST（抽象语法树），它在解释器中十分重要</description>
    </item>
    
    <item>
      <title>utf8特殊符号</title>
      <link>http://nber1994.github.io/posts/utf8%E7%89%B9%E6%AE%8A%E7%AC%A6%E5%8F%B7/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/utf8%E7%89%B9%E6%AE%8A%E7%AC%A6%E5%8F%B7/</guid>
      <description>㏠ ㏡ ㏢ ㏣ ㏤ ㏥ ㏦ ㏧ ㏨ ㏩ ㏪ ㏫ ㏬ ㏭ ㏮ ㏯ ㏰ ㏱ ㏲ ㏳ ㏴ ㏵ ㏶ ㏷ ㏸ ㏹ ㏺ ㏻ ㏼ ㏽ ㏾㍘ ㍙ ㍚ ㍛ ㍜ ㍝ ㍞ ㍟ ㍠ ㍡ ㍢ ㍣ ㍤ ㍥ ㍦ ㍧ ㍨ ㍩ ㍪ ㍫ ㍬ ㍭ ㍮ ㍯ ㍰㋀ ㋁ ㋂ ㋃ ㋄ ㋅ ㋆ ㋇ ㋈ ㋉ ㋊ ㋋㉿ ㊀ ㊁ ㊂ ㊃ ㊄ ㊅ ㊆ ㊇ ㊈ ㊉ ㊊ ㊋ ㊌ ㊍ ㊎ ㊏ ㊐ ㊑ ㊒ ㊓ ㊔ ㊕ ㊖ ㊗ ㊘ ㊙ ㊚ ㊛ ㊜ ㊝ ㊞ ㊟ ㊠ ㊡ ㊢ ㊣ ㊤ ㊥ ㊦ ㊧ ㊨ ㊩ ㊪ ㊫ ㊬ ㊭ ㊮ ㊯ ㊰㈠ ㈡ ㈢ ㈣ ㈤ ㈥ ㈦ ㈧ ㈨ ㈩ ㈪ ㈫ ㈬ ㈭ ㈮ ㈯ ㈰ ㈱ ㈲ ㈳ ㈴ ㈵ ㈶ ㈷ ㈸ ㈹ ㈺ ㈻ ㈼ ㈽ ㈾ ㈿ ㉀ ㉁ ㉂ ㉃㆒ ㆓ ㆔ ㆕ ㆖ ㆗ ㆘ ㆙ ㆚ ㆛ ㆜ ㆝ ㆞ ㆟ ✀ ✁ ✂ ✃ ✄ ✅ ✆ ✇ ✈ ✉ ✊ ✋ ✌ ✍ ✎ ✏ ✐ ✑ ✒ ✓ ✔ ✕ ✖ ✗ ✘ ✙ ✚ ✛ ✜ ✝ ✞ ✟ ✠ ✡ ✢ ✣ ✤ ✥ ✦ ✧ ✨ ✩ ✪ ✫ ✬ ✭ ✮ ✯ ✰ ✱ ✲ ✳ ✴ ✵ ✶ ✷ ✸ ✹ ✺ ✻ ✼ ✽ ✾ ✿ ❀ ❁ ❂ ❃ ❄ ❅ ❆ ❇ ❈ ❉ ❊ ❋ ❌ ❍ ❎ ❏ ❐ ❑ ❒ ❓ ❔ ❕ ❖ ❗ ❘ ❙ ❚ ❛ ❜ ❝ ❞ ❟ ❠ ❡ ❢ ❣ ❤ ❥ ❦ ❧ ❨ ❩ ❪ ❫ ❬ ❭ ❮ ❯ ❰ ❱ ❲ ❳ ❴ ❵ ❶ ❷ ❸ ❹ ❺ ❻ ❼ ❽ ❾ ❿ ➀ ➁ ➂ ➃ ➄ ➅ ➆ ➇ ➈ ➉ ➊ ➋ ➌ ➍ ➎ ➏ ➐ ➑ ➒ ➓ ➔ ➕ ➖ ➗ ➘ ➙ ➚ ➛ ➜ ➝ ➞ ➟ ➠ ➡ ➢ ➣ ➤ ➥ ➦ ➧ ➨ ➩ ➪ ➫ ➬ ➭ ➮ ➯ ➰ ➱ ➲ ➳ ➴ ➵ ➶ ➷ ➸ ➹ ➺ ➻ ➼ ➽ ➾ ➿ ① ② ③ ④ ⑤ ⑥ ⑦ ⑧ ⑨ ⑩ ⑪ ⑫ ⑬ ⑭ ⑮ ⑯ ⑰ ⑱ ⑲ ⑳ ⑴ ⑵ ⑶ ⑷ ⑸ ⑹ ⑺ ⑻ ⑼ ⑽ ⑾ ⑿ ⒀ ⒁ ⒂ ⒃ ⒄ ⒅ ⒆ ⒇ ⒈ ⒉ ⒊ ⒋ ⒌ ⒍ ⒎ ⒏ ⒐ ⒑ ⒒ ⒓ ⒔ ⒕ ⒖ ⒗ ⒘ ⒙ ⒚ ⒛ ⒜ ⒝ ⒞ ⒟ ⒠ ⒡ ⒢ ⒣ ⒤ ⒥ ⒦ ⒧ ⒨ ⒩ ⒪ ⒫ ⒬ ⒭ ⒮ ⒯ ⒰ ⒱ ⒲ ⒳ ⒴ ⒵ Ⓐ Ⓑ Ⓒ Ⓓ Ⓔ Ⓕ Ⓖ Ⓗ Ⓘ Ⓙ Ⓚ Ⓛ Ⓜ Ⓝ Ⓞ Ⓟ Ⓠ Ⓡ Ⓢ Ⓣ Ⓤ Ⓥ Ⓦ Ⓧ Ⓨ Ⓩ ⓐ ⓑ ⓒ ⓓ ⓔ ⓕ ⓖ ⓗ ⓘ ⓙ ⓚ ⓛ ⓜ ⓝ ⓞ ⓟ ⓠ ⓡ ⓢ ⓣ ⓤ ⓥ ⓦ ⓧ ⓨ ⓩ ⓪ ⓫ ⓬ ⓭ ⓮ ⓯ ⓰ ⓱ ⓲ ⓳ ⓴ ⓵ ⓶ ⓷ ⓸ ⓹ ⓺ ⓻ ⓼ ⓽ ⓾ ⓿ ─ ━ │ ┃ ┄ ┅ ┆ ┇ ┈ ┉ ┊ ┋ ┌ ┍ ┎ ┏ ┐ ┑ ┒ ┓ └ ┕ ┖ ┗ ┘ ┙ ┚ ┛ ├ ┝ ┞ ┟ ┠ ┡ ┢ ┣ ┤ ┥ ┦ ┧ ┨ ┩ ┪ ┫ ┬ ┭ ┮ ┯ ┰ ┱ ┲ ┳ ┴ ┵ ┶ ┷ ┸ ┹ ┺ ┻ ┼ ┽ ┾ ┿ ╀ ╁ ╂ ╃ ╄ ╅ ╆ ╇ ╈ ╉ ╊ ╋ ╌ ╍ ╎ ╏ ═ ║ ╒ ╓ ╔ ╕ ╖ ╗ ╘ ╙ ╚ ╛ ╜ ╝ ╞ ╟ ╠ ╡ ╢ ╣ ╤ ╥ ╦ ╧ ╨ ╩ ╪ ╫ ╬ ╭ ╮ ╯ ╰ ╱ ╲ ╳ ╴ ╵ ╶ ╷ ╸ ╹ ╺ ╻ ╼ ╽ ╾ ╿ ▀ ▁ ▂ ▃ ▄ ▅ ▆ ▇ █ ▉ ▊ ▋ ▌ ▍ ▎ ▏ ▐ ░ ▒ ▓ ▔ ▕ ▖ ▗ ▘ ▙ ▚ ▛ ▜ ▝ ▞ ▟ ■ □ ▢ ▣ ▤ ▥ ▦ ▧ ▨ ▩ ▪ ▫ ▬ ▭ ▮ ▯ ▰ ▱ ▲ △ ▴ ▵ ▶ ▷ ▸ ▹ ► ▻ ▼ ▽ ▾ ▿ ◀ ◁ ◂ ◃ ◄ ◅ ◆ ◇ ◈ ◉ ◊ ○ ◌ ◍ ◎ ● ◐ ◑ ◒ ◓ ◔ ◕ ◖ ◗ ◘ ◙ ◚ ◛ ◜ ◝ ◞ ◟ ◠ ◡ ◢ ◣ ◤ ◥ ◦ ◧ ◨ ◩ ◪ ◫ ◬ ◭ ◮ ◯ ◰ ◱ ◲ ◳ ◴ ◵ ◶ ◷ ◸ ◹ ◺ ◻ ◼ ◽ ◾ ◿ ☀ ☁ ☂ ☃ ☄ ★ ☆ ☇ ☈ ☉ ☊ ☋ ☌ ☍ ☎ ☏ ☐ ☑ ☒ ☓ ☔ ☕ ☖ ☗ ☘ ☙ ☚ ☛ ☜ ☝ ☞ ☟ ☠ ☡ ☢ ☣ ☤ ☥ ☦ ☧ ☨ ☩ ☪ ☫ ☬ ☭ ☮ ☯ ☰ ☱ ☲ ☳ ☴ ☵ ☶ ☷ ☸ ☹ ☺ ☻ ☼ ☽ ☾ ☿ ♀ ♁ ♂ ♃ ♄ ♅ ♆ ♇ ♈ ♉ ♊ ♋ ♌ ♍ ♎ ♏ ♐ ♑ ♒ ♓ ♔ ♕ ♖ ♗ ♘ ♙ ♚ ♛ ♜ ♝ ♞ ♟ ♠ ♡ ♢ ♣ ♤ ♥ ♦ ♧ ♨ ♩ ⌠ ⌡ ⌢ ⌣⌆ ⌇ ⌈ ⌉ ⌊ ⌋ ∀ ∁ ∂ ∃ ∄ ∅ ∆ ∇ ∈ ∉ ∊ ∋ ∌ ∍ ∎ ∏ ∐ ∑ − ∓ ∔ ∕ ∖ ∗ ∘ ∙ √ ∛ ∜ ∝ ∞ ∟ ∠ ∡ ∢ ∣ ∤ ∥ ∦ ∧ ∨ ∩ ∪ ∫ ∬ ∭ ∮ ∯ ∰ ∱ ∲ ∳ ∴ ∵ ∶ ∷ ∸ ∹ ∺ ∻ ∼ ∽ ∾ ∿ ≀ ≁ ≂ ≃ ≄ ≅ ≆ ≇ ≈ ≉ ≊ ≋ ≌ ≍ ≎ ≏ ≐ ≑ ≒ ≓ ≔ ≕ ≖ ≗ ≘ ≙ ≚ ≛ ≜ ≝ ≞ ≟ ≠ ≡ ≢ ≣ ≤ ≥ ≦ ≧ ≨ ≩ ≪ ≫ ≬ ≭ ≮ ≯ ≰ ≱ ≲ ≳ ≴ ≵ ≶ ≷ ≸ ≹ ≺ ≻ ≼ ≽ ≾ ≿ ⊀ ⊁ ⊂ ⊃ ⊄ ⊅ ⊆ ⊇ ⊈ ⊉ ⊊ ⊋ ⊌ ⊍ ⊎ ⊏ ⊐ ⊑ ⊒ ⊓ ⊔ ⊕ ⊖ ⊗ ⊘ ⊙ ⊚ ⊛ ⊜ ⊝ ⊞ ⊟ ⊠ ⊡ ⊢ ⊣ ⊤ ⊥ ⊦ ⊧ ⊨ ⊩ ⊪ ⊫ ⊬ ⊭ ⊮ ⊯ ⊰ ⊱ ⊲ ⊳ ⊴ ⊵ ⊶ ⊷ ⊸ ⊹ ⊺ ⊻ ⊼ ⊽ ⊾ ⊿ ⋀ ⋁ ⋂ ⋃ ⋄ ⋅ ⋆ ⋇ ⋈ ⋉ ⋊ ⋋ ⋌ ⋍ ⋎ ⋏ ⋐ ⋑ ⋒ ⋓ ⋔ ⋕ ⋖ ⋗ ⋘ ⋙ ⋚ ⋛ ⋜ ⋝ ⋞ ⋟ ⋠ ⋡ ⋢ ⋣ ⋤ ⋥ ⋦ ⋧ ⋨ ⋩ ⋪ ⋫ ⋬ ⋭ ⋮ ⋯ ⋰ ⋱ ← ↑ → ↓ ↔ ↕ ↖ ↗ ↘ ↙ ↚ ↛ ↜ ↝ ↞ ↟ ↠ ↡ ↢ ↣ ↤ ↥ ↦ ↧ ↨ ↩ ↪ ↫ ↬ ↭ ↮ ↯ ↰ ↱ ↲ ↳ ↴ ↵ ↶ ↷ ↸ ↹ ↺ ↻ ↼ ↽ ↾ ↿ ⇀ ⇁ ⇂ ⇃ ⇄ ⇅ ⇆ ⇇ ⇈ ⇉ ⇊ ⇋ ⇌ ⇍ ⇎ ⇏ ⇐ ⇑ ⇒ ⇓ ⇔ ⇕ ⇖ ⇗ ⇘ ⇙ ⇚ ⇛ ⇜ ⇝ ⇞ ⇟ ⇠ ⇡ ⇢ ⇣ ⇤ ⇥ ⇦ ⇧ ⇨ ⇩ ⇪⅓ ⅔ ⅕ ⅖ ⅗ ⅘ ⅙ ⅚ ⅛ ⅜ ⅝ ⅞ ⅟ Ⅰ Ⅱ Ⅲ Ⅳ Ⅴ Ⅵ Ⅶ Ⅷ Ⅸ Ⅹ Ⅺ Ⅻ Ⅼ Ⅽ Ⅾ Ⅿ ⅰ ⅱ ⅲ ⅳ ⅴ ⅵ ⅶ ⅷ ⅸ ⅹ ⅺ ⅻ ⅼ ⅽ ⅾ ⅿ ↀ ↁ ↂ℀ ℁ ℂ ℃ ℄ ℅ ℆ ℇ ℈ ℉ ℊ ℋ ℌ ℍ ℎ ℏ ℐ ℑ ℒ ℓ ℔ ℕ № ℗ ℘ ℙ ℚ ℛ ℜ ℝ ℞ ℟ ℠ ℡ ™ ℣ ℤ ℥ Ω ℧ ℨ ℩ K Å ℬ ℭ ℮ ℯ ℰ ℱ Ⅎ ℳ ℴ ℵ ℶ ℷ ℸ ₠ ₡ ₢ ₣ ₤ ₥ ₦ ₧ ₨ ₩ ₪ ₫ € ₭ ₮ ₯ ⁺ ⁻ ⁼ ⁽ ⁾ ⁿ ₀ ₁ ₂ ₃ ₄ ₅ ₆ ₇ ₈ ₉ ₊ ₋ ₌ ₍ ₎‐ ‑ ‒ – — ― ‖ ‗ ‘ ’ ‚ ‛ “ ” „ ‟ † ‡ • ‣ ․ ‥ … ‧ &amp;lt; ‪ ‫ ‬ ‭ ‮ ‰ ‱ ′ ″ ‴ ‵ ‶ ‷ ‸ ‹ › ※ ‼ ‽ ‾ ‿ ⁀ ⁁ ⁂ ⁃ ⁄ ⁅ ⁆ !</description>
    </item>
    
    <item>
      <title>立个flag</title>
      <link>http://nber1994.github.io/posts/%E7%AB%8B%E4%B8%AAflag/</link>
      <pubDate>Sun, 26 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E7%AB%8B%E4%B8%AAflag/</guid>
      <description>立个flag吧 2020年用这个键盘参与一个开源项目并成为主要开发成员 </description>
    </item>
    
    <item>
      <title>像素风</title>
      <link>http://nber1994.github.io/posts/%E5%83%8F%E7%B4%A0%E9%A3%8E/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E5%83%8F%E7%B4%A0%E9%A3%8E/</guid>
      <description></description>
    </item>
    
    <item>
      <title>scan遇上rehash</title>
      <link>http://nber1994.github.io/posts/scan%E9%81%87%E4%B8%8Arehash/</link>
      <pubDate>Fri, 27 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/scan%E9%81%87%E4%B8%8Arehash/</guid>
      <description>缘起 面试时被问到，redis如果你想要找到所有test_开头的键值时，一般使用什么命令 我当时想也不想，keys命令啊 面试官一脸失望的问我，有没有用过scan命令 我赶紧说用过用过 但是当时心里特别害怕，生怕问这两者的区别，不过好在没有继续往下问，嘿嘿 不过面试后，我隐隐好奇，这两者到底有什么区别，为什么都推荐用scan这个命令？
背景 keys和scan的区别 KEYS parttern：查找所有符合给定模式pattern的key。  KEYS指令一次性返回所有匹配的key。 key的数量过大会使服务卡顿。  SCAN cursor [MATCH pattern] [COUNT count]：查找给定数量内个数的符合给定模式pattern的key。  基于游标的迭代器，需要基于上一次的游标延续之前的迭代过程。 以0作为游标开始一次新的迭代，直到命令返回游标0完成一次遍历。 不保证每次执行都返回给定数量的元素，支持模糊查询。 一次返回的数量不可控，只能是大概率符合COUNT参数。 返回的游标不一定是递增的，可能会获取到重复key，需要在外部程序去重。  keys会导致的问题 首先我们看下redis的网络模型IO多路复用
IO多路复用 简单来说，IO多路复用是一场一对多的群架，相较于多进程与多线程网络模型，io多路复用使用一个进程（一个线程）遍历处理多个socket的请求，准确来说，是交由操作系统来进行socket的遍历操作 总的来说分为三步：
 fd拷贝（用户空间 -&amp;gt; 系统空间） 遍历fd 返回就绪的fd 进程处理就绪fd请求  首先我们知道，redis是一个基于内存的单进程单线程（基于IO多路复用）的kv数据库 在redis2.8之前，能满足这一需求的是keys命令，但是他会导致两个问题：
 没有limit，只能一次性的获取所有符合条件的结果，换句话说如果你的命令输入错误，可能会有成百上千的输出 单进程单线程的redis，一个O(N)的算法，如果执行时间很长，很可能会直接导致redis服务的阻塞  这谁顶得住啊，我如果需要在线上执行一个查询命令，即使命令没有输错，但是如果结果集很大，都有可能导致redis的一个节点阻塞
问题 为什么实现不了limit （时间复杂度） 那么我就会问，为什么不能支持limit操作呢，这样即使我的操作是O(N)的，我可以通过把limit设置的比较小，循环多次取，这样可以减少对服务的影响。但是为什么实现不了呢，这与redis的底层结构有关，我们知道redis的键值对底层是以dict这一内部数据结构组织的，那我们就看看dict这一结构为什么不好实现这一功能
dict结构 dict结构 typedef struct dict { //类型特定函数  dictType *type; //私有数据  void *privData; //哈希表  dictht ht[2]; //rehash索引  //当rehash不进行时，值为-1  int trehashidx; }  可以看到，一个dict存在两个hash表结构（本质是数组）</description>
    </item>
    
    <item>
      <title>如何查看剩余内存</title>
      <link>http://nber1994.github.io/posts/%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E5%89%A9%E4%BD%99%E5%86%85%E5%AD%98/</link>
      <pubDate>Wed, 21 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E5%89%A9%E4%BD%99%E5%86%85%E5%AD%98/</guid>
      <description>如何查看剩余内存</description>
    </item>
    
    <item>
      <title>codeReview</title>
      <link>http://nber1994.github.io/posts/codereview/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/codereview/</guid>
      <description>pic-codeReview </description>
    </item>
    
    <item>
      <title>https基础知识</title>
      <link>http://nber1994.github.io/posts/https%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/https%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</guid>
      <description> 公钥&amp;amp;私钥 公钥用来加密，私钥用来解迷
 http的问题  明文传输，可能导致信息被窃听 不互相验证身份，可能导致伪装 不校验报文的完整性，可能被篡改  https 在表示层增加stl&amp;amp;CA来进行加密  首先进行非对称加密（较耗费性能）  c请求s，s返回证书&amp;amp;公钥 c请求CA来验证证书（CA地址一般内置操作系统） 验证成功，则生成一个随机串，通过公钥加密传递给s   然后进行对称加密  s通过私钥解迷，拿到随机串 通过随机串加密响应结果，返回    </description>
    </item>
    
    <item>
      <title>InnoDB概述</title>
      <link>http://nber1994.github.io/posts/innodb%E6%A6%82%E8%BF%B0/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/innodb%E6%A6%82%E8%BF%B0/</guid>
      <description>InnoDB完整支持ACID事务
体系架构 InnoDB内部存在多个内存块，可以看做是内存池
内存池负责如下工作:
 维护内部数据结构 缓存磁盘上的数据，方便的快速读取。同时对磁盘文件的修改进行缓存 redo log的缓冲  后台线程：
 负责刷新内存池中数据，保证缓冲池中的是最近的数据 将已经修改的数据文件刷新到磁盘中 保证在发送异常时回复  后台线程 master thread 负责将缓冲池中的数据异步刷新到磁盘，脏页刷新，合并插入缓存等
IO thread InnoDB使用了大量的AIO处理IO请求，负责IO请求的回调
purge thread 回收事务提交后的已经使用的undo页
内存 缓冲池 InnoDB是基于磁盘的数据库，通常使用缓冲池技术来提高数据库的整体性能
 读取数据 缓冲池简单来说就是一块内存区域，当读取某一页时，会将数据从磁盘读取到缓冲池中，提高性能 写入数据 对数据的修改，会首先修改缓冲池中的页，然后再已一定的频率将修改刷回磁盘，这里采用的是checkpoint机制刷到磁盘，而不是每次发生页更新时触发 相关参数 innodb_buffer_pool_size 缓冲池缓冲页类型：索引页，数据页，undo页，插入缓冲，自适应哈希索引，innodb存储的锁信息等  LRU list和Free list和flush list 通常来说缓冲池是通过LRU算法来实现的，使用最频繁的页在列表的最前面，最少使用的页在对尾，当没有更多的内存时，首先释放列尾的页
在缓冲池中，每页的大小为16K
lru算法的改进 引入midpoint，新进入的页会放在midpoint的位置
改进的原因是因为当有大的结果的sql出现时，如果放入对首的话，会把热点数据给覆盖掉，而该sql不一定是会频繁出现的
同时还引入了一个innodb_old_blocks_time，规定了多久之后会将old数据放入new列表的对首
free list 该list记录得是所有的未分配的页面，当innodb刚启动是，缓冲池所有的页都存在于free list中
flush list 当LRU列表中的页被修改后，该页面被称为脏页，缓冲池中的数据与磁盘中的数据不一致。此时会通过checkpoint机制来讲脏页刷回磁盘，
所以flush list中的都是脏页，同时lru列表中也会存在脏页
重做日志缓冲 InnoDB中除了缓冲池外，还有redo log缓冲，InnoDB会先将redo log存到这个缓冲区，然后按照一定概率将其刷新到日志文件中
redo log会在如下情况下刷入磁盘：
 master thread每秒会刷新到文件 事务提交时会将日志刷新到文件（不一定commit group） 重做日志缓冲剩余空间小于1/2时  checkpoint技术 当页发送变化时将页的版本刷新到磁盘，开销是十分大的。同时如果从缓存页落地磁盘时发送宕机时，是无法恢复的。 所以采用了wirte ahead技术，在事务提交时，先写重做日志，再去修改页面，这样一来，宕机之后可以通过redo log 来恢复数据</description>
    </item>
    
    <item>
      <title>ip基础知识</title>
      <link>http://nber1994.github.io/posts/ip%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/ip%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</guid>
      <description>ip基础知识 网络层和数据链路层的区别  数据链路层负责在直连的网络的传输 而网络层负责在没有直连的网络之间传输  ip地址属于网络层地址
 ip用于识别地址 ip路由也叫做多跳路由，他的寻址方式  将数据报送到下一跳地址，然后在看吓一跳应该去哪里 数据包以一种十分偶然的方式进行传出    ip属于面向无连接  原因  较为简单  不需要繁琐的建立连接到步骤   为了提速  发送之前不需要家里接连，直接发送      ip定义  ip是以32位二进制表示 每8位由.隔开 大概可以容纳43亿的地址  但是一个网卡可以由多个ip 一个电脑有多个网卡    ip组成  因为ip具有寻址的功能，所以ip地址会分为  网络标识 主机标识    ip地址的分类  A类地址  1-8位网络标识 首位必须为0 0.0.0.0 - 127.0.0.0   B类地址  1-16位网络标识 首位为10 128.0.0.1 - 191.</description>
    </item>
    
    <item>
      <title>mysql-查询优化器&amp;sql军规</title>
      <link>http://nber1994.github.io/posts/mysql%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%E5%99%A8sql%E5%86%9B%E8%A7%84/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/mysql%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%E5%99%A8sql%E5%86%9B%E8%A7%84/</guid>
      <description>查询优化器  使用具体的字段名来取代*,因为会将*转化为表的所有字段 使用具体的表的字段名取代字段名。table.field取代field，因为在查询中，特别是多表联合查询时，如果不指定表名，则会查询所有表的字段 使用group条件替代distinct条件，查询优化器会将distinct条件转化为group条件 使用limit条件会增加查询时间 ，join inner join cross join在mysql中是等价的，都会转化为多表的联合查询，对于内连接查询来看，on和where是等价的 left join会将左边的表进行全表扫描，右边的表没有匹配的话会有null代替。当 数据表不能为NULL时，则左边不会列出所有的记录，并将外链接转化为多表联合查询 outer join的where和on条件有一些区别，on是在生产查询结果之前，进行过滤。where是在查询结果输出过程中的过滤，因此过滤条件写在where中，left不会显示所有的记录 转化子查询为多表联合查询。子查询会创建临时表，并且临时表没有任何索引导致性能过低。多表联合查询不会建立临时表，并且可以有效地利用查询索引  sql军规 基础规范   必须使用innoDB   支持事务，行级锁，并发性能更好，cpu以及内存资源利用率高
?? innoDB和MyIsAm引擎的区别
 必须使用utf8mb4字符集   万国码，无需转码，无乱码风险，节省空间
 数据表，字段必须加入中文注释    禁止使用存储过程，视图，触发器，event   ?? 什么是存储过程，视图，触发器和事件
存储过程不适合快速迭代，修改表结构之后可能无法使用
同时存过有很多逻辑判断，应该讲逻辑上移到应用程序
视图也是一样 高并发的网络架构思路是 解放数据库CPU，将计算转移到服务层
对于触发器来说，十分耗费资源，例如一个insert语句，每次都会触发触发器 因为在并发量大的情况下，这些功能可能会把数据库拖慢，而把这些逻辑放在应用层，可以轻易实现加机器就能加性能
 禁止存储大文件或大照片   数据库并不适合存储大文件和大图片，何不存入uri
命名规范  只允许使用内网域名，而非IP连接 线上，测试，开发环境数据库命名规范 业务名 xxx
线上环境 dj.xxx.db
测试环境 dj.xxx.tdb
开发环境 dj.xxx.rdb
从库-s标识 备库-ss 库名，表名，字段名:小写，下划线 表名t_xxx,索引名idx_xxx,唯一索引uniq_xxx   表设计规范  单实例表数目必须小于500 单表列数目必须小于30 表必须有主键     ？？ 主键的作用， 索引，内存管理 *   禁止使用外键，若有外键完整性约束，需要应用程序控制   外键会造成表之间的耦合，update和delete操作会涉及相关联的表</description>
    </item>
    
    <item>
      <title>mysql事务</title>
      <link>http://nber1994.github.io/posts/mysql%E4%BA%8B%E5%8A%A1/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/mysql%E4%BA%8B%E5%8A%A1/</guid>
      <description>事务概述  Innodb中的事务隔离级别和锁的关系 https://tech.meituan.com/innodb_lock.html
  A：原子性 一个事件中的几个步骤，要么不做，要么都做 C：一致性 事务将数据库从一个状态转化为另一个一致性状态，例如外键约束没有遭到破坏 一致性关注的是数据，用户只对事务开始前的数据和事务结束后的数据可见，中间状态的数据对用户是不可见的 I：隔离性 隔离性也叫做并发控制，可串行化，锁等。总的来说就是事务提交之前对其他事务是不可见的 隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。 D：持久性 事务一旦提交，则其结果就是永久性的 持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。  事务的实现 redo log 用来保证事务的持久性
undo log用来保证事务的一致性
redo log 和undo log并不是互为逆过程
redo log记录的是页的改动
undo log记录的是行的改动
redo log 分为两种，一种是redo缓冲区中的redo log，其是易失的 另一种是redo日志文件，是持久的
redo log作用 innodb是事务型存储引擎，通过force log at commit机制实现事务的持久化，即在事务提交之前将所有日志写入到日志文件中 redo log基本上是顺序写的，而且只有在redo log日志写入之后，调用fsync命令。所以磁盘的性能决定了sync的性能，进而决定了事务的性能
在innodb中，该日志包含两部分，redo log和undo log，redo log来实现事务的持久性，undo log来实现事务的回滚和mvcc机制
binlog与redo log区别  层次不同 binlog是记录的mysql行为的，而redo log只是innodb中的 日志内容不同，binlog记录的是逻辑日志，记录的内容是sql，而redo log记录的是页面的变动 写入时机不同，binlog是在事务提交只有写入，redolog在事务中就写入  redolog恢复 当mysql启动时，不论上次关闭是否正常，都会重做redolog，将页面改动做回磁盘，根据checkpoint表示的LSN，重做之后的redolog
undo log undolog用于事物的回滚，将数据改动为事务之前的状态 与redolog不同的是，undolog是存在于共享表空间的undo段
误解 undolog是逻辑日志，只记录变化量
undolog作业 一个是进行事务的回滚 另一个是实现mvcc 当一个事务读取一行信息，如果发现正在被某一事务占用，则会根据undolog读取到之前版本的信息 同时undolog也会导致redolog的产生，因为undolog也需要持久化保护</description>
    </item>
    
    <item>
      <title>mysql索引结构</title>
      <link>http://nber1994.github.io/posts/mysql%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/mysql%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84/</guid>
      <description>mysql-索引结构  索引的结构是B+Tree，这个众所周知，但是具体的结构以及原因我们来探究下
 聚簇索引和非聚簇索引 首先要知道  聚簇索引即数据行放在索引的叶子页面中，而非聚簇索引则是数据和索引分开存放 索引和表属于比较大的数据，所以存放在磁盘中，索引的变更等操作都会导致节点的分裂和新增 考量一个索引结构的性能和设计时，不能只考虑查询性能，还要考虑对数据的修改以及对索引调整的复杂度 一般一个B+Tree的节点为innodb的一页的大小，即16k  聚簇索引  数据文件存放在叶子节点中 数据存放顺序和索引顺序是一致的，索引相邻的话，磁盘存放位置就是相邻的  聚簇索引的特点   优点
 由于相邻索引的数据是在磁盘相邻存放的，所以可以将一类的数据的索引值相邻，这样一旦查询一类数据时，可以一次读取磁盘，将所有数据都读取，避免了随机读 数据访问会很快，因为到达叶子节点直接就能拿到数据    缺点
 脱离了IO密集型场景则失去优势 插入速度依赖插入的顺序，如果顺序插入速度最快，但是会在主键的上界产生明显的竞争 更新索引列的代价很高，因为会强制的对数据进行移动 使用辅助索引会带来两次查找（自适应哈希索引解决）     顺序写入与读取的性能要大于随机写入读取，所以你会发现很多地方的设计其实都是将随机写入转变为顺序写入的， 例如mysql的doublewirte，先将需要落磁盘的数据写入内存缓冲区之后，在顺序写入到磁盘的共享表空间中，再写入实际的页面中，来解决写磁盘时崩溃导致的数据丢失问题  非聚簇索引   数据和索引分开存放
  数据的存放于索引的顺序没有关系，叶子节点指向数据的地址
  优点
 插入索引非顺序时也很快 更新索引代价不大，不需要移动数据行    两种索引的数据存储 MyIsam 例如按照下述代码建表，col1为主键
create table layout_test( col1 int not null, col2 int not null, primary key(col1), key(col2) ); 主键索引的结构是按照行号来组织的，其结构如下 如下图，索引文件按照行号来进行组织，叶子节点存储的是数据行的地址指针 而对于col2对应的索引结构，与主键上的一致</description>
    </item>
    
    <item>
      <title>nginx平滑重启</title>
      <link>http://nber1994.github.io/posts/nginx%E5%B9%B3%E6%BB%91%E9%87%8D%E5%90%AF/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/nginx%E5%B9%B3%E6%BB%91%E9%87%8D%E5%90%AF/</guid>
      <description>nginx-平滑重启  本文转载自软件编程之路公众号文章：深入剖析nginx平滑重启
 一、背景 在服务器开发过程中，难免需要重启服务加载新的代码或配置，如果能够保证server重启的过程中服务不间断，那重启对于业务的影响可以降为0。最近调研了一下nginx平滑重启，觉得很有意思，记录下来供有兴趣的同学查阅。
二、重启流程   重启意味着新旧接替，在交接任务的过程中势必会存在新旧server并存的情形，因此，重启的流程大致为：
 启动新的server 新旧server并存，两者共同处理请求，提供服务 旧的server处理完所有的请求之后优雅退出    这里，最主要的问题在于如何保证新旧server可以并存，如果重启前后的server端口一致，如何保证两者可以监听同一端口。
  三、nginx实现  为了验证nginx平滑重启，笔者首先尝试nginx启动的情形下再次开启一个新的server实例，结果如图：   很明显，重新开启server实例是行不通的，原因在于新旧server使用了同一个端口80，在未开始socket reuseport选项复用端口时，bind系统调用会出错。nginx默认bind重试5次，失败后直接退出。而nginx需要监听IPV4地址0.0.0.0和IPV6地址[::]，故图中打印出10条emerg日志。
接下来就开始尝试平滑重启命令了，一共两条命令：  kill -USR2 `cat /var/run/nginx.pid` kill -QUIT `cat /var/run/nginx.pid.oldbin`  第一条命令是发送信号USR2给旧的master进程，进程的pid存放在/var/run/nginx.pid文件中，其中nginx.pid文件路径由nginx.conf配置。 第二条命令是发送信号QUIT给旧的master进程，进程的pid存放在/var/run/nginx.pid.oldbin文件中，随后旧的master进程退出。  那么问题来了，为什么旧的master进程的pid存在于两个pid文件之中？事实上，在发送信号USR2给旧的master进程之后，旧的master进程将pid重命名，原先的nginx.pid文件rename成nginx.pid.oldbin。这样新的master进行就可以使用nginx.pid这个文件名了。
先执行第一条命令，结果如图： 不错，新旧master和worker进程并存了。 再来第二条命令，结果如图: 如你所见，旧的master进程8527和其worker进程全部退出，只剩下新的master进程12740。
不由得产生困惑，为什么手动开启一个新的实例行不通，使用信号重启就可以达到。先看下nginx log文件： 除了之前的错误日志，还多了一条notice，意思就是继承了sockets，fd值为6，7。 随着日志翻看nginx源码，定位到nginx.c/ngx_exec_new_binary函数之中，
ngx_pid_t ngx_exec_new_binary(ngx_cycle_t *cycle, char *const *argv) { ... ctx.path = argv[0]; ctx.name = &amp;#34;new binary process&amp;#34;; ctx.argv = argv; n = 2; env = ngx_set_environment(cycle, &amp;amp;n); .</description>
    </item>
    
    <item>
      <title>nsq-v0文档</title>
      <link>http://nber1994.github.io/posts/nsq-v0.1.1%E6%96%87%E6%A1%A3/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/nsq-v0.1.1%E6%96%87%E6%A1%A3/</guid>
      <description>nsq-v0.1.1README NSQ An infrastructure component designed to support highly available, distributed, fault tolerant, &amp;ldquo;guaranteed&amp;rdquo; message delivery. 一个支持高可用，分布式，容错性以及可靠消息传递的消息队列
Background simplequeue was developed as a dead-simple in-memory message queue. It spoke HTTP and had no knowledge (or care) for the data you put in or took out. Life was good. simplequeue是一个十分简单的内存消息队列（不做持久化）。他基于HTTP并且对内部传递的消息无感知，简洁而美秒。
We used simplequeue as the foundation for a distributed message queue. In production, we silo&amp;rsquo;d a simplequeue right where messages were produced (ie.</description>
    </item>
    
    <item>
      <title>php-fpm进程管理</title>
      <link>http://nber1994.github.io/posts/php-fpm%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/php-fpm%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</guid>
      <description>php-fpm进程管理 fpm进程管理：w</description>
    </item>
    
    <item>
      <title>ping命令</title>
      <link>http://nber1994.github.io/posts/ping%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/ping%E5%91%BD%E4%BB%A4/</guid>
      <description> ping A
  基于ICMP，网络层，速度快 拼接IP包，加入A为目的地址，以及ICMP报文组成IP包发送至网络中寻址 到达目的IP机器子网后，会根据ARP协议，发送到目的IP机器，目的IP机器收到包后解析，然后封装响应包  </description>
    </item>
    
    <item>
      <title>questions</title>
      <link>http://nber1994.github.io/posts/questions/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/questions/</guid>
      <description>Questions OS 虚拟内存 段页式 倒排页表 LRU，LFU算法实现 共享内存 多进程，多线程 如何fork一个进程 exec waitpid exit 页表的copy-on-worite PCB
 PCB process control block &amp;gt; task_struct存储了进程的页表，打开文件描述符表，内存描述符，通用寄存器，进程状态等
 进程状态 IO多路复用 select，poll，epoll实现和优劣
用户态和内核态区别 进程，线程间通信 什么时候多线程什么时候多进程 线程ID进程组ID 线程和进程的切换和调度，切换的时什么 多进程 - 数据共享复杂，需要进程间通信 - 相对于多线程占用更多的内存 - 进程间切换相对于多线程开销较大 - 编程调试较简单 - 进程间互相不影响 - 适用于多机，性能扩展性较好 多线程 - 数据共享较简单 - 线程间可能会互相影响 - 编程调试较复杂 - 可以利用多核的优势 - 多线程之间切换开销较小
 文件描述符表  网络 http https https相比较于http来说，在会话层加入了stl算法加密，过程如下 1.服务端发送来证书和公钥 2.客户端根据内置的颁发机构验证证书的真伪 3.如果证书为假，则报错 4.如果证书为真，则生成随机值，并用公钥加密传递给服务端 5.服务端收到后使用私钥进行解密，拿到随机值 6.之后的通信都使用随机值进行加密
http code 200 ok 301 moved permanly 302 Found 303 See Other 400 Bad Request 401 Nuauthorized 403 forbidden 404 Not Found 500 internal server error 502 bad gateway 503 service unavaliable 504 gateway timout</description>
    </item>
    
    <item>
      <title>redis复制</title>
      <link>http://nber1994.github.io/posts/redis%E5%A4%8D%E5%88%B6/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E5%A4%8D%E5%88%B6/</guid>
      <description> redis通过slaveof命令，放一个服务器去复制另一个服务器，一个为主服务器，另一个为从服务器 主从服务器保存相同的数据称为一致  旧版本的复制实现  redis的复制功能分为同步和命令传播两个操作  同步用于将从服务器更新至与主服务器数据相同的数据库状态 命令传播用于当主服务器上存在修改，导致主从不一致的情况下，将主从服务器的数据库状态重回一致    同步  当从服务器收到salveof命令时，会向主服务器发生sync命令 主服务器收到sync命令行，会执行bgsave命令，生成RDB文件。并将RDB文件发生给从服务器 从服务器接收到RDB文件后，将RDB载入内存，将数据库状态更新至主服务器执行BGSAVE时的状态 主服务器将RDB重写缓冲区中的数据发送给从服务器执行 从服务器执行完重写缓冲区的命令后达到和主服务器相同的数据库状态  命令传播  同步完成后，主服务器的所有修改操作都会发送到从服务器 从服务器执行完修改命令后，重新达到数据库状态的一致性  问题  当出现连接断线时  从服务器重新发送sync命令，主服务器重新生成RDB文件，传送给从服务器载入 RDB文件包含了大量的从服务器已经存在的键值对，这种做法是十分低效的  主服务器生成RDB文件需要消耗CPU和磁盘IO资源 传送RDB文件耗费带宽 从服务器载入RDB文件，服务处于阻塞状态      新版本复制实现  新版采用了psync来代替sync命令 psync分文完整重同步和部分重同步  完整重同步和sync完全相同 部分重同步则会在断线之后，只发送在断线期间的写命令即可实现主从服务器数据库状态的    部分重同步的实现  部分重同步由三个部分构成  主服务器复制偏移量和从服务器复制偏移量 主服务器复制挤压缓冲区 runid    复制偏移量  主服务器每次向从服务器发送N个字节的数据时，复制偏移量加N 从服务器每次接收N个字节，复制偏移量会加N 两个偏移量不一致时，说明主从不一致  复制挤压缓冲区  redis会维护一个FIFO的大小为1MB的复制挤压缓冲区 当从服务器发送psync命令时，检查从复制的偏移量是否在复制挤压缓冲区中  在的话， 发送+COUNTINUE命令，将偏移量之后的数据发送给从服务器 不在的话则进行完整重同步    runid  每个服务器初始化时，都会生成一个唯一的runid 当从服务器首次复制主服务器时，执行完完整重同步之后，会保存主服务器的runid 从服务器重新连接主服务器时，会发送runid，如果runid和主服务器不一致则会导致完整重同步  psync命令实现  当首次接收到slaveof命令时，发送psync ？ -1 命令进行完整重同步 如果复制过主服务器，重新复制时，会发生psync runid offset命令  如果返回 +flulresync runid offset回复，标识需要进行完整重同步 返回+countinue，部分重同步操作，从服务器只需要等待主服务器发送复制积压缓冲区的数据即可 回复-ERR时，不识别psync，需要执行sync命令     复制的实现 步骤1：设置主服务器的地址和端口  slaveof是一个异步命令，在完成masterhost和masterport设置完成之后，就会向客户端恢复ok 实际的工作才刚刚开始  步骤2：建立套接字  建立套接字成功之后，从服务器会为套接字关联一个专门处理复制工作的文件事件处理器 主服务器接收到从服务器的连接之后，会为从服务器创建相应的客户端状态 从服务器作为主服务器的客户端  步骤3：ping  ping的两个作用  判断主从之间是否网络通畅 判断主服务器是否可以正常接收处理命令     步骤4：身份验证 步骤5：发送端口  从服务器会将自己监听的端口发送给主服务器  步骤6：同步  从服务器发送psync命令，根据主服务器的回复决定什么重同步方式  +FULLRESYNC runid offset 进行完整重同步 +CONTINUE 进行部分重同步 -ERR 不支持psync，使用sync同步    步骤7：命令传播  当完成同步之后，主服务器处理写命令之后，会将命令传播给从服务器，从而恢复一致性  心跳检测  在命令传播阶段，从服务器默认会以每秒一次的频率，向主服务器发送命令  REPLCONF ACK offset 从服务器当前读复制偏移量   心跳检测的作用  检测主从服务器之间网络的联通性  主从服务器之间会互发replconf ack，一定时间内没有收到回复则连接有问题   辅助实现min-slaves选项  min-slaves选项  min-slaves-to-write 3 从服务器小于三个时 min-slaves=max-lag 10 延时大于等于10秒时   当满足该条件时，主服务器就会拒绝执行写命令   检测命令丢失  当主服务器接收到replconf ack命令中从服务器的复制偏移量，发现少于主服务器的复制偏移量时，会检查复制挤压缓冲区是否包含该偏移量，有的话会将数据传输给从服务器 检测命令丢失是在没有断线的情况下进行检测，而部分重同步是在断线之后执行的      重点回顾 </description>
    </item>
    
    <item>
      <title>redis客户端</title>
      <link>http://nber1994.github.io/posts/redis%E5%AE%A2%E6%88%B7%E7%AB%AF/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E5%AE%A2%E6%88%B7%E7%AB%AF/</guid>
      <description>客户端  redis服务器中，保存着clients链表  struct redisServer { //一个链表，报错了所有客户端状态  list *clients; }  客户端种类  伪客户端，伪客户端的fd属性为-1。redis有两个地方用到伪客户端，一个是AOF载入时，一个是执行lua脚本  lua客户端在redis服务器期间都会一直存在   普通客户端，fd正整数   flag 标志主从服务器，lua客户端 输入输出缓冲区 命令与命令参数  服务器 serverCron函数   更新服务器时间缓存
 redis需要获取时间的场景，因为每次获取时间都是系统调用，比较费时，所以会将时间缓存    更新LRU时钟
 对象的lru属性，表明最后一次访问的时间    更新服务器的每秒执行命令次数
 每100毫秒抽样计算的方式    更新服务器内存峰值记录
  处理SIGTERM信号
 redis启动时，为SIGTERM信号关联信号处理器，该处理器会在接到信号后，打开服务器的标识位 serverCron函数会定期检查该标识，来决定是否关闭服务器    管理客户端资源
  管理数据库资源
  执行延迟的BGREWRITAOF
 BGSAVE期间，会阻塞GBWRITEAOF    检测持久化操作的允许状态</description>
    </item>
    
    <item>
      <title>redis常见问题</title>
      <link>http://nber1994.github.io/posts/redis%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</guid>
      <description> redis有哪些数据结构 redis分布式锁  scan命令 pipline和batch 数据淘汰策略 一致性hash  </description>
    </item>
    
    <item>
      <title>redis应用场景</title>
      <link>http://nber1994.github.io/posts/redis%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</guid>
      <description>127.0.0.1:6379&amp;gt; select 1 OK 字符串对象 常用命令 # 字符串对象  ## 设置 127.0.0.1:6379[1]&amp;gt; set a a OK ## 获取 127.0.0.1:6379[1]&amp;gt; get a &amp;#34;a&amp;#34; ## 删除 127.0.0.1:6379[1]&amp;gt; del testString (integer) 1 ## 设置并返回原值 127.0.0.1:6379[1]&amp;gt; get b &amp;#34;b&amp;#34; 127.0.0.1:6379[1]&amp;gt; getset b c &amp;#34;b&amp;#34; ## 增加 减少，追加 127.0.0.1:6379[1]&amp;gt; set testInt 1 OK 127.0.0.1:6379[1]&amp;gt; incr testInt (integer) 2 127.0.0.1:6379[1]&amp;gt; decr testInt (integer) 1 127.0.0.1:6379[1]&amp;gt; append a a (integer) 2 127.0.0.1:6379[1]&amp;gt; get a &amp;#34;aa&amp;#34; 127.0.0.1:6379[1]&amp;gt; incrby int 2 (integer) 3 127.</description>
    </item>
    
    <item>
      <title>redis数据结构--简单动态字符串</title>
      <link>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%80%E5%8D%95%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%80%E5%8D%95%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2/</guid>
      <description>redis自己构建了简单的字符串结构，c语言的字符串类型只用于一些字面量展示 SDS还被用于缓冲区，AOF模块的缓冲区就是SDS实现的
struct sdshdr { //记录buf已经使用的长度  int len; //记录buf数组未使用的字节数量  int free; //字节数组，用于保存字符串  char buf[]; } SDS通用遵循着\0结尾的方式，但是不会计入len，这样做的好处是可以使用部分C语言字符串函数
与c字符串的区别 常数复杂度的获取字符串长度  SDS获取字符串长度的时间复杂度是o(1) c字符串需要遍历所有的字符串O(n)  杜绝缓冲区溢出  c字符串由于不知道自己的长度，所以无法校验自身的长度，造成缓冲区溢出  对于SDS来说，每次append操作时，都会检查是否存在足够的空间，如果空间不够的话，则会提前分配空间  减少修改字符串带来的内存重新分配次数 c字符串存在的缺点： - 字符串拼接，如果不通过内存重分配扩展足够的空间，则会产生缓冲区溢出 - 字符串截断，如果不使用内存重新分配来释放字符串不用的空间的话，则会造成内存泄漏  对于c语言来说，偶尔的进行内存重新分配，其实是可以接受的，但是对于redis这种需要频繁修改的场景来说，内存重分配会占用一大部分时间，造成性能的降低
SDS的解决方案：  空间预分配 当需要对sds进行修改，并且需要对sds进行空间扩展时，  如果对SDS进行修改之后，SDS的大小小于1MB的话，则会给SDS分配相同大小的空闲空间， 即len和free相同 如果对SDS修改之后，SDS的大小大于1MB，则会给SDS分配1MB的空闲空间   在对SDS进行扩展操作时，会检查剩余空间是否足够，如果足够的话，则直接插入字符即可 这种空间与分配的策略，会将连续N次增长的情况下内存分配的次数从N次变为最多N次 惰性空间释放  对于SDS的字符串缩短操作，SDS并不会释放空闲出的空间，而是通过维护free，来等待将来的使用    二级制安全  c字符串使用\0表示字符串的结尾，这使得c字符串不能存储图像，音频视频等文件 而对于SDS来说，并不会对\0进行过滤截断等操作，所有的api都是用二进制的方法处理buf中的数据 即存入时是什么样，读取时就是什么样  兼容部分C字符串函数  由于SDS采用c语言的\0结尾的惯例，所以它可以使用一部分c语言字符串的处理函数  </description>
    </item>
    
    <item>
      <title>redis数据结构--链表</title>
      <link>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E9%93%BE%E8%A1%A8/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E9%93%BE%E8%A1%A8/</guid>
      <description> 链表提供了高效的节点重排的能力 顺序访问的能力 发布订阅，慢查询，监视器等都用到了链表  链表结构 typedef struct listNode { //前置节点  struct listNode *prev; //后置节点  struct listNode *next; //节点的值  void *value; } 多个listNode可以通过prev和next链接为双向链表 typdef struct list { //表头节点  listNode *head; //表尾节点  listNode *tail; //链表包含的节点数量  unsigned long len; //节点值复制函数  void *(*dup)(void *ptr); //节点值释放函数  void *(*free)(void *ptr); //节点值对比函数  void *(*match)(void *ptr， void *key); } redis链表实现的特性：  双端：每个节点都存在prev和next指针，获取某个节点前后指针为O(1) 无环：头节点和尾节点的prev和next为null，对链表的访问以null终止 带有表头和表尾指针，自带表头和表尾指针，查找表头和表尾指针为O(1) 待链表长度计数器：获取链表长度为O(1) 多态：链表的值为*void，而且可以通过绑定不同的dup，free，match函数，可以保存不同类型的值  重点回顾 </description>
    </item>
    
    <item>
      <title>redis数据结构-对象</title>
      <link>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%AF%B9%E8%B1%A1/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%AF%B9%E8%B1%A1/</guid>
      <description>redis并没有直接使用底层的数据结构，而是基于这些数据结构创建了一个对象系统 该系统包含了字符串对象，列表，hash表，集合，有序集合五种数据对象 带来的收益：  通过对象系统，可以在执行给出的命令来说，执行之前可以判断是否能执行该命令 同时可以根据不同的使用场景，来选择数据类型的不同的实现方式 通过引用计数，可以实现内存回收机制，当不再占用对象时，会对其回收。同时引用计数还可以实现对象共享，来节省内存 对象还记录了访问时间，以此来计算数据库键的空转时长    对象的类型与编码 当创建一个键值对时，至少会创建两个对象，一个是键的字符串对象，另一个是值的对象
typedef struct redisObject { //类型  unsigned type:4; //编码  unsigned encoding:4; //指向底层实现数据结构的指针  void *ptr; } robj; 类型 对象的type的值： 编码和底层实现 encoding来决定ptr指向哪种底层数据结构 不同的type对应的encoding  对于字符串对象，底层可以有三种实现方式，int，emstr和raw 对于列表对象，底层可以有链表，压缩表实现 对于hash表对象，底层可以有字典，压缩表实现 对于集合对象，底层可以有字典，整数集合实现 对于有序集合对象，底层可以有跳跃表，压缩表实现  不为某种对象绑定特定的数据结构，极大的提高了redis对象的灵活性
字符串对象  字符串对象可以有int，embstr和raw实现 当字符串的值可以用long类型标识时，字符串对象会使用int作为底层实现  ？？ 为什么  当字符串长度小于39字节时，采用embstr的方式来实现 当字符串长度大于39字节时，采用raw的方式来实现 为什么是39呢，因为redis采用的是jemalloc进行动态内存的申请，会申请8，16，32，64字节的内存，但是sds大小为33，而且redisObject为16字节，所以64-16-4-4-1 = 39   采用embstr的优势  embstr和raw的区别是，redisObject和SDS的内存地址是连续的，这样：  初始化时只需要一次内存分配 删除时也仅仅需要一次内存分配 由于是连续的，读取的时候只需要一次寻址，速度较快   embstr并没有实现操作函数，所以对embstr进行操作时，会先转化为raw再进行操作  ？？那为什么不都存为embstr 编码的转化 int编码和embstr编码有时会转化为raw，比如append命令</description>
    </item>
    
    <item>
      <title>redis数据结构-整数集合</title>
      <link>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%B4%E6%95%B0%E9%9B%86%E5%90%88/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%B4%E6%95%B0%E9%9B%86%E5%90%88/</guid>
      <description>一般集合键只保存整数且集合的大小不大时，采用整数集合作为其底层实现
结构 typedef struct intset { //编码方式  uint32_t encoding; //整数集合包含的元素数量  uint32_t length; //保存元素的数组  int8_t contents[]; } intset;  contents作为整数集合的底层实现，每个元素都是contents数组的一个项，各个节点从小到大排列，并且不会重复 contents的项的大小不一定为uint8_t，具体是根据encoding的值来决定  整数集合的升级  当整数集合中的添加的元素大于现有所有元素的类型都要长时，会将contents中元素的类型进行升级 步骤：  首先会根据新加入元素的大小为现有的元素重新分配数组代销 将原来的元素，通过类型转之后，放入新数组的对应位置 将新元素添加入新集合   因为每次新添加元素时，可能会发生升级，会遍历所有的元素进行类型转换，所有时间复杂度为O(n)  升级带来的好处  提高了灵活性，一般数组中我们都会存储相同类型的int值，集合添加元素时，我们不需要关心是插入uint64还是uint32，intset自动适类型的转化 节省了内存空间：当数组中不存在uint64的数时，没有比要把数组初始化为uint64-t类型，这样节约了空间  降级 整数集合不支持降级，整数一旦进行升级之后，不能进行降级
重点回顾 </description>
    </item>
    
    <item>
      <title>redis订阅</title>
      <link>http://nber1994.github.io/posts/redis%E8%AE%A2%E9%98%85/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E8%AE%A2%E9%98%85/</guid>
      <description> redis发布订阅相关的命令  publish，发布 subscribe，订阅 psubscribe，模式订阅    频道订阅和退订 struct redisServer { //保存所有频道的订阅关系  dict *publish_channels; }  频道的订阅信息由publish_channels保存  字典的键为频道名 字典的值为一个客户端的指针的链表     订阅频道 退订频道 模式的订阅和退订  所有模式订阅信息都保存在redsiServer中的pubsub_patterns属性里  struct redisServer { //保存所有模式订阅关系  list *pubsub_patterns; }  pubsub_patterns是一个链表，每个链表的节点结构为  struct pubsubPatterns { //订阅模式的客户端  redisClient *client; //被订阅的模式  robj *patterns; } 发送消息  publish channel message  首先将消息发送给channel的订阅者 表里pubsub_patterns列表，符合条件的客户端发送消息    重点回顾 </description>
    </item>
    
    <item>
      <title>redis问题</title>
      <link>http://nber1994.github.io/posts/redis%E9%97%AE%E9%A2%98/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E9%97%AE%E9%A2%98/</guid>
      <description>redis-问题 BRPOP，BLPOP
https://github.com/antirez/redis/issues/2576 why redis-cluster use 16384 slots? crc16() can have 2^16 -1=65535 different remainders。 原因是：
正常的心跳包携带节点的完整配置，可以用幂等方式替换旧节点以更新旧配置。这意味着它们包含原始形式的节点的插槽配置，它使用带有16k插槽的2k空间，但使用65k插槽将使用高达8k的空间。 同时，由于其他设计权衡，Redis Cluster不太可能扩展到超过1000个主节点。 因此，16k处于正确的范围内，以确保每个主站有足够的插槽，最多1000个主站，但足够小的数字可以轻松地将插槽配置传播为原始位图。请注意，在小型集群中，位图难以压缩，因为当N很小时，位图将设置插槽/ N位，这是设置的大部分位。</description>
    </item>
    
    <item>
      <title>redsi持久化-AOF</title>
      <link>http://nber1994.github.io/posts/redsi%E6%8C%81%E4%B9%85%E5%8C%96-aof/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redsi%E6%8C%81%E4%B9%85%E5%8C%96-aof/</guid>
      <description> redsi持久化-AOF
  除了RDB持久化之后，redis还提供了AOF持久化功能（append only file） AOF持久化使用过保存redis写命令来记录数据库状态的 在AOF文件中，除了指定数据库的select语句之外，其他的都是通过客户端发生的命令  AOF持久化实现  AOF持久化的实现是通过命令追加，文件写入，文件同步三个步骤实现的
 命令追加 struct redisServer { //aof缓冲区  sds aof_buf; }  在redisServer中保存了aof_buf的缓冲区，改缓冲区是由sds实现的 每次redis的写命令之后，都会讲命令追加到这个缓冲区中  文件写入和文件同步  对于redisserver来说，redis的服务进程就是一个事件循环 在每个时间循环的最后，都会调用flushAppendOnlyFile函数并评估是否需要将aof_buf中的内容写入文件 对于flushAppendOnlyFile函数来说，有三种行为：  现代操作系统中，文件写入操作并不会立即写入磁盘，而是会在文件缓存中，以一定频率写入到磁盘 默认是everysec，每次循环结束，会将aof_buf写入文件缓冲区，当上次flush时间已经距现在超过一秒，就将缓冲区同步到磁盘    文件同步的安全性  always 最多会丢失一个时间循环的命令 everysec 会丢失一秒的命令 no 以来操作系统何时将文件同步到磁盘  AOF的载入  当redis服务启动时，服务器会读入AOF文件，并还原数据库状态 步骤  由于命令需要运行在client的上下文，所以redis会创建一个伪客户端来执行命令 从AOF文件读取一行 伪客户端执行读出的命令 知道AOF被读完    AOF文件的重写  随着命令的执行，AOF文件会越来越大，会占用过多的服务器资源，如果不加以控制的话，会对宿主机造成影响 所以需要对AOF文件进行重写，redis服务器创建一个新的AOF文件替代就得AOF文件，两个文件包含的数据库状态完全相同，只是新的AOF文件不包含冗余的命令 实际上，redis并不会根据就得AOF文件进行重写，而是根据现有的数据库状态进行重写  后台重写任务  前台的AOF文件重写任务会带来大量的文件写入操作，所以导致单线程的redis阻塞 所以将AOF重写任务放入后台，bgRewriteAof会新起一个子进程来进行重写  这样在重写期间redis服务可以正常响应请求 而且相对于多线程来说，可以避免锁的使用    AOF重写缓冲区  后台重写任务期间，redis也会产生新的AOF文件，这一部分命令需要一块AOF重写缓冲区进行存储 在后台重写任务期间，redis服务器每条写命令执行完之后，会将命令分别写入AOF缓冲区和AOF重写缓冲区 当AOF重写完成之后，会想redis发送一个信号，父进程会将AOF重写缓冲区中的命令写入新的AOF文件中 之后原子性的将新的AOF文件替换就得AOF文件 整个过程中，只有信号处理函数会打断redis对请求的响应，其他都不会阻碍redis正常的响应  重点回顾 </description>
    </item>
    
    <item>
      <title>tcp怎么保证可靠传输</title>
      <link>http://nber1994.github.io/posts/tcp%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/tcp%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93/</guid>
      <description> 确认机制和超时重传  收到消息后会恢复ack来确认到达，如果一段时间后未收到ack则会重传   数据校验和  tcp的报文头有校验和，校验是否损坏   排序  接收方会根据顺序来进行排序，将先到的数据缓存起来，等待之前的包到达后才发送给应用   流量控制  可以根据接收方的接收能力来调整滑动窗口的大小   拥塞控制  当网络情况不好的时候，可以调整滑动窗口的大小来防止丢包    延伸  拆包和粘包 拆包就是说，发送方一次发送的数据，接收方可能两次才能收到  发送的大小大于了IP包的大小 发送过急，大于发送缓冲区剩余大小   粘包，接收方读取一次数据，接收到了发送方两次发送的内容  发送缓冲区未满，一次将多个包发出 接收太慢，缓冲区满了，一次读取多个包   解决方案  为每个包增加长度信息 将所有的包封装为固定长度 包之间设置边界    </description>
    </item>
    
    <item>
      <title>top命令</title>
      <link>http://nber1994.github.io/posts/top%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/top%E5%91%BD%E4%BB%A4/</guid>
      <description>任务队列信息 当前系统时间 系统累计运行时间 当前登录用户 活跃进程数1，5，15分钟 top - 11:47:19 up 298 days, 19:59, 1 user, load average: 0.99, 1.01, 1.03 进程信息 总共进程数 正在运行 休眠进程 停止进程 僵尸进程 Tasks: 175 total, 4 running, 170 sleeping, 1 stopped, 0 zombie CPU信息 用户态占用CPU百分比 内核态占用CPU百分比 改变过优先级的进程百分比 空闲百分比 IO等待百分比 硬中断 软中断 %Cpu(s): 15.9 us, 35.1 sy, 0.0 ni, 49.1 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st 内存状态 物理内存总量 空闲内存总量 使用内存总量 缓存的内存量 KiB Mem : 8009832 total, 225372 free, 662292 used, 7122168 buff/cache swap分区信息 交换区总量 空闲 使用 KiB Swap: 0 total, 0 free, 0 used.</description>
    </item>
    
    <item>
      <title>unix-hater-handbook</title>
      <link>http://nber1994.github.io/posts/unix-hater-handbook/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/unix-hater-handbook/</guid>
      <description>最近偶尔发现了一本书，叫做unix痛恨者指南。 用了这么久的unix（linus），似乎所有的程序员都在谈论unix（linux），但是却很少有人对unix提出质疑 偶尔读读这样的书也挺有意思的，某些点也引发了我对unix（linux）的思考
 UNIX痛恨者手册 第一章 UNIX——世界上第一个电脑病毒
“伯克利的两项最著名的产品是UNIX和LSD (一种毒品)，我想这不是巧合”
病毒依赖于微小的个体和强大的适应性得以生存。它们并不复杂：它们没有为呼吸，新 陈代谢，肌体活动等功能提供什么，只有足够的DNA或RNA以供繁衍。比如，肺炎病毒比 起它们入侵的细胞要小得多，但它们在每个肺炎流行季节都能够产生新的变种，造成无 数人死亡。
一个好病毒的特点是：
  个头小 病毒做的事情不多，所以不需要很大。有人认为病毒不是生物，只是一些有破坏性的酸 和蛋白质。
  可移植性 病毒经常变异，以便以不同的方式攻击不同的细胞。据说AIDS就是由猴子身上的病毒变 异而成的。
  耗尽寄主的资源
  快速变异
  UNIX具有以上所有优点。在它刚诞生时，很小，功能不多，缺乏真正操作系统所需要的 功能（如文件映射，告诉IO，健壮的文件系统，设备锁，合理的进程间通讯），它的移 植性很好。UNIX耗尽主机的资源，没有系统管理员的时时呵护，UNIX会不断恐慌，core dump，挂起。UNIX不断变异：同一个补丁在一个版本上工作，在另一个版本上就不行。
UNIX是有用户界面的计算机病毒。
标准化那些不一致的 “标准的伟大之处在于它可以有很多” &amp;mdash; Grace Murray Hopper
自从UNIX 80年代开始流行以来，UNIX厂商一直在努力进行UNIX标准化工作。SUN, IBM， HP和DEC在这个他们自己制造的难题上倾注了数百万美元。
为什么UNIX厂商不喜欢UNIX标准化?
许多用户受够了复杂繁多的UNIX，最终只好使用Windows，因为他们的这个UNIX无法支持 那个UNIX上的应用程序。
如果UNIX标准化了，谁还会买SUN的机器呢 第二章 欢迎新用户
欢迎新用户如同用一把上了六颗子弹的左轮枪玩俄罗斯轮盘赌
Ken Thompson 自己设计过一辆汽车。和其他车不同，它没有速度计、汽油计，也没有那 些愚蠢的指示灯讨司机的厌。如果司机犯了什么错误，仪表盘上就会出现一个大大的“ ？”。“有经验的司机，”Thompson说，“应该知道哪儿搞错了。”
计算机系统的新手需要一个友好的系统。至少，一个得体的系统会这样招待自己的客人 ：
与功能有逻辑关系的命令名 对危险命令的小心处理 一致的命令行为和命令行参数解析 易得和易读的在线文档 当命令失败时，给出可理解和有用的错误反馈
在建造UNIX的过程中，从没邀请过住户。来访的都是些戴着安全帽的建筑工人，被安插 在这个破木板房子的各个角落。不幸的是，不仅没有人性因素（human factors）工程师 的参与，而且住户的需要就从来没有被考虑过。所以抽水马桶、中央供暖、窗户等这些 方便设施在后期就很难再添加了。但是建筑师们仍然为UNIX的设计而骄傲，似乎他们并 不介意在一个没有烟火探测器的屋子里睡觉。</description>
    </item>
    
    <item>
      <title>二叉树</title>
      <link>http://nber1994.github.io/posts/%E4%BA%8C%E5%8F%89%E6%A0%91/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E4%BA%8C%E5%8F%89%E6%A0%91/</guid>
      <description>package main import ( &amp;#34;fmt&amp;#34; ) type TreeNode struct { Val int Left *TreeNode Right *TreeNode } type stack struct { BinTree []*TreeNode Top int } func (nodeStack *stack) push(node *TreeNode) { nodeStack.BinTree = append(nodeStack.BinTree, node) nodeStack.Top++ } func (nodeStack *stack) pop() *TreeNode { var res *TreeNode nodeStack.Top-- if nodeStack.Top &amp;lt; 0 { res = nil } else { res = nodeStack.BinTree[nodeStack.Top] } nodeStack.BinTree = nodeStack.BinTree[:nodeStack.Top] return res } func inorderTraversal1(root *TreeNode) []int { res := []int{} myStack := &amp;amp;stack{[]*TreeNode{}, 0} for nil !</description>
    </item>
    
    <item>
      <title>内存地址</title>
      <link>http://nber1994.github.io/posts/%E5%86%85%E5%AD%98%E5%9C%B0%E5%9D%80/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E5%86%85%E5%AD%98%E5%9C%B0%E5%9D%80/</guid>
      <description>os-大端小端  一个十六进制值为0x01234567 大端法就是数据的高位存在地址的低位 小端法就是数据的低位存在地址的高位 大端法比较适应阅读习惯  os-32&amp;amp;64位系统  32位指的是主线上一次可以传输的信息的位数,可以作为主存寻址地址 32位的机器大概可以存在2^32个地址，即2^32字节的内存（4GB） 64位的机器大概可以存2^64个字节（256TB）   基础知识  一个字节有一个地址，每个地址内的存储顺序是不变的 一个字节一个地址 1字节=8bit 可以容纳两个16进制的值  </description>
    </item>
    
    <item>
      <title>内核态用户态的转换</title>
      <link>http://nber1994.github.io/posts/%E5%86%85%E6%A0%B8%E6%80%81%E7%94%A8%E6%88%B7%E6%80%81%E7%9A%84%E8%BD%AC%E6%8D%A2/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E5%86%85%E6%A0%B8%E6%80%81%E7%94%A8%E6%88%B7%E6%80%81%E7%9A%84%E8%BD%AC%E6%8D%A2/</guid>
      <description>os-内核态用户态的转换  陷阱  如系统调用，会进入内核态执行系统命令   故障  缺页故障   中断  比如读取磁盘完毕以后，会发送中断信号，调用中断处理程序    </description>
    </item>
    
    <item>
      <title>分布式事务系统设计</title>
      <link>http://nber1994.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</guid>
      <description>分布式事务-掘金 分布式事务的解决方案有很多种， 一致性从强到弱，性能开销从从多到少：三阶段，二阶段，TCC，saga 一致性保障的基本思路，协调者掌握多个子流程的执行过程信息，协调者负责根据子流程执行信息作出决策
分布式事务产生的原因  不同的service节点  一个事务流程需要调用不同的服务执行不同的子任务   不同的resource节点  一个事务会调用不同的数据来源，例如mysql的分库操作    分布式事务的原则 CAP原则  CAP的解释  C 一致性原则，此处值得是读取到的数据都是事务完成之后和事务完成之前的数据，对于数据事务的中间状态时不可见的 A 可用性，非故障节点在合理的合理的时间内返回合理的响应 P 分区容错性，当出现网络分区后，仍能继续工作。例如某个节点故障了之后，集群仍能继续工作   对于CAP原则，P是大前提，因此CAP解释成，当P发生时，A和C只能选一个，假设节点1和节点2正好处于网络分区的两侧，例如节点1网络正常，而节点2网络故障。这时，一个事务请求到达集群，节点2一定是不能正常处理的，节点1对于该事务请求  如果节点1也对该事务不执行，这保证了C，但是违背了A 如果节点1对该事务执行，这保证了A，但是违背了C    BASE原则  BASE指的是，基本可用，软状态和最终一致性，是对AP的一种扩展 BASE允许存在中间状态，牺牲了一致性而保证了可用性，但是必须是强一致的状态  解决方案 2PC 两阶段提交协议  存在一个协调者，多个参与者 步骤：  第一阶段：  协调者想参与者发出投票，等待各个参与者的响应 各个参与者执行事务，并写入redo log和undo log（此时资源还未释放） 参与者响应协调者发起的投票，若事务执行成功，则响应同意，若执行失败，则响应终止   第二阶段  当所有的参与者都同意时，  协调者向参与者发送正式提交的请求 参与者收到后，完成事务的提交，并释放占用的资源 向协调者发送完成响应 协调者收到所有完成响应后，完成事务   当存在终止响应时，  协调者向参与者发出回滚请求 参与者利用undo log将事务回滚，并释放资源 参与者向协调者发送回滚完成 协调者等待所有的回滚完成后，结束事务       会存在很多的问题  所有参与者对资源的占用都是阻塞的 协调者要对参与者设定超时机制 太依赖协调者，一旦宕机，会导致整个事务阻塞    3PC 三阶段提交协议  引入超时机制，同时将准备阶段一分为二 步骤  canCommit  协调者向参与者发送canCommit请求，并等待响应 参与者接收到请求后，如果认为自己可以执行，则返回YES，否则NO   preCommit  如果参与者响应都是YES  向参与者发送preCommit请求 参与者进行事务的执行，并进行redo log，undo log的落地 如果成功执行了指令，则返回ack响应，同时开始等待最终指令   如果存在一个NO，或者存在超时  向参与者发送中断请求 参与者接收到了abort请求之后，或则超时未收到协调者的请求，会将事务中断     doCommit  若接收到了所有参与者的ack之后，  向所有的参与者发送doCommit请求 参与者接收到了请求后，执行事务并释放资源，发送ack给协调者 协调者接收到所有的ack之后，完成事务   若未收到所有的ack或者存在超时响应  向所有的参与者发送abort请求 参与者收到后根据之前的undo log进行回滚操作，并释放所有资源 想协调者发送ack响应 协调者收到ack后，终止事务        TCC模型 （两阶段型，补偿型）  TCC为Try Confirm Cancel  Try尝试待执行的业务  并未执行业务，只进行一致性检查，但是预留资源   Confirm执行业务  直接执行，使用第一步预留的资源   Cancel取消执行的业务  如果业务失败，则进行资源的回滚，释放占用资源     TCC必须基于本地事务 必须提供幂等性保障  会存在一些超时重试补偿机制    saga模型  每个Saga由一系列sub-transaction Ti 组成 每个Ti 都有对应的补偿动作Ci，补偿动作用于撤销Ti造成的结果,这里的每个T，都是一个本地事务。 可以看到，和TCC相比，Saga没有“预留 try”动作，它的Ti就是直接提交到库。 Saga的执行顺序有两种：  T1, T2, T3, &amp;hellip;, Tn T1, T2, &amp;hellip;, Tj, Cj,&amp;hellip;, C2, C1，其中0 &amp;lt; j &amp;lt; n   Saga定义了两种恢复策略：  向后恢复，即上面提到的第二种执行顺序，其中j是发生错误的sub-transaction，这种做法的效果是撤销掉之前所有成功的sub-transation，使得整个Saga的执行结果撤销。 向前恢复，适用于必须要成功的场景，执行顺序是类似于这样的：T1, T2, &amp;hellip;, Tj(失败), Tj(重试),&amp;hellip;, Tn，其中j是发生错误的sub-transaction。该情况下不需要Ci。   这里要注意的是，在saga模式中不能保证隔离性，因为没有锁住资源，其他事务依然可以覆盖或者影响当前事务。   还是拿100元买一瓶水的例子来说，这里定义 T1=扣100元 T2=给用户加一瓶水 T3=减库存一瓶水 C1=加100元 C2=给用户减一瓶水 C3=给库存加一瓶水 我们一次进行T1,T2，T3如果发生问题，就执行发生问题的C操作的反向。 上面说到的隔离性的问题会出现在，如果执行到T3这个时候需要执行回滚，但是这个用户已经把水喝了(另外一个事务)，回滚的时候就会发现，无法给用户减一瓶水了。这就是事务之间没有隔离性的问题</description>
    </item>
    
    <item>
      <title>分布式锁系统设计</title>
      <link>http://nber1994.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</guid>
      <description>分布式锁的一些原则  互斥性 最基本的 可重入性 同一个节点对于同一资源可以多次获取 锁超时 避免死锁  常见实现方式  mysql redis  mysql实现 CREATE TABLE `resourceLock` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `resource_name` varchar(128) NOT NULL DEFAULT &amp;#39;&amp;#39; COMMENT &amp;#39;资源名字&amp;#39;, `node_info` varchar(128) DEFAULT NULL COMMENT &amp;#39;节点信息&amp;#39;, `count` int(11) NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;锁的次数 （可重入）&amp;#39;, `desc` varchar(128) DEFAULT NULL COMMENT &amp;#39;资源描述&amp;#39;, `mtime` timestamp NULL DEFAULT NULL, `ctime` timestamp NULL DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `uniq_resource` (`resource_name`) ) ENGINE=InnoDB DEFAULT CAHRSET=utf8mb4; 加锁 查询xxx资源是否是当前节点所有，如果有的话则增加count</description>
    </item>
    
    <item>
      <title>剑指offer</title>
      <link>http://nber1994.github.io/posts/%E5%89%91%E6%8C%87offer/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E5%89%91%E6%8C%87offer/</guid>
      <description>题目列表，当做一个速查列表好了，具体代码就不放了:P
 链表-8道： 剑指Offer（三）：从尾到头打印链表 剑指Offer（十四）：链表中倒数第k个结点 剑指Offer（十五）：反转链表 剑指Offer（十六）：合并两个排序的链表 剑指Offer（二十五）：复杂链表的复制  第一步：复制复杂指针的label和next。但是这次我们把复制的结点跟在元结点后面，而不是直接创建新的链表； 第二步：设置复制出来的结点的random。因为新旧结点是前后对应关系，所以也是一步就能找到random； 第三步：拆分链表。奇数是原链表，偶数是复制的链表。   剑指Offer（三十六）：两个链表的第一个公共结点  方法一：  我们可以把两个链表拼接起来，一个pHead1在前pHead2在后，一个pHead2在前pHead1在后。这样，生成了两个相同长度的链表，那么我们只要同时遍历这两个表，就一定能找到公共结点。时间复杂度O(m+n)，空间复杂度O(m+n)。    方法二：  我们也可以先让把长的链表的头砍掉，让两个链表长度相同，这样，同时遍历也能找到公共结点。此时，时间复杂度O(m+n)，空间复杂度为O(MAX(m,n))。    剑指Offer（五十五）：链表中环的入口结点 剑指Offer（五十六）：删除链表中重复的结点 二叉树(12道)： 剑指Offer（四）：重建二叉树 剑指Offer（十七）：树的子结构 剑指Offer（十八）：二叉树的镜像 剑指Offer（二十二）：从上往下打印二叉树 剑指Offer（二十四）：二叉树中和为某一值的路径 剑指Offer（三十八）：二叉树的深度 剑指Offer（三十九）：平衡二叉树 剑指Offer（五十七）：二叉树的下一个结点 剑指Offer（五十八）：对称的二叉树 剑指Offer（五十九）：按之字顺序打印二叉树 剑指Offer（六十）：把二叉树打印成多行 剑指Offer（六十一）：序列化二叉树 二叉搜索树(3道)： 剑指Offer（二十三）：二叉搜索树的后序遍历序列 剑指Offer（二十六）：二叉搜索树与双向链表 剑指Offer（六十二）：二叉搜索树的第k个结点 数组(11道)： 剑指Offer（一）：二维数组中的查找 剑指Offer（六）：旋转数组的最小数字 剑指Offer（十三）：调整数组顺序使奇数位于偶数前面 剑指Offer（二十八）：数组中出现次数超过一半的数字 剑指Offer（三十）：连续子数组的最大和 剑指Offer（三十二）：把数组排成最小的数 剑指Offer（三十五）：数组中的逆序对 剑指Offer（三十七）：数字在排序数组中出现的次数 剑指Offer（四十）：数组中只出现一次的数字 剑指Offer（五十）：数组中重复的数字 剑指Offer（五十一）：构建乘积数组 字符串(8道)： 剑指Offer(二)：替换空格 剑指Offer（二十七）：字符串的排列 剑指Offer（三十四）：第一个只出现一次的字符 剑指Offer（四十三）：左旋转字符串 剑指Offer（四十四）：翻转单词顺序序列 剑指Offer（四十九）：把字符串转换成整数 剑指Offer（五十二）：正则表达式匹配 剑指Offer（五十三）：表示数值的字符串 栈(3道)： 剑指Offer（五）：用两个栈实现队列 剑指Offer（二十）：包含min函数的栈 剑指Offer（二十一）：栈的压入、弹出序列 递归(4道)： 剑指Offer（七）：裴波那契数列 剑指Offer（八）：跳台阶 剑指Offer（九）：变态跳台阶 剑指Offer（十）：矩形覆盖 回溯法(2道)： 剑指Offer（六十五）：矩阵中的路径 剑指Offer（六十六）：机器人的运动范围 其他(15道)： 剑指Offer（十一）：二进制中1的个数 剑指Offer（十二）：数值的整数次方 剑指Offer（十九）：顺时针打印矩阵 剑指Offer（二十九）：最小的K个数 剑指Offer（三十一）：整数中1出现的次数（从1到n整数中1出现的次数） 剑指Offer（三十三）：丑数 剑指Offer（四十一）：和为S的连续正数序列 剑指Offer（四十二）：和为S的两个数字 剑指Offer（四十五）：扑克牌顺子 剑指Offer（四十六）：孩子们的游戏（圆圈中最后剩下的数） 剑指Offer（四十七）：求1+2+3+…+n 剑指Offer（四十八）：不用加减乘除的加法 剑指Offer（五十四）：字符流中第一个不重复的字符 剑指Offer（六十三）：数据流中的中位数 剑指Offer（六十四）：滑动窗口的最大值</description>
    </item>
    
    <item>
      <title>小猫咪</title>
      <link>http://nber1994.github.io/posts/%E5%B0%8F%E7%8C%AB%E5%92%AA/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E5%B0%8F%E7%8C%AB%E5%92%AA/</guid>
      <description></description>
    </item>
    
    <item>
      <title>排序</title>
      <link>http://nber1994.github.io/posts/%E6%8E%92%E5%BA%8F/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E6%8E%92%E5%BA%8F/</guid>
      <description>各个算法的比较 归并排序  将数组打散为两两一组，两两一组进行排序，然后将各个组进行合并    把 n 个记录看成 n 个长度为1的有序子表； 进行两两归并使记录关键字有序，得到 n/2 个长度为 2 的有序子表； 重复第2步直到所有记录归并成一个长度为 n 的有序表为止。  归并排序非递归思路 按照先分组再合并的思路，我们设置一个逐渐变大的间隔，然后按照间隔来讲数据进行分组，并进行归并  我们可以先将一个无序数组A，按照2位单位，分成诸多长度为2的子数组：
如下：
假如有数组A：[2 ,1 ,5 ,9 ,0 ,6 ,8 ,7 ,3]
可以分成以下长度为1的子数组：
{2}、{1}、{5}、{9}、{0}、{6}、{8}、{7}、{3}
那么对这9个子数组进行归并排序，也即使用上面提到的代码进行排序，那么就可以得到 {1,2}、{5,9}、{0,6}、{7,8}、{3} 这样我们就有5个有序的子数组了，再讲这五个子数组两两归并，即得到： {1,2,5,9}、{0,6,7,8}、{3} 就这样依次归并下去，即得到一个有序的数组B {0 ,1 ,2 ,3 ,5 ,6 ,7 ,8 ,9}
 package main import &amp;#34;fmt&amp;#34; func main() { test_arr := []int{1, 7, 6, 1, 1, 2, 9, 5, 9, 1, 9} fmt.</description>
    </item>
    
    <item>
      <title>操作系统资源链接</title>
      <link>http://nber1994.github.io/posts/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%B5%84%E6%BA%90%E9%93%BE%E6%8E%A5/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%B5%84%E6%BA%90%E9%93%BE%E6%8E%A5/</guid>
      <description>栈的主要功能是实现函数调用 栈的主要功能是实现函数的调用。因此在介绍栈溢出原理之前，需要弄清函数调用时栈空间发生了怎样的变化。每次函数调用时，系统会把函数的返回地址（函数调用指令后紧跟指令的地址），一些关键的寄存器值保存在栈内，函数的实际参数和局部变量（包括数据、结构体、对象等）也会保存在栈内。这些数据统称为函数调用的栈帧，而且是每次函数调用都会有个独立的栈帧，这也为递归函数的实现提供了可能。
http://www.feemic.cn/mooc/icourse163/1002692015 李志军老哥讲义
栈的主要功能是实现函数的调用。因此在介绍栈溢出原理之前，需要弄清函数调用时栈空间发生了怎样的变化。每次函数调用时，系统会把函数的返回地址（函数调用指令后紧跟指令的地址），一些关键的寄存器值保存在栈内，函数的实际参数和局部变量（包括数据、结构体、对象等）也会保存在栈内。这些数据统称为函数调用的栈帧，而且是每次函数调用都会有个独立的栈帧，这也为递归函数的实现提供了可能。
https://www.jianshu.com/p/c1015f5ffa74 https://www.jianshu.com/p/486b0965c296 https://www.jianshu.com/p/aed6067eeac9 阻塞&amp;amp;IO模型
https://blog.csdn.net/u013309870/article/details/75193592 动态规划 http://www.hawstein.com/posts/dp-novice-to-advanced.html 动态规划 https://blog.csdn.net/luyafei_89430/article/details/12971171 进程调度算法
￼ http://blog.codepiano.com/2017/03/01/read-file-from-disk 读写磁盘
￼</description>
    </item>
    
    <item>
      <title>数组</title>
      <link>http://nber1994.github.io/posts/%E6%95%B0%E7%BB%84/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E6%95%B0%E7%BB%84/</guid>
      <description>package main import ( &amp;#34;fmt&amp;#34; &amp;#34;sort&amp;#34; ) func main() { fmt.Println(twoSum1([]int{2, 11, 7, 15}, 9)) fmt.Println(twoSum2([]int{2, 11, 7, 15}, 9)) } //两数之和 //给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。 // //你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。 // //示例: // //给定 nums = [2, 7, 11, 15], target = 9 // //因为 nums[0] + nums[1] = 2 + 7 = 9 //所以返回 [0, 1] //两个指针向中间逼近 func twoSum1(nums []int, target int) []int { lens := len(nums) oldNums := make([]int, lens) copy(oldNums[:], nums) left := 0 right := lens - 1 sortedNums := sort.</description>
    </item>
    
    <item>
      <title>文本处理命令</title>
      <link>http://nber1994.github.io/posts/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4/</guid>
      <description>统计日志中出现最多的IP grep -i -o -E &amp;#39;([0-9]{1,3}\.){3}[0-9]{1,3}&amp;#39; log.log | sort -n | uniq -c | sort -n -r | head -10   grep
 -i 忽略大小写 -o 输出匹配部分 -E 正则表达式    sort
 -n 数值排序 -r 倒叙排序    uniq
 -c 显示重复次数    head
 -n 显示前n行    awk命令 log内容
root:x:0:0:root:/root:/usr/bin/zsh daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin bin:x:2:2:bin:/bin:/usr/sbin/nologin sys:x:3:3:sys:/dev:/usr/sbin/nologin sync:x:4:65534:sync:/bin:/bin/sync # awk命令结构 awk 选项 &amp;#39;条件 动作&amp;#39; 文件 # 例如 awk &amp;#39;{print $0}&amp;#39; log  $0 表示当前行 $n 表示按照分隔符切割后的第几个（默认是空格，制表符） NF 分割了多少个字段 $(NF-n)倒数第几个 -F 设置分隔符  awk -F &amp;#39;:&amp;#39; &amp;#39;{print $0}&amp;#39; log  NR 当前行  awk &amp;#39;{print NR &amp;#34;)&amp;#34; $1}&amp;#39; log 1) root 2) daemon 3) bin 4) sys 5) sync  函数  tolower()：字符转为小写。 length()：返回字符串长度。 substr()：返回子字符串。 rand()：随机数。   条件  $ awk -F &amp;#39;:&amp;#39; &amp;#39;/usr/ {print $1}&amp;#39; demo.</description>
    </item>
    
    <item>
      <title>栈</title>
      <link>http://nber1994.github.io/posts/%E6%A0%88/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E6%A0%88/</guid>
      <description>package main import &amp;#34;fmt&amp;#34; func main() { a := &amp;amp;TreeNode{7, nil, nil} b := &amp;amp;TreeNode{3, nil, nil} c := &amp;amp;TreeNode{15, nil, nil} d := &amp;amp;TreeNode{9, nil, nil} e := &amp;amp;TreeNode{20, nil, nil} a.Left = b a.Right = c c.Left = d c.Right = e obj := Constructor(a) for obj.HasNext() { fmt.Println(obj.Next()) } } type TreeNode struct { Val int Left *TreeNode Right *TreeNode } //实现一个二叉搜索树迭代器。你将使用二叉搜索树的根节点初始化迭代器。 // //调用 next() 将返回二叉搜索树中的下一个最小的数。 // //BSTIterator iterator = new BSTIterator(root); //iterator.</description>
    </item>
    
    <item>
      <title>短连接系统设计</title>
      <link>http://nber1994.github.io/posts/%E7%9F%AD%E8%BF%9E%E6%8E%A5%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E7%9F%AD%E8%BF%9E%E6%8E%A5%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</guid>
      <description>要求  尽可能的短  方案 短网址的长度  我们可以用英文字母和数字来组合，一共有62种，所以长度为n的短网址的个数为62^n 我们选用7 远远大于互联网的所有连接的总和 我们选用长度为7的连接，由大小写字母和数字组成  一对一还是一对多映射 原网址对应多个短网址，一个短网址的记录会包含诸如访问用户，http的user-agent信息等
以供后续做大数据分析，挖掘数据的价值
如何计算短网址 假设我们的短网址服务是一个7长度的，我们如何计算得到这个短网址呢？
最容易想到的就是使用一个64位整数来通过62位进制的转换来获取，怎么生成这个整数，则就需要用到发号器
怎么存储 存储可以使用mysql和redis都可
跳转301或者302 301永久重定向，短网址会永久重定向到原网址，这对于搜索引擎来说会直接展示原网址
所以使用302临时重定向
预防攻击  hacker短时间内向tinyUrl服务发送请求，会迅速消耗光url  每个ip限制单日请求数量，每个ip每天分配的短url有上限   hacker使用大量肉鸡来进行攻击  redis作为缓存，存储长连接与ID的关系，使用LRU来维护，遇到相同的url直接返回id    参考  短url-知乎 tinyUrl  </description>
    </item>
    
    <item>
      <title>缓存和DB的数据一致性系统设计</title>
      <link>http://nber1994.github.io/posts/%E7%BC%93%E5%AD%98%E5%92%8Cdb%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E7%BC%93%E5%AD%98%E5%92%8Cdb%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</guid>
      <description> 这个问题给我印象很深
 引用  缓存和DB一致性  </description>
    </item>
    
    <item>
      <title>缓存的常见问题</title>
      <link>http://nber1994.github.io/posts/%E7%BC%93%E5%AD%98%E7%9A%84%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E7%BC%93%E5%AD%98%E7%9A%84%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</guid>
      <description> 缓存常见的问题  缓存穿透 缓存雪崩 缓存击穿（热点key）    缓存穿透 现象 缓存穿透问题是指，请求了一个一定不会请求到的数据，这个时候，一定会穿透缓存到达DB，如果量十分大的话，会对DB性能造成影响（攻击）
解决  使用布隆过滤器，添加入所有的可能查询，对请求进行过滤，如果不存在的直接过滤 空值缓存，对于拿到为空的请求，加入缓存设置空值，并给与很短的失效时间，因为可能这个值不一定是攻击，故不必存储太久  缓存雪崩 现象 缓存在同一时间大量失效，DB可能在突增的压力下崩溃
解决  使用互斥锁来保证只有单个线程可以对DB进行请求，该方法会降低QPS 种缓存时将超时时间错开，可以随机加一个秒数  缓存击穿（热点key） 现象 对于一些热点key，在他失效的那一段时间内，会有大量的请求走DB，对DB造成很大的压力
解决方案  二级缓存，不同等级的缓存设置不同的失效时间 互斥锁，限制只有一个线程对DB进行请求 永不过期，后台异步线程去定时的刷新缓存  </description>
    </item>
    
    <item>
      <title>缓存管理策略</title>
      <link>http://nber1994.github.io/posts/%E7%BC%93%E5%AD%98%E7%AE%A1%E7%90%86%E7%AD%96%E7%95%A5/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E7%BC%93%E5%AD%98%E7%AE%A1%E7%90%86%E7%AD%96%E7%95%A5/</guid>
      <description>LRU算法  最近最少使用算法，一般使用一个链表，最新访问的数据会移动至首部，当链表到达容量时淘汰尾部的节点  LRU-K  相对于LRU，多了一个记录访问次数的链表，这个链表里记录的是每个key对应的访问次数，当访问次数达到k时，才会到达LRU链表中 这个设计保证了偶然的数据访问造成命中率降低，如果某个数据到达尾部即将被淘汰，此时有一个请求，使之到达首部，但是后续可能再没有访问   实施流程  当有访问来时，左边链表会记录每个key被访问的次数，并且按照FIFO淘汰 当某个值访问次数达到了K，会将该key移动到右边的LRU队列 当右边的某个key被访问后，移动至队列首部 当队列满后，淘汰对尾的key    LFU  最近最长使用，使用的频率越高，越排在队列前面，当队列满了之后淘汰对尾元素   步骤  新数据进入队列，引用计数为1，重新排列队列 如果相同的引用计数，则按照时间排序 整体按照引用计数排序    </description>
    </item>
    
    <item>
      <title>网络分层</title>
      <link>http://nber1994.github.io/posts/%E7%BD%91%E7%BB%9C%E5%88%86%E5%B1%82/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E7%BD%91%E7%BB%9C%E5%88%86%E5%B1%82/</guid>
      <description>分层以及对应关系  应用层  应用层 表示层 会话层   传输层  传输层   网络层  网络层   物理层  数据链路层 物理层     tcp包的结构  每一层都会在首部添加本层的数据结构  以太网首部  mac地址   ip首部  IP地址   tcp首部  端口号       </description>
    </item>
    
    <item>
      <title>网络基础知识</title>
      <link>http://nber1994.github.io/posts/%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</guid>
      <description> 协议的分层  osi分层  应用层  实现针对特定应用的协议   表示层  特定数据格式和网络通用格式的转换   会话层  通信管理，负责建立和断开通信连接   传输层  管理两个节点之间的数据传输，负责可靠传输   网络层  负责目标寻址和路由   数据链路层  互联设备之间的数据传输   物理层  负责0，1和电压高低之间的转换        osi中的每一层，都附上本层的首部，同时接收方读取本层的首部  网络层中传输方式-面向有连接和面向无连接  面向有链接，则会在通信之前首先建立一条通信连接  电路交换与分组交换  电路交换会在两个互相通信的节点之间独占一条电路，其他电路只有等到该节点之间通信完成后再进行通信 分组交换就是让所有计算机上的数据分为包，按照顺序发送，这样所有计算机都可以同时发送数据包  按照目标端数量分类  单播  一对一   广播  发送到所有与之相连的主机   多播  发送到多个满足一定条件的主机   任播  从满足条件的主机中任意选出一个    </description>
    </item>
    
    <item>
      <title>进程</title>
      <link>http://nber1994.github.io/posts/%E8%BF%9B%E7%A8%8B/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E8%BF%9B%E7%A8%8B/</guid>
      <description>进程和线程之间的区别： 进程之间的关系
进程经典定义 一个执行中程序的实例
进程上下文  同时进程运行依赖其进程运行时的上下文，上下文包括其  代码和数据 打开的文件描述符表 环境变量 运行时栈 通用目的寄存器     进程提供的假象 一个独立的逻辑控制流，好像是独占cpu 一个独立的地址空间，好像是独占主存
并发流 多任务也叫时间分片。每个进程执行它部分逻辑流的一段时间叫做时间分片
私有地址空间 一个进程的常见内存情况  代码段总是从地址0x400000开始的，然后是数据段，然后是堆 内存最高位则是内核内存空间，用户栈是从2^48-1处开始向下延伸的 在用户栈和堆之间存在一块为共享库分配的内存空间  用户模式和内核模式  操作系统必须限制一个进程可以执行的指令和可以访问的内存空间，这种功能是通过控制某个模式位实现的 当设置了模式位时，进程就会运行在内核模式中 进程从用户态进入内核态的唯一方法是诸如中断，陷阱，故障这样的异常 当异常发生时，异常处理程序就会把模式位置为内核模式，当返回到用户程序时，处理器会将模式位置为用户位  调度  内核决定抢占当前进程，并重新开始一个之前被抢占的进程，叫做调度 调度是通过切换进程运行的上下文来进行的  保存当前进程的上下文 恢复新进程的上下文环境 将控制权移交给新的进程    调度的原因  阻塞：如果一个进程因为等待某个事件发生，如读取磁盘，内核可以让进程休眠，切换到另一个进程 中断：所有的机器都有产生周期性定时器中断的机制，通常为1毫秒或10毫秒，定时器终端时，内核可以进行进程调度  一个因为读取磁盘的调度实例  初始时，进程A运行在用户模式，进程调用read命令时，进程A会从用户态切换到内核态，同时内核会把A的内核态切换到B的内核态进程，然后再运行在B的用户态执行 同时陷阱处理程序会通过DMA，不经过cpu，直接将数据从磁盘读取到内存中，读取完毕后，磁盘控制器会向cpu发送一个中断信息 当内核觉得进程B已经执行了足够长的时间时，内核通过切换上下文，将控制权移交给A进程，同时从read的之后的指令开始执行  进程的三种状态  运行 正在cpu执行，或者在等待被执行且最终会被执行 停止 进程执行被挂起，且不会被调度。 终止 进程永远的停止了 三种终止原因：1.收到一个信号 2.从主程序返回 3.exit函数退出  创建子进程  父进程创建子进程时，会拥有和父进程相同的代码段，数据段和用户栈以及文件描述符表 父进程和子进程最大的区别就是PID是不同的  回收子进程  当一个子进程由于某种原因终止时，内核并不会把它立即从系统中清除，而是保持在终止状态下，指到父进程回收 一个已经终止了，但是还未被回收的进程成为僵尸进程 当父进程终止了，内核会安排init进程作为他的孤儿子进程的养父，init进程的PID为1  一号进程是在系统启动时创建的    信号  传送信号到目的进程，分为两个步骤  发送信号 内核通过更新目的进程上下文的某个状态，发送一个信号给目的进程   发送信号的原因有两种： 1.</description>
    </item>
    
    <item>
      <title>进程间通信IPC</title>
      <link>http://nber1994.github.io/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc/</guid>
      <description>进程间通信（IPC，InterProcess Communication）是指在不同进程之间传播或交换信息。IPC的方式通常有管道（包括无名管道和命名管道）、消息队列、信号量、共享存储、Socket、Streams等。其中 Socket和Streams支持不同主机上的两个进程IPC。
 一、管道  管道，通常指无名管道，是 UNIX 系统IPC最古老的形式。  1、特点：   它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端。
  它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）。
  它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。
  2、原型： #include &amp;lt;unistd.h&amp;gt;int pipe(int fd[2]); // 返回值：若成功返回0，失败返回-1 当一个管道建立时，它会创建两个文件描述符：fd[0]为读而打开，fd[1]为写而打开。如下图： 要关闭管道只需将这两个文件描述符关闭即可。
3、例子   单个进程中的管道几乎没有任何用处。所以，通常调用 pipe 的进程接着调用 fork，这样就创建了父进程与子进程之间的 IPC 通道。如下图所示：   若要数据流从父进程流向子进程，则关闭父进程的读端（fd[0]）与子进程的写端（fd[1]）；反之，则可以使数据流从子进程流向父进程。
  #include&amp;lt;stdio.h&amp;gt;#include&amp;lt;unistd.h&amp;gt; int main() { int fd[2]; // 两个文件描述符 	pid_t pid; char buff[20]; if(pipe(fd) &amp;lt; 0) // 创建管道 	printf(&amp;#34;Create Pipe Error!\n&amp;#34;); if((pid = fork()) &amp;lt; 0) // 创建子进程 	printf(&amp;#34;Fork Error!</description>
    </item>
    
    <item>
      <title>链表</title>
      <link>http://nber1994.github.io/posts/%E9%93%BE%E8%A1%A8/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E9%93%BE%E8%A1%A8/</guid>
      <description>package main import &amp;#34;fmt&amp;#34; func main() { a := &amp;amp;ListNode{1, nil} b := &amp;amp;ListNode{4, nil} c := &amp;amp;ListNode{5, nil} d := &amp;amp;ListNode{1, nil} e := &amp;amp;ListNode{3, nil} f := &amp;amp;ListNode{4, nil} g := &amp;amp;ListNode{2, nil} h := &amp;amp;ListNode{6, nil} a.Next = b b.Next = c d.Next = e e.Next = f g.Next = h lists := []*ListNode{a, d, g} res := mergeKLists(lists) for res != nil { fmt.Println(res.Val) res = res.</description>
    </item>
    
    <item>
      <title>顿悟</title>
      <link>http://nber1994.github.io/posts/%E9%A1%BF%E6%82%9F/</link>
      <pubDate>Fri, 05 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E9%A1%BF%E6%82%9F/</guid>
      <description>os-顿悟 一直以来一直在疑惑，unix中fork函数竟然是使用的是c的内置的函数，我就很搞不懂c语言和操作系统的关系，难道c语言编译器不是运行在操作系统里的吗？ 直到我找到了答案，编译器是早于操作系统的存在，早起的机器其实没有操作系统的概念，开机就是一个代码编译器 所以操作系统其实可以看做一个运行在c基础上的巨大的应用
有趣！ </description>
    </item>
    
    <item>
      <title>panic</title>
      <link>http://nber1994.github.io/posts/panic/</link>
      <pubDate>Wed, 26 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/panic/</guid>
      <description></description>
    </item>
    
    <item>
      <title>一切归零</title>
      <link>http://nber1994.github.io/posts/%E4%B8%80%E5%88%87%E5%BD%92%E9%9B%B6/</link>
      <pubDate>Thu, 20 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E4%B8%80%E5%88%87%E5%BD%92%E9%9B%B6/</guid>
      <description> 一切归零，从头开始
 </description>
    </item>
    
    <item>
      <title>leetcode-图</title>
      <link>http://nber1994.github.io/posts/%E5%9B%BE/</link>
      <pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E5%9B%BE/</guid>
      <description>表示方式 package main import ( &amp;#34;fmt&amp;#34; ) func main() { g := graph{} n1, n2, n3, n4, n5 := node{1}, node{2}, node{3}, node{4}, node{5} g.addNode(&amp;amp;n1) g.addNode(&amp;amp;n2) g.addNode(&amp;amp;n3) g.addNode(&amp;amp;n4) g.addNode(&amp;amp;n5) g.addEdge(&amp;amp;n1, &amp;amp;n2) g.addEdge(&amp;amp;n1, &amp;amp;n5) g.addEdge(&amp;amp;n2, &amp;amp;n3) g.addEdge(&amp;amp;n2, &amp;amp;n4) g.addEdge(&amp;amp;n2, &amp;amp;n5) g.addEdge(&amp;amp;n3, &amp;amp;n4) g.addEdge(&amp;amp;n4, &amp;amp;n5) g.string() g.BFS() g.DFS() } type node struct { val int } type graph struct { nodes []*node //使用邻接表来存储关系 	edges map[node][]*node } func (g *graph) addNode(n *node) { g.</description>
    </item>
    
    <item>
      <title>strace命令</title>
      <link>http://nber1994.github.io/posts/strace%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/strace%E5%91%BD%E4%BB%A4/</guid>
      <description>进程对用户来说就是一个黑盒，strace就是打开这个黑盒子的工具，可以解析出我们需要的调用
 使用实例 strace -tt -T -v -f -e trace=file -o /data/log/strace.log -s 1024 -p 23489  -tt 在每行输出的前面，显示毫秒级别的时间 -T 显示每次系统调用所花费的时间 -v 对于某些相关调用，把完整的环境变量，文件stat结构等打出来。 -f 跟踪目标进程，以及目标进程创建的所有子进程 -e 控制要跟踪的事件和跟踪行为,比如指定要跟踪的系统调用名称 -o 把strace的输出单独写到指定的文件 -s 当系统调用的某个参数是字符串时，最多输出指定长度的内容，默认是32个字节 -p 指定要跟踪的进程pid, 要同时跟踪多个pid, 重复多次-p选项即可。
 #跟踪nginx strace -tt -T -f -e trace=file -o /data/log/strace.log -s 1024 ./nginx # -e trace=file 显示和文件访问相关的调用 -e的拓展 要跟踪某个具体的系统调用，-e trace=xxx即可。但有时候我们要跟踪一类系统调用，比如所有和文件名有关的调用、所有和内存分配有关的调用。
如果人工输入每一个具体的系统调用名称，可能容易遗漏。于是strace提供了几类常用的系统调用组合名字。
 -e trace=file 跟踪和文件访问相关的调用(参数中有文件名) -e trace=process 和进程管理相关的调用，比如fork/exec/exit_group -e trace=network 和网络通信相关的调用，比如socket/sendto/connect -e trace=signal 信号发送和处理相关，比如kill/sigaction -e trace=desc 和文件描述符相关，比如write/read/select/epoll等 -e trace=ipc 进程见同学相关，比如shmget等</description>
    </item>
    
    <item>
      <title>linux常用命令</title>
      <link>http://nber1994.github.io/posts/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Mon, 03 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</guid>
      <description>top 任务队列信息 当前系统时间 系统累计运行时间 当前登录用户 活跃进程数1，5，15分钟 top - 11:47:19 up 298 days, 19:59, 1 user, load average: 0.99, 1.01, 1.03 进程信息 总共进程数 正在运行 休眠进程 停止进程 僵尸进程 Tasks: 175 total, 4 running, 170 sleeping, 1 stopped, 0 zombie CPU信息 用户态占用CPU百分比 内核态占用CPU百分比 改变过优先级的进程百分比 空闲百分比 IO等待百分比 硬中断 软中断 %Cpu(s): 15.9 us, 35.1 sy, 0.0 ni, 49.1 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st 内存状态 物理内存总量 空闲内存总量 使用内存总量 缓存的内存量 KiB Mem : 8009832 total, 225372 free, 662292 used, 7122168 buff/cache swap分区信息 交换区总量 空闲 使用 KiB Swap: 0 total, 0 free, 0 used.</description>
    </item>
    
    <item>
      <title>nginx网络模型的演变</title>
      <link>http://nber1994.github.io/posts/nginx%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%BC%94%E5%8F%98/</link>
      <pubDate>Fri, 31 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/nginx%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%BC%94%E5%8F%98/</guid>
      <description>nginx-网络模型的演变 网络模型的演变</description>
    </item>
    
    <item>
      <title>网络IO模型</title>
      <link>http://nber1994.github.io/posts/%E7%BD%91%E7%BB%9Cio%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Fri, 31 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E7%BD%91%E7%BB%9Cio%E6%A8%A1%E5%9E%8B/</guid>
      <description>IO多路复用 select、poll、epoll之间的区别总结[整理]  select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。 但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 关于这三种IO多路复用的用法，前面三篇总结写的很清楚，并用服务器回射echo程序进行了测试。连接如下所示：  select：http://www.cnblogs.com/Anker/archive/2013/08/14/3258674.html
poll：http://www.cnblogs.com/Anker/archive/2013/08/15/3261006.html
epoll：http://www.cnblogs.com/Anker/archive/2013/08/17/3263780.html
select实现  select的调用过程如下所示： （1）使用copy_from_user从用户空间拷贝fd_set到内核空间 （2）注册回调函数__pollwait （3）遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll,udp_poll或者datagram_poll） （4）以tcp_poll为例，其核心实现就是__pollwait，也就是上面注册的回调函数。 （5）__pollwait的主要工作就是把current（当前进程）挂到设备的等待队列中，不同的设备有不同的等待队列，对于tcp_poll来说，其等待队列是sk-&amp;gt;sk_sleep（注意把进程挂到等待队列中并不代表进程已经睡眠了）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒了。 （6）poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值。 （7）如果遍历完所有的fd，还没有返回一个可读写的mask掩码，则会调用schedule_timeout使调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间（schedule_timeout指定），还是没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有没有就绪的fd。 （8）把fd_set从内核空间拷贝到用户空间。  缺点 （1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 （2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大 （3）select支持的文件描述符数量太小了，默认是1024
poll实现 　poll的实现和select非常相似，只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构，其他的都差不多。
 关于select和poll的实现分析，可以参考下面几篇博文：  http://blog.csdn.net/lizhiguo0532/article/details/6568964#comments http://blog.csdn.net/lizhiguo0532/article/details/6568968 http://blog.csdn.net/lizhiguo0532/article/details/6568969 http://www.ibm.com/developerworks/cn/linux/l-cn-edntwk/index.html?ca=drs- http://linux.chinaunix.net/techdoc/net/2009/05/03/1109887.shtml    epoll 　epoll既然是对select和poll的改进，就应该能避免上述的三个缺点。那epoll都是怎么解决的呢？在此之前，我们先看一下epoll和select和poll的调用接口上的不同，select和poll都只提供了一个函数——select或者poll函数。而epoll提供了三个函数，epoll_create,epoll_ctl和epoll_wait，
 epoll_create是创建一个epoll句柄； epoll_ctl是注册要监听的事件类型； epoll_wait则是等待事件的产生。  epoll改进  对于第一个缺点，epoll的解决方案在epoll_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝一次。 对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用schedule_timeout()实现睡一会，判断一会的效果，和select实现中的第7步是类似的）。 对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。  代码对比 /*select的回调函数，将当前进程添加到fd的等待队列上 * 该函数可以看到，是初始化了一个entry的结构，在init_waitqueue_entry函数中，将当前进程设置为了该entry的私有值， * 并且在将唤醒函数绑定 */ static void __pollwait(struct file *filp, wait_queue_head_t *wait_address, poll_table *p) { struct poll_table_entry *entry = poll_get_entry(p); if (!</description>
    </item>
    
    <item>
      <title>进程平滑重启</title>
      <link>http://nber1994.github.io/posts/%E8%BF%9B%E7%A8%8B%E5%B9%B3%E6%BB%91%E9%87%8D%E5%90%AF/</link>
      <pubDate>Fri, 31 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E8%BF%9B%E7%A8%8B%E5%B9%B3%E6%BB%91%E9%87%8D%E5%90%AF/</guid>
      <description></description>
    </item>
    
    <item>
      <title>csip</title>
      <link>http://nber1994.github.io/posts/csip/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/csip/</guid>
      <description>os-csip  cs 代码段寄存器 Ip 指令指针寄存器 基地址：偏移地址  在8086pc机中，任意时刻，设CS中的内容为M，IP中的内容为N，8086CPU将从内存M*16+N单元开始，读取下一条指令
8086cpu工作的过程可以描述如下：  1:从CS:IP指向的内存单元读取指令，读取的指令进入指令缓冲器 2：IP=IP+所读取指令的长度，从而读取下一条指令 3:执行指令，转到步骤1，重复这个过程  </description>
    </item>
    
    <item>
      <title>代码链接</title>
      <link>http://nber1994.github.io/posts/%E4%BB%A3%E7%A0%81%E9%93%BE%E6%8E%A5/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E4%BB%A3%E7%A0%81%E9%93%BE%E6%8E%A5/</guid>
      <description> 编译程序往往需要编译器驱动程序，常用的如GCC，它将调用程序预处理器，编译器，汇编器和链接器   编译过程  程序预处理器将代码文件处理为ascii码的文件main.i 编译器将main.i文件翻译为汇编文件main.s 汇编器将main.s翻译为一个可重定位目标文件 main.o 链接器将main.o和sum.o组合起来，创建一个可执行目标文件 shell调用加载器，加载可执行目标文件，将代码和数据加载到内存中执行  链接器的工作  符号解析 每个符号对应于一个函数，变量等 符号解析做的就是将每个符号引用和符号定义关联起来 重定位 编译器和汇编器生成的是地址从0开始的代码和数据节。链接器通过把每个符号定义和一个内存位置关联起来（会合并不同可重定位目标文件的.data节），然后更新所有这个符号的引用，使其指向这个引用位置 由于ELF加载的方式已经定了，各个节的大小也已经定了，所以链接之后，所有的符号的位置已经定了（虚拟内存地址）  目标文件 Linux中目标文件的格式ELF文件  ELF文件的格式    ELF的头是一个16字节的固定序列，包含一些基本信息，包括目标文件的类型，机器类型，节头部表偏移量
在ELF头和节头部表之间的一些节 .text 已经编译程序的机器代码 .rodata 只读数据 类似于代码中的硬编码 sprintf(‘%s’) .data 已初始化的全局&amp;amp;静态变量 (局部变量在运行时保存在栈中) .bss 未初始化的全局变量&amp;amp;静态变量，以及被声明为0的全局&amp;amp;静态变量
 静态链接库  可执行目标文件 可执行文件包含只读内存段（代码段）和读写内存段（数据段） ELF头中还包含程序的入口点，即第一条指令的地址
 加载可执行目标文件  Shell指令加载ELF文件到内存中，1.将代码段和数据段加载到内存中，并跳转到程序入口点   运行时的内存映像 代码段总是从0x400000地址开始的，之后是数据段 数据段之后是堆，堆后面的内存是为共享模块保留的 用户栈总是从最大的合法地址开始向下延伸，之后的是内核内存
 动态链接共享库  动态链接库在链接器阶段，会引入来更新重定位和符号表信息 在加载器之后，会调用动态链接库来引入代码和数据  ￼  动态链接库是在调用动态库代码时，程序被载入时才计算代码的逻辑地址 这就要求动态库代码是由位置无关代码构成  位置无关代码  链接一个函数时，多个进程都引用同一个函数，每个进程都占用内存，如果可以引用共享内存中的库代码是极好的   动静态链接共享库区别  动态链接库占用空间比静态小，但是会影响程序性能 动态库并不是和可执行文件一起存储在磁盘上，共享代码端一次性加载到共享段中，供所有的进程使用 静态库在链接阶段已经确定了内存位置，动态是在程序加载时才会计算出代码地址 静态库一旦有修改，所有使用的可执行文件都需要重新编译，动态链接则不用  </description>
    </item>
    
    <item>
      <title>同步异步阻塞非阻塞</title>
      <link>http://nber1994.github.io/posts/%E5%90%8C%E6%AD%A5%E5%BC%82%E6%AD%A5%E9%98%BB%E5%A1%9E%E9%9D%9E%E9%98%BB%E5%A1%9E/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E5%90%8C%E6%AD%A5%E5%BC%82%E6%AD%A5%E9%98%BB%E5%A1%9E%E9%9D%9E%E9%98%BB%E5%A1%9E/</guid>
      <description>同步、异步、阻塞与非阻塞  同步和异步关注的是消息通知的机制 阻塞和非阻塞关注的是等待消息时线程的状态  区分   如果一直在显示的等待消息的到来，同步
  如果经过一个消息通知机制，等待消息则是异步
  在等待消息的时候，如果线程还能做其他事情，则是非阻塞的
  如果除了等待消息，其他什么事情也不能做，则是阻塞的
  同步阻塞 坐等待消息到来，而且什么也不做
  同步非阻塞 坐等待消息的到来，期间还可以做一些其他的事情
  异步阻塞 等待消息的通知，期间并不做其他事情
  异步非阻塞 等待消息的通知，期间还做其他的事情
  举例  下载文件  我盯着下载进度，什么也不敢 一遍夹手指甲，不时的瞄一眼进度条 我什么也不做，等待下载完成叮的一声 我剪指甲，等待叮的一声    区别 同步阻塞形式  效率是最低的， 拿上面的例子来说，就是你专心排队，什么别的事都不做。 实际程序中：就是未对fd 设置O_NONBLOCK标志位的read/write 操作；  异步阻塞形式  如果在银行等待办理业务的人采用的是异步的方式去等待消息被触发（通知），也就是领了一张小纸条，假如在这段时间里他不能离开银行做其它的事情，那么很显然，这个人被阻塞在了这个等待的操作上面； 异步操作是可以被阻塞住的，只不过它不是在处理消息时阻塞，而是在等待消息通知时被阻塞。 比如select 函数，假如传入的最后一个timeout参数为NULL，那么如果所关注的事件没有一个被触发，程序就会一直阻塞在这个select 调用处。 这种方式岂不是很傻  同步非阻塞形式  实际上是效率低下的 想象一下你一边打着电话一边还需要抬头看到底队伍排到你了没有，如果把打电话和观察排队的位置看成是程序的两个操作的话，这个程序需要在这两种不同的行为之间来回的切换，效率可想而知是低下的。 很多人会写阻塞的read/write 操作，但是别忘了可以对fd设置O_NONBLOCK 标志位，这样就可以将同步操作变成非阻塞的了。  异步非阻塞形式  效率更高 因为打电话是你(等待者)的事情，而通知你则是柜台(消息触发机制)的事情，程序没有在两种不同的操作中来回切换。 比如说，这个人突然发觉自己烟瘾犯了，需要出去抽根烟，于是他告诉大堂经理说，排到我这个号码的时候麻烦到外面通知我一下(注册一个回调函数)，那么他就没有被阻塞在这个等待的操作上面，自然这个就是异步+非阻塞的方式了。 如果使用异步非阻塞的情况，比如aio_*组的操作，当发起一个aio_read操作时，函数会马上返回不会被阻塞，当所关注的事件被触发时会调用之前注册的回调函数进行处理。  ￼ Socket IO的形式是会将接收到的数据先缓存在内核缓冲区上，然后再复制到进程的内存中</description>
    </item>
    
    <item>
      <title>操作系统常见问题</title>
      <link>http://nber1994.github.io/posts/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</guid>
      <description>1.进程和线程的区别   进程抽象来说 内存空间+逻辑控制流
  线程依附于进程上，拥有相同的内存空间，不同的逻辑控制流，带来很多竞争问题
  特别的进程和线程拥有相同的堆，但是不同的用户栈
  僵尸进程和孤儿进程
  2.线程同步的方式 linux下提供了多种方式来处理线程同步，最常用的是互斥锁、条件变量和信号量。
互斥锁 条件变量 线程A阻塞并等待某个条件的达成才继续执行，基于共享变量实现的
信号量 互斥锁可以看为特殊情况的信号量
信号阻塞，嵌套 3.进程间通信的方式 1.管道pipe匿名管道  管道是半双工的，只能一个方向流动 且只能用于有血缘关系的进程之间（父子或者兄弟进程之间） 单独构成一种文件系统，对于进程而言就是一个文件，但不属于文件系统，是存在于内存中  管道的实质：  实质就是一个内核缓冲区，采用先进先出的方式对数据进行读取和写入，一旦读空或者写满的情况，则会相应的进程等待  局限性：  只能在亲缘关系进程之间 没有名字 缓冲区域是有限的，一般是一页 管道内所传送的是无格式的字节流，所以需要读写双方预定好数据格式 Pipe必须确定对方存在，否则将直接退出 如果写入大于管道的容量，写入将阻塞  2.有名管道FIFO  有名管道为了克服pipe的只能在亲缘进程之间的局限而提出的 有名管道提供了一个路径名与之关联，存在于文件系统中，这样，不同亲缘关系的进程之间也可以借助FIFO进行通信 特别的，有名管道名字存在于文件系统中，但是内容存放在内存中 当对方不在连接时，则会阻塞  3.信号  信号是软件层次上的 对中断机制的一种模拟，是一种异步通信方式 ？？？？？常见信号SIGKILL SIGSTOP SIGTERM SIGHUP 信号的类型  4.消息队列  消息队列是存放在内存中的消息链表 消息队列存放在内核中，只有内核重启或者显示的删除，消息才会被删除 与管道不同的是，消息对列并不需要等待目标进程就绪  5.共享内存  多个进程可直接读写同一块内存区域，是最快的IPC方式 同时由于多个进程同时共享一块内存区域，则需要信号量来保证同步&amp;amp;互斥  6.</description>
    </item>
    
    <item>
      <title>操作系统并发编程</title>
      <link>http://nber1994.github.io/posts/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/</guid>
      <description>现代操作系统提供了三种构造并发程序的方法 1.进程 每个逻辑控制流都是一个进程，由内核来调度和维护，所以控制流之间通信可以采用IPC进程间通信技术
2.I/O多路复用 在这种形式的并发编程中，应用程序在一个进程的向下文中显示的调度自己的逻辑流。逻辑流被模型化为状态机，数据到达后，主程序显示的从一个状态转换为另一个状态。
3.线程 运行在一个单一进程上下文中的逻辑流，由内核进行调度
基于进程的并发编程 如何工作 服务器监听了描述符3， 客户端1连接上以后，服务端分配了fd4给客户端1，并且派生一个子进程， 关闭主进程的fd4,同时在子进程的文件描述符表中，关闭fd3。 父子进程文件描述符表都指向了同一个文件表项。 从此父进程继续接受请求，子进程提供服务 基于进程的并发服务器 优缺点： 优点：进程存在独立的内存空间，这样避免了内存互相覆盖的迷惑 缺点：进程间共享状态十分困难，必须使用IPC（进程间通信），但是IPC一般开销比较高
基于I/O多路复用的并发编程 一个进程某一时刻，只能处理一个事件，为了解决这个问题，可以借助select函数，要求内核将进程挂起，只有在一个或多个I/O事件发生后，才将控制权返回给应用程序
一般实现的逻辑是，将逻辑流模型转化为一个状态机。
I/O多路复用的技术的优劣 优点： 1.相比较基于进程的并发技术，I/O多路复用提供给程序员对程序行为的控制 2.所有的逻辑控制流是在一个进程中的，所以不同的逻辑流可以共享数据十分方便
缺点： 1.编码复杂 2.不能充分利用多核
基于线程的并发编程 可以看为基于进程&amp;amp;IO多路复用的结合
进程就是运行在进程中上下文中的逻辑流.线程是由内核调度的，且每个线程都有其自己的线程上下文，还包括一个唯一的线程ID，栈，栈指针等。所有运行在一个进程里的线程共享改进程的整个虚拟地址空间。
线程与进程的区别
1.线程的上下文比进程的上下文小的多，因而线程的切换比进程的切换更快 2.线程没有严格的父子继承关系，只有主线程和对等线程的区别，一般主线程是进程中第一个线程 3.对等线程池内的对等线程可以杀死或者等待对等线程，且各个线程之间可以共享数据，拥有相同的堆块，但是用户栈确是不同的
线程异步服务的代码实现 主线程等待请求到达，当接收到一个请求后，创建一个对等线程对请求进程处理
基于预线程化的并发服务器 基于预线程化的并发服务器会事先初始化好一个线程池 使用线程提高并发性 线程并发的程序，在多核处理器中常常有很好的性能，因为内核会在多个核上并发的调度线程
并行程序是运行在多个处理器上的并发程序
同步多个线程的方法 控制对共享数据的并发访问，基于一种叫做信号量的特殊类型变量的方法。 信号量是非负整数的全局变量，P操作会将s减一，而V操作会将s加一，且都是原子操作 基于二原信号量的同步也常常成为互斥锁，对互斥锁进行P操作叫做加锁，V操作为解锁
不过对于这种同步方式，开销是十分大的，应该尽可能的避免这种方式</description>
    </item>
    
    <item>
      <title>操作系统异常控制流</title>
      <link>http://nber1994.github.io/posts/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%BC%82%E5%B8%B8%E6%8E%A7%E5%88%B6%E6%B5%81/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%BC%82%E5%B8%B8%E6%8E%A7%E5%88%B6%E6%B5%81/</guid>
      <description>异常控制流(ECF) 异常可以分为四种 中断，陷阱，故障，终止 中断 中断时异步的，是处理IO设备的信号，例如正在读取磁盘（DMA）完毕后，发送信号到cpu芯片的一个引脚，这时，cpu会停止当前工作，根据传递来的异常号码查询异常表的异常处理程序，等处理完之后，控制会跳转到中断发生时的下一条命令，程序继续执行
陷阱 陷阱执行完毕之后，也是会返回到发生陷阱时的下一条指令 陷阱最重要的用途就是在用户进程和内核之间提供一个系统调用 用户态进程准备向内核请求服务时，内核允许用户进程通过syscall， 会产生一个异常处理程序的陷阱，对于linux来说系统调用的参数不是通过栈传递的，而是通过寄存器传递的 系统调用&amp;amp;普通函数调用区别 普通调用只在用户态内存中，且只能访问和函数相同的栈 系统调用运行在内核模式中，可以访问内核中的栈 故障 故障是由错误情况引起的，会将控制转移到故障处理程序处理，得到的结果可能是终止程序或者返回引起故障的地方重新执行 一个比较经典的例子是缺页异常 当指令引用一个虚拟内存地址时，对应的物理地址不存在主存中，就会触发故障处理程序，从磁盘读入相关的页面到主存中，然后将控制权重新返回给引用内存的指令，这时就会读到相应的内存地址，顺利执行
终止 当发生无法修复的异常时，比如硬件设备DRAM/SRAM损坏，会导致整个进程终止</description>
    </item>
    
    <item>
      <title>机器内存储类型</title>
      <link>http://nber1994.github.io/posts/%E6%9C%BA%E5%99%A8%E5%86%85%E5%AD%98%E5%82%A8%E7%B1%BB%E5%9E%8B/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E6%9C%BA%E5%99%A8%E5%86%85%E5%AD%98%E5%82%A8%E7%B1%BB%E5%9E%8B/</guid>
      <description>存储 存储在不同的存储器的速度 随机访问存储器  静态RAM和动态RAM SRAM既可以在芯片上，也可以在芯片下  访问主存 总线事务  读事务是从主存传输数据到cpu 写事务是从cpu传输数据到主存   Cpu通过系统总线链接I/O桥，主存通过内存总线链接I/O桥
读事务： 1.cpu将地址放在系统总线中，通过I/O桥传给内存总线传递给内存 2.内存感知到内存总线传递来地址，读出地址数据，并传递到内存总线上 3.cpu感受到系统总线传递的数据，并将其复制到寄存器中
写事务： 1.cpu将需要写数据的地址传递给内存，内存读出地址等待数据 2.cpu将数据写入系统总线 3.内存从内存总线拿到数据，写入DRAM中
 DRAM速度比磁盘快10万倍，SRAM比磁盘快100万倍  磁盘  盘面：磁盘是由一些盘面组成的，每个盘面上下都可以使用 磁道：磁道是一组同心圆 扇区：一个磁道分为一组扇区，扇区之前尤一些间隙隔开 柱面：是所有盘面表面到主轴中心距离相等的磁道的集合   磁盘读写 磁盘通过读写头对磁盘进行读写，读写头位于机械臂头部，通过前后摆动进行寻道操作，同一个时刻上，读写头都位于一个柱面
磁盘读写速度  磁盘的读写速度受三个时间影响：  寻道时间+旋转时间+传送时间     访问磁盘  Cpu当前的进程访问磁盘时，会将命令，逻辑块号和内存地址写入到磁盘控制器 磁盘控制器读出数据，直接存入内存相关地址（DMA） 磁盘控制器发出一个中断给cpu  设备可以直接执行写或者读总线事务，而不经过cpu，成为直接内存访问DMA </description>
    </item>
    
    <item>
      <title>系统IO</title>
      <link>http://nber1994.github.io/posts/%E7%B3%BB%E7%BB%9Fio/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E7%B3%BB%E7%BB%9Fio/</guid>
      <description> 一个应用程序通过要求内核打开相应的文件，来宣告自己要访问一个I/O设备。内核返回一个非负整数，成为文件描述符。内核会记录该描述符的所有信息 Linux shell会给每个进程分配三个文件描述符 0标准输入 1标准输出 2标准错误  文件类型 linux文件类型分为
  普通文件 普通文件包括文本文件和二进制文件
  目录 目录是包含一组链接的文件，其中每个链接都将一个文件名映射到一个文件
  套接字 用来与另一个进程进行跨进程通信的文件
  共享文件 内核如何表示打开的文件  由三个数据结构表示  描述符表 每个进程都有一个文件描述符表，并以文件描述符作为索引 文件表 打开文件的集合是由一张表表示的，所有进程共享这张表，每一个表项包含当前文件的位置，引用计数，以及一个v-node表中对应表项的指针，进程关闭一个文件，表项中的引用计数会减一，当为0时，内核会删除该表项 v-node表 同文件表一样，每个进程共享一张表，每个表项包含stat结构大多数信息，包含了文件的类型和对于文件操作函数的指针    多个文件描述符可以通过不同的表项来引用同一个文件（只要打开同一个文件两次，两个不同的fd）
父子进程共享文件 </description>
    </item>
    
    <item>
      <title>虚拟内存</title>
      <link>http://nber1994.github.io/posts/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/</guid>
      <description>虚拟内存是一种对主存的抽象  三个重要的功能：  将内存抽象为了磁盘的活动区域的缓存，并可以按照需求换入换出，高效的使用了主存 为每个进程提供了一致的地址空间，方便内存管理 保护每个进程地址空间不被其他进程破坏   虚拟地址需要翻译为物理地址，翻译的组件叫做内存管理单元（MMU），同时需要配合存放在主存中的页表   页表操作的问题  需要判断一个虚拟页是否缓存在主存上，如果有的话还要确定虚拟内存对应的物理地址。 如果不存在的话，还要确定虚拟页存放在磁盘的那个位置，并且在内存中牺牲一个页，并将虚拟也从磁盘复制到主存上，替换掉这个牺牲页  页表条目（PTE）  在页表中每个固定的偏移量都有一个固定的条目  一个PTE由一个有效位和一个n位地址字段组成 有效位标识标识该虚拟也是否被缓存在DRAM中 N位的地址是物理内存页的起始位置，或者是磁盘上的起始位置（未设置有效位）  页命中  地址翻译会根据虚拟内存地址翻译出PTE的索引，并从内存读取它，发现设置了有效位，则直接读取地址拿到虚拟内存  缺页  DRAM不命中则成为缺页 虚拟内存根据地址翻译得到PTE的索引，同时读取标志位，发现未设置，则会触发一个缺页异常，缺页处理程序会选出一个牺牲页，如果牺牲页已经被修改了，内核会把修改写会磁盘。  之后内核会把虚拟页从磁盘读出来，写入主存并更新PTE，之后会返回，将重新启动导致缺页的指令（故障） 磁盘和内存之间传送页的活动叫做换入   虚拟内存作为内存管理工具
 共享内存   即是多个进程的虚拟地址映射到同一个物理内存地址上
  VM简化了
 链接 加载 代码 数据共享 已及应用程序的内存分配     简化链接  每个进程加载到内存中使用的格式都是代码段起始地址为0x40000开始，然后是数据段，堆等等，这样极大地简化了连接器的设计与实现，允许连接器生成完全链接的可执行文件，并且是独立于物理内存中代码和数据的最终位置的  简化加载  简化了加载的步骤，加载器只是为代码和数据段分配好未标记的虚拟页，并不会实际的加载进内存，在被执行时，cpu会按需加载  简化共享   简化共享，按理来说，每个进程都会有独立的内存空间，代码，数据，堆和栈信息都是不共享的，实际的物理地址也都是不重合的，但是难免会有需要共享的场景，比如说c语言库，动态链接库。操作系统安排每个进程中将适当的虚拟地址映射到相同的物理地址上去，节省了内存资源实现了共享内存</description>
    </item>
    
    <item>
      <title>leetcode-杂题</title>
      <link>http://nber1994.github.io/posts/%E6%9D%82%E9%A2%98/</link>
      <pubDate>Tue, 09 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E6%9D%82%E9%A2%98/</guid>
      <description>环形链表II 给定一个链表，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。 说明：不允许修改给定的链表。 进阶： 你是否可以不用额外空间解决此题？ 思路： 如下图所示：  初始化slow指针指向head节点，fast指向head-&amp;gt;next节点，假设slow与fast在c点相遇。由于slow走过的路程为x+y，fast走过的路程为x+y+z+y，且fast走过的距离是slow的两倍，所以：   2(x+y)=x+y+z+y
  化简得：x=z，此时把slow指针放到c处，fast指针放到a处，俩指针以相同速度向前走，则相遇节点为b，且b为相遇节点。  //两数之和 //借助一个hash表来进行数据的存储 //O(N) func twoSum(nums []int, target int) []int { hashMap := make(map[int]int, len(nums)) for k, v := range nums { if index, exist := hashMap[target-v]; exist { return []int{k, index} } else { hashMap[v] = k } } return nil } //先将数组排序，然后两个指针分别寻找 //O(logN) func twoSum1(nums []int, target int) []int { lens := len(nums) oldNums := make([]int, lens) copy(oldNums[:], nums) sortedNums := sort.</description>
    </item>
    
    <item>
      <title>布隆过滤器系统设计</title>
      <link>http://nber1994.github.io/posts/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</guid>
      <description>什么情况下需要布隆过滤器？   先来看几个比较常见的例子
  字处理软件中，需要检查一个英语单词是否拼写正确
  在 FBI，一个嫌疑人的名字是否已经在嫌疑名单上
  在网络爬虫里，一个网址是否被访问过
  yahoo, gmail等邮箱垃圾邮件过滤功能 这几个例子有一个共同的特点： 如何判断一个元素是否存在一个集合中？
  常规思路 数组
链表
树、平衡二叉树、Trie
Map (红黑树)
哈希表
虽然上面描述的这几种数据结构配合常见的排序、二分搜索可以快速高效的处理绝大部分判断元素是否存在集合中的需求。
但是当集合里面的元素数量足够大，如果有500万条记录甚至1亿条记录呢？这个时候常规的数据结构的问题就凸显出来了。
数组、链表、树等数据结构会存储元素的内容，一旦数据量过大，消耗的内存也会呈现线性增长，最终达到瓶颈。
有的同学可能会问，哈希表不是效率很高吗？查询效率可以达到O(1)。但是哈希表需要消耗的内存依然很高。
使用哈希表存储一亿 个垃圾 email 地址的消耗？哈希表的做法：首先，哈希函数将一个email地址映射成8字节信息指纹；考虑到哈希表存储效率通常小于50%（哈希冲突）；因此消耗的内存：8 * 2 * 1亿 字节 = 1.6G 内存，普通计算机是无法提供如此大的内存。
这个时候，布隆过滤器（Bloom Filter）就应运而生。在继续介绍布隆过滤器的原理时，先讲解下关于哈希函数的预备知识。
哈希函数 哈希函数的概念是：将任意大小的数据转换成特定大小的数据的函数，转换后的数据称为哈希值或哈希编码。下面是一幅示意图：
可以明显的看到，原始数据经过哈希函数的映射后称为了一个个的哈希编码，数据得到压缩。哈希函数是实现哈希表和布隆过滤器的基础。
布隆过滤器介绍  巴顿.布隆于一九七零年提出 一个很长的二进制向量 （位数组） 一系列随机函数 (哈希) 空间效率和查询效率高 有一定的误判率（哈希表是精确匹配）  布隆过滤器原理  布隆过滤器（Bloom Filter）的核心实现是一个超大的位数组和几个哈希函数。假设位数组的长度为m，哈希函数的个数为k
  以上图为例，具体的操作流程：
 假设集合里面有3个元素{x, y, z}，哈希函数的个数为3。首先将位数组进行初始化，将里面每个位都设置位0。 对于集合里面的每一个元素，将元素依次通过3个哈希函数进行映射，每次映射都会产生一个哈希值，这个值对应位数组上面的一个点，然后将位数组对应的位置标记为1。 查询W元素是否存在集合中的时候，同样的方法将W通过哈希映射到位数组上的3个点。如果3个点的其中有一个点不为1，则可以判断该元素一定不存在集合中。 反之，如果3个点都为1，则该元素可能存在集合中。 注意：此处不能判断该元素是否一定存在集合中，可能存在一定的误判率。  可以从图中可以看到：假设某个元素通过映射对应下标为4，5，6这3个点。虽然这3个点都为1，但是很明显这3个点是不同元素经过哈希得到的位置，因此这种情况说明元素虽然不在集合中，也可能对应的都是1，这是误判率存在的原因。    布隆过滤器添加元素  将要添加的元素给k个哈希函数 得到对应于位数组上的k个位置 将这k个位置设为1  布隆过滤器查询元素  将要查询的元素给k个哈希函数 得到对应于位数组上的k个位置 如果k个位置有一个为0，则肯定不在集合中 如果k个位置全部为1，则可能在集合中  </description>
    </item>
    
    <item>
      <title>秒杀系统设计</title>
      <link>http://nber1994.github.io/posts/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</guid>
      <description> 秒杀系统主要解决两个问题，一个是并发写，一个是并发读 首先需要和常规的电商系统隔离，避免影响正常的业务流程 同时还需要注意系统的高性能，高扩展，高可用，以及数据一致性（减库存）  秒杀架构的原则  请求数据要尽量少 请求数要尽量少 路径要尽量短 依赖要尽量少 不要存在单点  实现 实现动静分离  所谓动态数据就是指页面输出数据是否和url，浏览者，时间地域等有关系 静态数据是指不变的数据， 静态数据直接上CDN，请求不到后端服务  削峰  排队  队列来承接流量的冲击，但是达到队列的处理瓶颈后，会有请求丢失   答题  防刷 分散请求   分层过滤  从每一层都拦截或者丢弃（当处理能力达到瓶颈时）一部分的流量来进行请求的削峰    减库存  下单减库存  很多下单后没有付款，导致其他人不能正常购买   付款减库存  下单数多于库存，导致一些付款无法成功   预扣库存 例如库存预留十分钟时间，当真实付款时检查是否过期，如果过期则就去减库存，如果没有库存则付款失败  同样会存在作弊行为    </description>
    </item>
    
    <item>
      <title>分库分表分区系统设计</title>
      <link>http://nber1994.github.io/posts/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%88%86%E5%8C%BA%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Wed, 09 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%88%86%E5%8C%BA%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</guid>
      <description>要求 mysql数据库在什么情况下需要进行分库分表分区
基础概念  分表 能够解决单表数据量过大带来的查询效率下降的问题 分库 面对高并发的读写访问，master无法应对写操作的压力时，需要分库来提高数据库的并发访问能力  分库分表场景  单表数据达到千万 数据库面临高并发访问  实现策略 对关键字取模，实现对数据访问路由
分库  按照功能分  比如用户，订单等   按照地区分  北京，上海   带来的问题  跨库join问题  全局表 数据冗余 应用层组装      分表 水平分表  解决的问题  单表过大的问题   方法 一般都是按照某个字段hash取模  按照某个字段分  比如status状态1 2 3，分到三个不同的表中   按照日期分表    垂直分表  解决的问题  实现冷热数据分离 减少数据行大小，避免跨页问题，提高查询性能   方法  把不常用的字段单独放在一张表 打字单单独拆分出来放在附件表中 经常组合查询的在一张表    分区 水平分区 mysql仅仅支持水平分区</description>
    </item>
    
    <item>
      <title>发号器系统设计</title>
      <link>http://nber1994.github.io/posts/%E5%8F%91%E5%8F%B7%E5%99%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Wed, 09 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E5%8F%91%E5%8F%B7%E5%99%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</guid>
      <description>ID生成器 要求 ID一定要是全局有序的，再者因为有诸如按照时间排序的场景，所以要求按照时间有序。同时要求尽可能的短
 按照时间粗略有序 尽可能短  方案 1.使用数据库的auto_increment生成全局递增ID 优点：
 简单 能够全局唯一 时间严格递增 缺点： 可用性难以保持，主库挂了就挂了 扩展性差，主库写性能为上限，难以扩展  2.数据库集群 一共有n个节点，每个节点设置不同的auto_increment初始值，已经相同的增长步长
 优点：  具有较高的可用性和扩展性   缺点：  并不是根据时间严格递增    3.uuid 数据库生成ID方法，都需要有远程调用。uuid的方法是在本地生成唯一ID
 4个字节标识unix timestamp 3个字节标识机器ID 2个字节标识进程ID 3个字节标识计数器 优点：  高性能，生成很快，不会重复   缺点：  较长，查询效率较低 同时不失严格的按照时间有序    4.snowflake 核心思想：一个long的ID，41bit作为毫秒数，10bit作为机器编号，12bit作为毫秒内序列号 理论上每秒能生成：1000*2^12个大约400w的ID
 实现自己的分布式算法  单机并发量 多少个机房 每个机房机器数量 几个业务线 需要几年     假设一个64bit的int值，如果系统预计运行10年，至少需要10365246060*1000来算出大致需要多少位 单机的峰值10w，也就是每毫秒大概是100，则需要预留7bit给毫秒内序列号 机房和机器数也按照该规则   优点：  ID唯一 毫秒在高位，时间递增    参考  沈剑-发号器  </description>
    </item>
    
    <item>
      <title>http基础知识</title>
      <link>http://nber1994.github.io/posts/http%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/http%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</guid>
      <description>http  http是无状态的协议 为了保持http的状态，引入了cookie 请求报文结构  响应报文结构   http方法  get  获取资源   post  传输实体   put  传输文件   head  获取报文首部   delete  删除文件   options  获取url支持的方法   trace  将到达web服务器之前的通信节点换回给客户端 max-forward首部字段填入数值，每经过一个服务器该值就减一，当减为0时停止传输，并就地返回200 ok    持久连接节省通信量  keep-alive  一个页面上会有多个需要http请求的资源 如果每个资源都会建立和断开tcp连接，增加网络开销 因此增加了keep-alive的方法，只要任一端没有明确断开连接，就会一直保持连接   pipline  keep alive方法使得管线化成为可能 之前一个http请求完成之后，才会请求下一个http请求 管线化则同时发生多个请求，比持久化连接更快    使用cookie记录状态  客户端会根据服务端返回的响应报文中的set-cookie的首部字段，来保存cookie 当再次发生请求给服务端时，会将cookie一并发送给服务端    响应报文   请求报文</description>
    </item>
    
    <item>
      <title>InnoDB三大特性</title>
      <link>http://nber1994.github.io/posts/innodb%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A7/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/innodb%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A7/</guid>
      <description>三大特性  插入缓冲 两次写 自适应哈希索引  自适应哈希索引 InnoDB会监控表上二级索引的查找，如果耳机索引多次被查询，则会对该热数据建立hash索引
这些操作都是InnoDB自己的行为，用户控制不了</description>
    </item>
    
    <item>
      <title>InnoDB文件</title>
      <link>http://nber1994.github.io/posts/innodb%E6%96%87%E4%BB%B6/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/innodb%E6%96%87%E4%BB%B6/</guid>
      <description>文件   参数文件   日志文件  错误日志 二级制日志  恢复 复制 审计   慢查询日志 查询日志    socket文件   pid文件   Mysql表结构定义文件   InnoDB存储引擎文件   表空间文件 innodb存储按照表空间进行存放。初始化有一个10M的ibdata1文件，文件就是默认的表空间文件 重做日志文件 每个innodb引擎至少与一个重做日志文件组，每个组内至少有两个重做日志文件 并以循环写入的方式运行</description>
    </item>
    
    <item>
      <title>InnoDB淘宝团队博客</title>
      <link>http://nber1994.github.io/posts/innodb%E6%B7%98%E5%AE%9D%E5%9B%A2%E9%98%9F%E5%8D%9A%E5%AE%A2/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/innodb%E6%B7%98%E5%AE%9D%E5%9B%A2%E9%98%9F%E5%8D%9A%E5%AE%A2/</guid>
      <description>连接  MySQL · 引擎特性 · InnoDB undo log 漫游 http://mysql.taobao.org/monthly/2015/04/01/ MySQL · 引擎特性 · InnoDB redo log漫游 http://mysql.taobao.org/monthly/2015/05/01/ MySQL · 引擎特性 · InnoDB 崩溃恢复过程 http://mysql.taobao.org/monthly/2015/06/01/ MySQL · 引擎特性 · Innodb change buffer介绍 http://mysql.taobao.org/monthly/2015/07/01/ MySQL · 引擎特性 · InnoDB index lock前世今生 http://mysql.taobao.org/monthly/2015/07/05/ MySQL · 引擎特性 · InnoDB Adaptive hash index介绍 http://mysql.taobao.org/monthly/2015/09/01/ MySQL · 引擎特性 · InnoDB 全文索引简介 http://mysql.taobao.org/monthly/2015/10/01/ MySQL · 引擎特性 · InnoDB 事务子系统介绍 http://mysql.taobao.org/monthly/2015/12/01/ MySQL · 引擎特性 · InnoDB 事务锁系统简介 http://mysql.</description>
    </item>
    
    <item>
      <title>InnoDB锁</title>
      <link>http://nber1994.github.io/posts/innodb%E9%94%81/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/innodb%E9%94%81/</guid>
      <description>锁用于控制对共享资源的并发访问 对于innodb来说，支持行锁 对于myisam，支持表锁 表锁一般ddl时会用到
锁概述 lock的对象是事务，用来锁定数据库的对象，表，页，行。一般是在事务的commit和rollback之后释放 innodb中锁有两种类型
 s锁（共享锁），允许事务读取一行数据 x锁（排他锁），允许事务删除或更新一行数据   意向锁  InnoDB支持多粒度的锁定，这种锁定允许事务在行级锁上和表级锁上同时存在 为了支持这种操作，innodb支持一种额外的枷锁方式，成为意向锁  对于最细粒度进行上锁，首先需要对粗粒度的对象进行上锁，如果需要对行r上X锁，则需要对数据库A，表，页上意向所IX，然后再对行r上X锁 对于innodb来说，意向锁设计的比较简单，意向锁即是表锁。设计目的是为了在一个事务中揭示下一行将要被请求的锁类型
 意向共享锁（IS lock）事务想要获得一张表中几行的共享锁 意向排它锁（IX lock）事务想要获得一张表中几行的排他锁 可以看到，意向锁和s和x锁都是兼容的，而只有s和IS锁之间兼容 IS和IX都是表级锁，对于行级锁的X和S锁并不会冲突，只会和表级的S和X锁冲突 而对于行级锁的S和X锁，还是按照基本的原则  意向锁的作用  如果不存在意向锁，加锁时需要便利所有行来判断是否会有冲突 存在意向锁时，只需要判断意向锁与枷锁的兼容性即可。因为存在意向锁代表有行级锁的存在  一致性非锁定读 多版本控制技术MVCC，innodb是基于undo log来实现的 对于read commited隔离级别，每行数据读的是最新版本的数据 而对于repetable read隔离级别，没行数据读的都是事务开始时数据版本数据 对于read commited隔离级别来说，违反了一致性准则
一致性锁定度 两种一致性锁定度的语句
 select * from A &amp;hellip; for update 加X锁 select * from A ,,, lock in share mode 加S锁 对于innodb，在没有引入next-key锁之前，即使加上以上语句，即使读取的行加了for update，其他的事务特使可以读取的  锁的算法 行锁的三种算法：
  record lock 单个记录的锁   gap lock 间隙所，一个范围上的锁，但是不包括记录本身   next-key lock gap lock+record lock锁，锁定一个范围，而且包括记录本身   next-key lock是为了解决幻读的问题</description>
    </item>
    
    <item>
      <title>mysql-5.7连接池</title>
      <link>http://nber1994.github.io/posts/mysql5.7%E8%BF%9E%E6%8E%A5%E6%B1%A0/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/mysql5.7%E8%BF%9E%E6%8E%A5%E6%B1%A0/</guid>
      <description>mysql5.7之后，引进了线程池的概念
 为什么要是有线程池 没有线程池的现象  随着DB访问的增大，DB的响应时间也会随之增大  而当DB访问达到一定程度的时候，DB吞吐量也会出现下降，并且会越来越差   原因 减少线程重复创建与销毁的开销，提高性能 线程池采用预线程技术，在监听到新的请求到来时，会从线程池中分配一个线程来处理，
处理后该线程不会销毁而是去处理其他请求 这样避免了频繁的线程的创建和销毁，减少了上线文切换
对系统起到保护作用 线程池限制了并发线程数，相当于限制了runing的线程数。
不论出现多大的请求，超过最大线程都需要排队，所以讲系统保持在高性能的状态， 防止DB雪崩现象
线程池和连接池的区别 连接池一般是在客户端设置的，避免连接的频繁销毁和创建，但是并不能起到对DB的保护作用 所以一般线程池和连接池一起使用
Mysql线程池介绍 简介 为了应付频繁创建销毁线程的开销以及高并发导致的雪崩问题 架构 线程池被划分为多个组group，每个组下面有对应的工作线程
架构图 thread pool 组成 线程池由一个timer thread线程和多个线程组组成，而每个线程组又是由两个队列，已和listener线程和多个worker线程组成
队列(高优先级队列和低优先级队列) 高优先级队列会优先存放事务中的语句,同时如果一个任务存在于低优先级太长时间也会到高优先级里。如果是非事务队列，
或者是autocommit的事务，都会直接放在低优先级队列
listener线程 listener线程监听该group的语句，当队列中存在待处理的任务，说明这时有worker在工作，那么直接把任务放入队列中。
如果任务队列为空，则将自己转变为worker进程，进行处理。这么做主要是为了减少创建线程的开销
worker线程 真正干活的线程
timer线程 检查阻塞  timer线程周期性的检查group是否处理阻塞状态,当出现阻塞，会唤醒线程或者新建线程来解决   检查方法：worker线程去检查队列时，会将queue_event_count+1，而timer线程检查完是否阻塞后会将其置为0
如果此时,queue_event_count=0并且队列不为空，则说明所有的worker都在工作，group阻塞
 怎么工作  请求连接到mysql， threadid%thread_pool_size确定落在那个group group接收到请求后，检查队列是否为空，如果为空，则自己作为worker处理请求，否则将任务放入队列中 worker检查队列请求，如果有请求的话，首先检查运行的线程数是否超过thread_pool_oversubscribe+1, 如果没有则执行，没有拿到任务的线程会在thread_pool_idle_timeout之后被回收 timer线程会检查各个group是否存在阻塞出现，一旦出现阻塞，则会创建新的线程去处理请求  更多细节  一个连接可以被一个group中的一个或多个worker线程处理的 listener线程不是固定的 listener线程是通过epoll的方式来监听group中的连接事件的。  连接推荐 MYSQL线程池总结 https://www.cnblogs.com/cchust/p/4510039.html
MySQL线程池问题个人整理 https://cloud.</description>
    </item>
    
    <item>
      <title>mysql-mysql中操作系统的知识补充</title>
      <link>http://nber1994.github.io/posts/mysql%E4%B8%AD%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/mysql%E4%B8%AD%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/</guid>
      <description>磁盘上的扇区和块大小  扇区是512字节 块是4k 扇区是对于磁盘来说的，而块是对于文件系统来说的  </description>
    </item>
    
    <item>
      <title>mysql常见问题</title>
      <link>http://nber1994.github.io/posts/mysql%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/mysql%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</guid>
      <description>innoDB和MyIsAm引擎的区别 什么是存储过程，视图，触发器和事件 存储过程 存储过程就是一组完成特定功能的sql语句集合，经过编译后存储在mysql中，通过名字+参数进行调用 但是mysql的存储过程相对较弱使用较少
视图 视图两种方式，一个是简历临时表，另一个是合并算法
主键的作用， 索引，内存管理 外键完整性约束 join 链接 join和inner join是等价的
Mysql只支持两种内连接和外连接
对于left join来说，类似
slelect on where
会先根据on条件生成临时表 where在临时表的基础上进行数据筛选 所以连表查询会建立临时表
mysql为什么要使用线程池 随着DB访问量的增加，DB的响应时间会越来越长，同时吞吐量也会增加 使用线程池之后，可以减少线程的重复创建和销毁的开销，同时由于对线程数量做了限制，所以可以防止内存雪崩，对系统起到保护作用
你常会用到的关于mysql的规范  总体来说，mysql不善于存储大图片和大文件，同时禁止使用存储过程视图，触发器等 同时使用utf8mb4编码  </description>
    </item>
    
    <item>
      <title>mysql架构</title>
      <link>http://nber1994.github.io/posts/mysql%E6%9E%B6%E6%9E%84/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/mysql%E6%9E%B6%E6%9E%84/</guid>
      <description>各模块之间的配合工作 初始化 Mysql启动之后，初始化模块会将读取配置文件和命令行参数去初始化整个系统，比如申请buffer或者初始化数据结构 同时会初始化各个存储引擎
监听请求 初始化之后，会将控制权交给连接管理模块，接收客户端请求
当客户端连接上之后，双方会根据协议相互确认后，连接管理器会请求线程管理器去请求分配连接线程，分配线程进行处理
线程管理模块拿到请求后，调用用户模块对用户进程授权检查，线程处理模块会检测是否有cache的线程，如果没有则新建一个线程返回
之后会进行query的判断，如果是command命令，则不需要进行解析，直接执行，如果是sql相关的，则转发给query解析器，query判断出是select指令，会调用query cache进行读取，有则直接返回结果。如果失败，则会回传给query解析器
switch sejlect语句： 调用查询缓存，失败后调用查询优化器，对query进程查询优化 ddl&amp;amp;dml语句： 交给表管理模块 更新统计信息&amp;amp;检测&amp;amp;整理: 调用表维护模块 复制相关的： 调用复制模块 请求状态： 调用状态收集模块 所有模块拿到请求之后，会先请求访问控制模块检查链接用户是否有操作权限，如果有则调用表管理模块请求相应表获取对应的锁
拿到打开表之后，会根据表相关的meta数据，判断标的存储引擎类型，根据相关的类型转发给相关的存储引擎。
当一个query或者command完成后，控制权会传给连接管理模块。并将返回结果或者错误信息返回给连接
在这之间，如果数据发生了变化，则日志处理模块也会生成binlog
各个模块的操作都十分以来内部API
相关连接 MySQL 系统架构 说明 https://blog.csdn.net/tianlesoftware/article/details/7029112</description>
    </item>
    
    <item>
      <title>mysql知识树</title>
      <link>http://nber1994.github.io/posts/mysql%E7%9F%A5%E8%AF%86%E6%A0%91/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/mysql%E7%9F%A5%E8%AF%86%E6%A0%91/</guid>
      <description>mysql架构  mysql层的结构 查询优化器 join 连表查询 binlog ddl/dml/sql 查询缓存 查询优化 explain sql军规 外键完整性约束  连接池  连接on-thread-per-con 线程池  存储引擎  存储引擎的区别  InnoDB：  三大特性 索引 ： 索引覆盖 B+，hashmap，聚簇索引，前缀，全文索引 索引建立的规则 事务&amp;amp;隔离级别 当前读，快照度 mvcc 锁 事务实现 acid redo log undo log  工程 分表分库分片 内存管理 </description>
    </item>
    
    <item>
      <title>mysql索引技巧</title>
      <link>http://nber1994.github.io/posts/mysql%E7%B4%A2%E5%BC%95%E6%8A%80%E5%B7%A7/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/mysql%E7%B4%A2%E5%BC%95%E6%8A%80%E5%B7%A7/</guid>
      <description>ps：平衡查找树
  B B+ https://zhuanlan.zhihu.com/p/27700617
  MySQL索引背后的数据结构及算法原理 http://blog.codinglabs.org/articles/theory-of-mysql-index.html
  联合索引结构原理 https://blog.csdn.net/weixin_30531261/article/details/79329722
  覆盖索引 https://yq.aliyun.com/articles/62419
  联合索引如何选取wherer http://hedengcheng.com/?p=577
 索引数据结构基础知识 平衡二叉树 平衡二叉树是基于二分法的策略提高数据查找速度的数据结构 B-tree 与平衡二叉树的区别是B树属于多叉树，每个节点多于两个查找路径 规则 B+树 B+树让查询速度更加稳定，完全趋近于二分查找
与B树的区别 特点：飞叶子节点中不保存记录指针，每个节点可以存更多的关键字，数据只保存在叶子节点，每次查询的速度一定
每个节点的出度增加，进而树高会降低，提高了查找速度。
为什么使用B/B+树 一般来说，索引本身都很大，所以一般会存在磁盘上，而相对于内存读取，读取磁盘的开销是十分大的，所以衡量一个索引性能的一个标准
就是一次查询IO的次数
mysql索引实现 MyIsAM索引结构是通过B+树实现的，叶子节点存放的是数据的地址
而对于辅助索引来说，其结构和主键索引没有任何区别
 这类索引成为非聚簇索引，即数据和索引文件是分开的
 InnoDB索引实现  对于InnoDB来说，数据本身就是主索引文件，
 因为索引和数据是被保存在一起的，与MyIsAm不同的是，InnoDB的B+树的叶子节点
包含完整的数据行记录，因而该索引称为聚簇索引
因而InnoDB表必须有主键，如果没有的话，InnoDB会自动隐世的创建主键索引
 另外对于InnoDB引擎来说，辅助索引叶子节点存储的是主键的值而不是地址
 因而InnoDB检索需要经过两边索引：首先通过辅助索引拿到主键的值，在检索一遍主键索引
因而不建议将索引做的过大，因为会导致过大的索引文件
不单调的字段作为索引会导致数据插入时频繁的分裂调整
索引使用策略&amp;amp;优化 最左前缀原理&amp;amp;优化 SHOWINDEXFROMemployees.titles;+--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+ |Table|Non_unique|Key_name|Seq_in_index|Column_name|Collation|Cardinality|Null|Index_type|+--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+ |titles|0|PRIMARY|1|emp_no|A|NULL||BTREE||titles|0|PRIMARY|2|title|A|NULL||BTREE||titles|0|PRIMARY|3|from_date|A|443308||BTREE|+--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+  情况一：全列匹配
 EXPLAINSELECT*FROMemployees.titlesWHEREemp_no=&amp;#39;10001&amp;#39;ANDtitle=&amp;#39;Senior Engineer&amp;#39;ANDfrom_date=&amp;#39;1986-06-26&amp;#39;;+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+ |id|select_type|table|type|possible_keys|key|key_len|ref|rows|Extra|+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+ |1|SIMPLE|titles|const|PRIMARY|PRIMARY|59|const,const,const|1||+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+ where后的字段InnoDB会自动调整顺序</description>
    </item>
    
    <item>
      <title>mysql资源汇总</title>
      <link>http://nber1994.github.io/posts/mysql%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/mysql%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/</guid>
      <description>MySQL也有了几年了，说不出来个所以然，认知比较肤浅。所以需要加深学习呀，这里是学习过程中收集的一些好的资源，希望大家共同进步了。不是很系统的整理，看到了就记录了下来。
 官方文档必须要优先看滴呀！本文Github地址
博客 前辈们的博客就是他们成长的足迹。
  DimitriK&amp;rsquo;s (dim)
  MATSUNOBU Yoshinori MHA作者
  玄惭 阿里
  何登成 阿里
  叶金荣 知数堂
  姜成尧 网易
  杨奇龙 支付宝
  penglixun 阿里
  王朝阳
  大师兄
  吴老师 知数堂
  黄杉
  周振兴 一个故事@MySQL DBA
  for dba
  那海蓝蓝的博客 Oracle 对mysql，pg都比较多
  四爷 msyql，pg很多对比</description>
    </item>
    
    <item>
      <title>redis一致性hash算法</title>
      <link>http://nber1994.github.io/posts/redis%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%AE%97%E6%B3%95/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%AE%97%E6%B3%95/</guid>
      <description>redis-一致性hash算法 http://www.zsythink.net/archives/1182 https://zhuanlan.zhihu.com/p/34985026 一致性hash算法</description>
    </item>
    
    <item>
      <title>redis事件</title>
      <link>http://nber1994.github.io/posts/redis%E4%BA%8B%E4%BB%B6/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E4%BA%8B%E4%BB%B6/</guid>
      <description>redis是一个事件驱动程序
  他需要处理两类事件  文件事件  文件事件就是对套接字的抽象，服务器与客户端之间的通信会产生相应的时间事件，服务器通过监听这些事件完成网络操作   时间事件  时间事件就是一些操作需要在特定的时间完成      文件事件  redis通过reacter模式开发了自己的文件事件处理器  文件事件处理器通过IO多路复用程序来监听多个套接字，并为套接字绑定了多个事件处理程序 当一个套接字准备好accept，read，write，close等操作时，会产生相应的事件，这时事件处理程序就会调用相应的处理程序   使用IO多路复用模型，可以在实现高性能的网络响应模型的同时，保持了系统的简单性  文件事件处理器的构成  文件事件处理器包括套接字，IO多路复用处理程序，文件事件分派器，事件处理程序 文件事件其实是对套接字操作的抽象 IO多路复用程序监听多个套接字，多个文件事件可能并发的出现，IO多路复用程序会将并发事件放在一个队列中，有序的同步的传递给文件事件处理程序 只有处理完一个文件事件之后，IO多路复用才会去处理下一个文件事件 文件事件分派器会将不同的文件事件分派给不同的文件时间处理程序  IO多路复用实现 redis使用的是c标准的select，poll，epoll等标准函数库，同时为这些库实现了相同的API，所以底层是可以互换的
文件事件的类型  文件事件分为AE_READABLE事件和AE_WRITABLE事件
  当套接字可读时，即客户端准备对套接字进行write，或者有新的可应答套接字出现时，套接字产生AE_READABLE事件（write, close，accept） 当套接字变得可写时，客户端对套接字执行read操作，会产生AE_WRITEABLE事件（read） 同时IO多路复用还支持同时监听套接字两种事件，如果两种事件同时出现，优先处理AE_READABLE事件  文件事件处理器  redis为文件事件编写了多个处理器
  为了对客户端进行应答，服务器为客户端关联链接应答处理器 为了接收客户端的命令请求，服务器为客户端关联命令请求处理器 为了向客户端返回命令结果，服务器要为客户端关联命令回复处理器  连接应答处理器 当系统刚初始化完成时，redis会将连接应答处理器和AE_READABLE事件关联起来
命令请求处理器 在客户端连接服务器的整个过程中，服务器会一直讲命令请求服务器和AE_READABLE事件关联起来
命令回复处理器  当服务器有命令结果需要返回给客户端时，会将命令回复处理器和AE_WRITEABLE事件绑定起来 当套接字变为可写时，会产生AE_WRITEABLE事件，命令回复处理器会将结果返回给客户端 之后，会接触命令回复处理器和AE_WRITEABLE事件的绑定  一次完整的客户端和服务器链接过程 时间事件  定时时间和周期型事件 一个时间事件有三个属相组成  id，递增id，新事件比老的事件id大 when，记录了事件的到达时间 timeProc，时间事件处理函数    时间事件的实现  服务器将所有的时间事件都放在一个无需链表里，每当时间事件执行器运行时，就会便利这个链表   事件事件应用实例：serverCron函数  redis中的事件事件任务都有serverCron函数负责执行，他的任务包括  更新服务器的各类统计信息，比如时间，内存占用，数据库占用等 清理数据库过期的键值对 关闭和清理链接失效的客户端 尝试进行RDB和AOF持久化操作 如果是主服务器则对从服务器定期同步 集群模式则对集群定期进行同步和连接测试    主循环处理文件事件和时间事件的伪代码  获取最接近的时间事件的还有多久到达 将该秒数传入IO监听函数，两个条件满足一个会向下执行  时间事件到达 IO多路复用监听到文件事件产生   然后先执行文件事件 后执行时间事件   因为文件事件在时间事件之前执行，所以时间事件往往会比设定事件稍晚一点执行</description>
    </item>
    
    <item>
      <title>redis事务</title>
      <link>http://nber1994.github.io/posts/redis%E4%BA%8B%E5%8A%A1/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E4%BA%8B%E5%8A%A1/</guid>
      <description> redis通过multi，exec，watch等命令实现事务功能 事务提供了一种将多个命令打包，一次性顺序执行的多个命令的机制  事务实现  事务开始 命令入队 事务执行  事务开始  multi命令可以将执行该命令的客户端从非事务状态切换为事务状态  将客户端的flag属性变为redis_multi    命令入队  当处于非事务状态下，客户端发送的命令会立即执行 当处于事务状态下，  客户端发送的exec，discard，watch，multi命令会立即执行 除了以上命令，服务器并不执行，而是放入一个事务队列中，返回quneued    事务队列  每个客户端都有一个事务状态，  typedef struct redisClient { //事务状态  multiState mstate; } redisClient;  每个事务状态包含一个事务队列，一个已入队命令计数器  typedef struct multiState { //事务队列，FIFO顺序  multiCmd *commands; //已入队命令计数  int count; } 事务对列是一个multiCmd的数组
typedef struct multiCmd { //参数  robj **argv; //参数数量  int argc; //命令指针  struct redisCommand *cmd; } 执行事务  当服务器收到客户端传来的exec命令时，会立即执行事务队列中的命令 并将执行结果返回给客户端  watch命令  watch是一个乐观锁，可以在exec执行之前，监视任意数量的数据库键 当exec执行时，如果监视的键被修改了，则事务就会拒绝提交   watch命令监听数据库键 typedef struct redisDb { //正在被watch命令监听的键  dict *watched_keys; } RedisDB;  watched_keys的键为键名， 而值则是一个链表，每个链表代表一个监听该键的客户端  监听的触发  对数据库的修改命令，set lpush sadd等，会检查watched_keys字典 如果有客户端正在监听键时，会遍历watched_keys[key]对应的client的REDIS_DIRTY_CAS标识打开，标识事务安全性已被破坏 当事务exec时，会根据REDIS_DIRTY_CAS是否打开，来决定事务是否能提交  事务的ACID  原子性 ok  redis的事务不支持回滚，有一条命令出错后，其他的命令继续执行   一致性  事务提交之后，不包含非法或者无效的错误数据 redis通过错误检查和简单的设计来避免一致性  入队错误：命令入队时，命令不存在或者不正确，redis拒绝执行事务 执行错误：执行中发生了错误，服务器也不会终端事务，其他的命令并不会受错误命令的影响     隔离性 ok 单线程 持久性  无持久化：不具有持久性 RDB持久化：不具有耐久性 AOF持久化，appendsync为always时具有    重点回顾 </description>
    </item>
    
    <item>
      <title>redis持久化-RDB</title>
      <link>http://nber1994.github.io/posts/redis%E6%8C%81%E4%B9%85%E5%8C%96-rdb/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%8C%81%E4%B9%85%E5%8C%96-rdb/</guid>
      <description> redis持久化-RDB
  二进制文件 一个服务器的所有非空数据库的所有的键值对成为数据库状态 redis是一个内存型数据库，为了解决持久化问题，引入了RDB持久化和AOF持久化  RDB文件的创建与载入  创建  RDB文件可以由save和bgsave命令生成 save会阻塞服务器进程，知道save命令结束，否则不会接受任何请求 gbsave命令则不同，他会派生一个子进程来进行任务，并不会阻碍redis的正常请求   载入  RDB文件的载入是在服务器启动时，检测到存在RDB文件的话就会自动载入RDB文件   值得一提的是，由于AOF文件更新的频率比RDB更快，所以redis会优先选择AOF文件来还原数据库状态 当没有开启AOF持久化功能时，才会采用RDB文件来恢复  save和bgsave的互斥性  在bgsave期间，bgsave和save服务器会拒绝，这是因为为了防止竞争产生 bgsave和bgrewariteaof也不能同时执行，虽然没有什么冲突，但是为了性能考虑  载入状态下服务器的状态  阻塞  对自动保存的设置  redis允许用户对bgsave的频率进行设置 其中设置频率会设置两个指标  dirty计数器表示了上次save之后修改的键的数目 lastsave 上次bgsave的时间   serverCron会定期的检查是否满足save的条件，从而进行保存  RDB文件的结构  REDIS是最开头的部分，保存着REDIS来标识是否是RDB文件 db_version标识RDB版本 databases包含着0或多个数据库的键值对数据 EOF标识着RDB文件结束 check_sum是根据其他部分计算出来的，用来校验RDB文件是否有损坏  database部分  每个databases包含着三个部分  selectdb 标志着是一个database段的开始 db_number标识出是哪个数据库 key_valud_pairs 存储着键值对    key_value_pairs部分  type标识是哪种对象和实现方式 EXPIRETIME 标志位，标识接下来读入的是一个到期时间 ms 到期的时间戳  重点回顾 </description>
    </item>
    
    <item>
      <title>redis数据库</title>
      <link>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E5%BA%93/</guid>
      <description>struct redisServer { //一个数组，保存所有数据库  redisDb *db; //数据库的数量  int dbnum; }  在数据库初始化时，会根据服务器状态属性dbnum来决定初始化多少的数据库 默认情况下时16个  切换数据库  在服务器上，每个客户端都会有一个对应的数据结构，记录客户端的状态  typedef struct redisClient { //记录当前的数据库  redisDb *db; }  默认情况下会使用0号数据库 select 命令的实现就是通过切换redisDb指针的值来切换数据库  数据库键空间  redis是一个键值对数据库，每个数据库都有对应的redisDb结构 所有的键值对都保存在redisDb中的dict中  typedef struct redisDb { //数据库键空间，存储所有的键值对  dict *dict; //过期字典  dist *expire; } redisDb;  键空间和用户所见的键值对是直接对应的 其对键值对的操作都对应字典对于键值对的操作 其他对于数据库的操作  比如flushDB就是直接删除键空间 randomkey就是在键空间中随机返回一个键 dbsize直接返回键空间的大小    读写键空间时的维护操作  读写一个键之后，会更新键空间中的hit和miss属性 更新该键对象的lru时间 判断是否过期，过期则删除改建 如果使用了watch命令监视了该键，则会将该键标记为dirty 修改一个键之后，会对dirty计数器加一，从而引发持久化和复制操作 如果开启了消息通知功能，则会发送相关的消息  键值的过期时间  设置过期命令  expire 设置生存时间为多少秒 pexpire 设置生存时间为多少毫秒 expireat 将过期时间设置为xxxs pexpireat 将过期时间设置为xxxms   其实四个命令都是以pexpireat实现的  保存过期时间  保存过期时间都是通过expire子弹实现的  键是一个指向了dict中对象的地址 键值为一个时间戳     移除过期时间  persist 命令就是讲某个键值在expire字典中删除即可  过期键的删除策略  常见的国期间删除策略  定时删除  在一定时间间隔后，将键空间的过期键全部删除 优点：对内存比较友好，定期删除节省内存空间 缺点：对cpu不友好，当有大量的过期键需要删除时，会造成服务的中断   惰性删除  每次读写某个键之前判断是否已经过期 优点：对cpu较友好，不会占用太多的cpu资源 缺点：对于内存不友好，如果大量的过期键没有访问，则会占用大量的内存资源   定期删除  每隔一段时间，会对数据库键进行检查，删除一部分的过期键 定时并以一定量删除的方式，减少了cpu的占用 同时也解决了过期键带来的内存浪费      redis的过期删除策略  配合使用定期删除和惰性删除两种策略 定期删除策略  由serverCron函数执行，在规定的时间内，分多次便利所有数据库，随机的删除过期键 全局便利current_db记录了当前的进度，到达16之后会归0    AOF和RDB以及复制功能对过期键的处理 RDB  save和bgsave生存RDB文件时，会进行检查，不会讲过期键存入RDB文件中 载入RDB文件时  主服务器模式下，会对键值进行检查，舍弃过期键 从服务器模式下，不会检查，全部载入。但是一般复制时会将数据库全部删除，所以一般不会造成影响    AOF  在AOF持久化时，不会对过期键值过滤，因为当惰性删除和定期删除之后，会写入一条del AOF重写时，会对过期键进行过滤  复制  主服务器删除一个键之后，会显示的向所有从服务器发生del命令 从服务器在执行客户端命令时，并不会判断键是否过期，而是返回结果 只有得到主服务器的del命令，才会删除 这种方式，可以保持主从的一致性  重点回顾 </description>
    </item>
    
    <item>
      <title>redis数据结构-压缩列表</title>
      <link>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8/</guid>
      <description>压缩列表是列表建和哈希键的底层实现之一 压缩表是一系列有特殊编码组成的顺序型的数据结，可以保存字节数组和整数值  压缩表结构  zlbytes：记录整个压缩表的字节长度 zltail：记录尾节点的距离列表起始地址有多少字节 zllen：记录存在节点的数目 entryX：压缩表包含的节点，长度由保存内容决定 zlend：特殊值，标明压缩表的结尾  压缩表节点结构  prev_entry_length 前一个节点的长度，prev_entry_length可以是1字节或者5字节  当前一个节点的长度小于254字节时，prev_entry_length为一个字节 当前一个节点的长度大于254字节时，prev_entry_length为5字节 遍历：当想要遍历一个压缩表时，会根据zltail首先跳转到最后的节点，然后根据prev_entry_length节点向前遍历   encoding 编码  encoding记录着节点content的长度和数据类型   content 内容  content的值的类型由encoding来决定    连锁更新  如果存在这一一种情况的数组，每个节点的长度都在250到254之间时，当向前一个节点的插入一个大于254长度的节点，后一个节点会更新期prev_entry_length的长度，使该节点的长度也大于了254，这样将导致一系列的内存重分配操作 除了插入操作，删除操作也会导致连续更新的操作 在连续更新的情况下，最坏为O（N^2） 连续更新操作大量出现的概率比较小，所以压缩表的平均还是为O(N)  重点回顾 ？？压缩表优点 内存中以连续快存放，载入速度更快</description>
    </item>
    
    <item>
      <title>redis数据结构-字典</title>
      <link>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%AD%97%E5%85%B8/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%AD%97%E5%85%B8/</guid>
      <description>字典是一个用于保存键值对的数据结构 字典的键为独一无二的 redis的数据库就是使用字典实现的 hash键的底层实现  hash表结构 哈希表结构 typedef struct dictht { //哈希表数组  dictEntry **table; //哈希表大小  unsigned long size； //哈希表大小掩码，用于计算索引值，总之等于size-1  unsigned long sizemask; //该哈希表已有节点的数量  unsigned long used; } table是一个数组，数组中的每个元素都是指向dictEntry结构的指针，每个dictEntry保存这一个键值对 hash节点 typedef struct dictEntry { //键  void *key; //值  union { void *val; uint64_tu64; int64_ts64; }v; //指向下一个hash节点，形成链表  struct dictEntry *next; } dictEntry; 其中next可以连接相同的节点，可以通过这个指针将相同哈希值的多个键值对节点连接起来，来解决哈希冲突的问题 字典结构 字典由如下结构表示：
typedef struct dict { //类型特定函数  dictType *type; //私有数据  void *privData; //哈希表  dictht ht[2]; //rehash索引  //当rehash不进行时，值为-1  int trehashidx; }  ht属性是一个包含两个项的数组，一般情况下，使用ht[0],ht[1]只用来进行rehash操作 trehashidx记录了rehash的进度   hash算法 hash算法根据键值，计算出哈希值，在结合sizemask的值，计算出索引值 向hash表添加一个键值对时，先根据hash算法计算出键值对的哈希值和索引值 再根据索引值确定新的哈希表节点放到指定索引上</description>
    </item>
    
    <item>
      <title>redis数据结构-跳跃表</title>
      <link>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E8%B7%B3%E8%B7%83%E8%A1%A8/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E8%B7%B3%E8%B7%83%E8%A1%A8/</guid>
      <description> 跳跃表通过每个节点位置多个指向其他节点的指针来实现快速访问 跳跃表可以实现最好O(logN)，最坏O(N)的节点查找，同时可以顺序操作批量处理 redis的应用，一个是在有序集合中使用了跳跃表，同时在集群节点中作为内部数据结构使用  结构 跳跃表由zskiplistNode和zskiplist结构组成 对于跳跃表结构: typedef strut zskiplist { //表头节点和表尾节点  struct zskiplistNode *header, *tail;; //表节点的数量  unsigned long length； //表中层数最大值  int level } zskilplist;  header: 指向表头节点的指针 level：跳跃表中level最大的level值，不包括表头结点 length：跳跃表中包含节点的个数，不包含表头  对于跳跃表节点结构： typedef struct zskiplistNode { //层  struct zskiplistLevel { //前进指针  struct zskiplistNode *forward; //跨度  unsigned int span; } level[]; //后退指针  struct zskiplistNode *backward; //分值  double score; //成员对象  robj *obj; } zskiplistNode;  level：每个节点在初始化时，会分配给其一个1-32之间的level，每个level包含一个前进指针和跨度，前进指针用于访问队尾其他的节点，而跨度记录了本节点到前进指针所指节点的距离；一般来说层数越多，访问其他节点的速度越快  对于跨度，其实是用来计算某个节点在列表中的排位的   bw：后退指针，后退指针用于访问该节点的前一个节点。 score：分值，保存各个节点的分值。跳跃表中的节点是按照分值从小到大排列的。score是一个double型 obj：保存成员对象， 成员对象指向一个字符串对象，其保存一个SDS 注意：头节点同样存在后退指针，分值和成员对象，但是一般不使用 注意：当节点的score值相同时，但是成员变量不能重复，会按照成员对象在字典中的大小进行排序  重点回顾 </description>
    </item>
    
    <item>
      <title>Redis概述</title>
      <link>http://nber1994.github.io/posts/redis%E6%A6%82%E8%BF%B0/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%A6%82%E8%BF%B0/</guid>
      <description>redis是一个key-value形式的单线程的内存型数据库
数据结构与对象 redis每个键值对都是由对象组成的
 数据库键总是一个字符串对象 数据库的键值可以是字符串对象，列表对象，哈希对象，集合对象，有序集合对象其中的一种  单机数据库的实现  服务器保存键值对的原理，对过期的方法，自动删除过期键值的方法 持久化 RDB持久化和AOF持久化， 生成方法和恢复方式 bgsave和bgwriteaof实现原理 事件  文件事件 时间事件   管理客户端  妈的，什么也没有看，写这个真的蛋疼，待续吧</description>
    </item>
    
    <item>
      <title>redis相关资源</title>
      <link>http://nber1994.github.io/posts/redis%E7%9B%B8%E5%85%B3%E8%B5%84%E6%BA%90/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E7%9B%B8%E5%85%B3%E8%B5%84%E6%BA%90/</guid>
      <description>redis相关资源 掘金-常见问题 https://zhuanlan.zhihu.com/p/32540678 https://www.jianshu.com/p/85d55f2ffd0a</description>
    </item>
    
    <item>
      <title>redis集群</title>
      <link>http://nber1994.github.io/posts/redis%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E9%9B%86%E7%BE%A4/</guid>
      <description>redis集群通过分片来进行数据共享，并且提供复制和故障转移的功能  节点  一个集群是由多个节点组成 CLUSTER MEET ip port 命令用于将节点加入自己的集群中 集群中每个节点会维护的数据结构  clusterNode 保存了节点的状态，比如创建时间，名字，配置纪元，节点ip port等 clusterLink clusterState    clusterNode struct clusterNode { //创建时间  mstimer_t ctime; //节点的名字  char name[REDIS_CLUSTER_NAMELEN]; //节点标识  //主从节点，上线下线  int flags; //当前配置纪元，用于故障转移  uint64_t configEpoch; //节点IP  char ip[REDIS_IP_STR_LEN]; //节点端口  int port; //保存连接节点所需的信息  clusterLink *link; //保存节点的槽指派信息  unsigned char slots[16384/8]; //槽指派的个数  int numslots； //复制的节点  struct clusterNode *slaveof; } clusterLink  clusterLink保存了连接节点所需的信息  typedef struct clusterLink { //连接创建时间  mstime_t time; //TCP套接字描述符  int fd; //输出缓冲区,保存待发给其他节点的消息  sds sndbuf; //输入缓冲区，保存着从其他节点接收到的消息  sds revbuf; //与这个连接相关联的节点，没有就为null  struct clusterNode *node; } clusterLink;  redisClinet和clusterLink结构很像，但是redsiClient对应的是客户端的链接信息，而clusterLink对应的是和其他节点的连接信息  clusterState  该结构保存了在当前节点的视角下，整个集群的状态  typedef struct clusterState { //指向当前节点的指针  clusterNode *self; //集群当前的配置纪元，用于实现故障转移  uint64_t currentEpoch; //集群当前状态：上线还是下线  int state; //集群中至少处理一个槽的节点的数量  int size; //集群单节点名单（包括自己）  dict *nodes; //记录了集群中槽的指派情况  clusterNode *slot[16384]; //正在导入的槽的节点  clusterNode importing_slots_from[16384]; } clusterState; 集群 cluster meet实现  当cluster meet ip port指向B  节点A会为B在自己的clusterState.</description>
    </item>
    
    <item>
      <title>tcp与udp区别</title>
      <link>http://nber1994.github.io/posts/tcp%E4%B8%8Eudp%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/tcp%E4%B8%8Eudp%E5%8C%BA%E5%88%AB/</guid>
      <description>tcp和ip是互相互补的
 TCP协议 tcp基于字节流的传输层协议，位于应用层之下，完成的是IP协议完成不了的可靠传输
IP协议 IP协议是不可靠的，负责在原地址和目的地址之间传输，他只关心跨越本地网络边界问题，寻址和路由
分层  应用层  http ftp telnet dns   传输层  tcp udp   网络层  IP 负责路由寻址 ARP 地址解析协议获取统一物理网络中的物理地址 ICMP 控制消息协议 传送错误和控制信息 IGMP 组管理协议 用来实现本地广播   数据链路层   tcp/ip或者udp/ip中，唯一确认一个连接为五个元素  源IP 源端口号 协议 目的IP 目的端口号    端口号  既定端口号  telnet 23 ssh 22 fpt 21 http 80 mysql 3306 redis 6379   时序分配  交给操作系统进行分配    udp  无连接 没有流量控制 不保证包的顺序性  应用场景  即时通信 广播通信 包总量较少通信  tcp  充分实现了数据传输时的各种控制功能  丢包重传 分包保持顺序 面向连接    通过序列号和确认应答提高可靠性 确认应答  接受端收到消息后会返回一个已经收到的消息通知，叫做ACK 如果收到的消息不理解则会返回一个NACK 发送端发送一段时间之后没有收到ACK消息，则可以认定数据已经丢失，并进行重发  但是没有收到ACK也并不代表消息没有到达，也有可能是ack丢失  这种情况下也会导致发送端以为数据没有到达，进行重发 这种情况下，即使ack返回延迟了，发送端仍会重发包，而对于接收端来说  会受到重复数据，需要对数据进行去重      序列号  确认应答处理，重发控制，重复控制 序列号为每一个字节添加一个编号 接收端查询接收数据首部的序列号和数据长度，并将自己下一步应该接收的序号作为应答返回 通过序列号和确认应答号，实现可靠传输   重发超时如何确定  理想是找到一个最小时间，保证在该段时间内确认包一定能返回 但是该时间会根据网络情况不同而不同 每次发包都会计算往返时间和偏差 重发时间就是往返时间加上偏差时间稍微大一点 一般超时重发时间都是0.</description>
    </item>
    
    <item>
      <title>存储</title>
      <link>http://nber1994.github.io/posts/%E5%AD%98%E5%82%A8/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E5%AD%98%E5%82%A8/</guid>
      <description>存储  存储在不同的存储器的速度   随机访问存储器
  静态RAM和动态RAM SRAM既可以在芯片上，也可以在芯片下   访问主存   总线事务 读事务是从主存传输数据到cpu 写事务是从cpu传输数据到主存  Cpu通过系统总线链接I/O桥，主存通过内存总线链接I/O桥
读事务： 1.cpu将地址放在系统总线中，通过I/O桥传给内存总线传递给内存 2.内存感知到内存总线传递来地址，读出地址数据，并传递到内存总线上 3.cpu感受到系统总线传递的数据，并将其复制到寄存器中
写事务： 1.cpu将需要写数据的地址传递给内存，内存读出地址等待数据 2.cpu将数据写入系统总线 3.内存从内存总线拿到数据，写入DRAM中
DRAM速度比磁盘快10万倍，SRAM比磁盘快100万倍
磁盘 盘面：磁盘是由一些盘面组成的，每个盘面上下都可以使用 磁道：磁道是一组同心圆 扇区：一个磁道分为一组扇区，扇区之前尤一些间隙隔开 柱面：是所有盘面表面到主轴中心距离相等的磁道的集合
磁盘读写 磁盘通过读写头对磁盘进行读写，读写头位于机械臂头部，通过前后摆动进行寻道操作，同一个时刻上，读写头都位于一个柱面
磁盘读写速度 磁盘的读写速度受三个时间影响： 寻道时间+旋转时间+传送时间 影响类型	时间 寻道时间	3-9ms 旋转时间	同上 传送时间	可忽略
访问磁盘 Cpu当前的进程访问磁盘时，会将命令，逻辑块号和内存地址写入到磁盘控制器 磁盘控制器读出数据，直接存入内存相关地址（DMA） 磁盘控制器发出一个中断给cpu
设备可以直接执行写或者读总线事务，而不经过cpu，成为直接内存访问DMA</description>
    </item>
    
    <item>
      <title>问题汇总</title>
      <link>http://nber1994.github.io/posts/%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</guid>
      <description>问题汇总 OS 虚拟内存 段页式 倒排页表 LRU，LFU算法实现 共享内存 多进程，多线程 如何fork一个进程 exec waitpid exit 页表的copy-on-worite PCB
 PCB process control block &amp;gt; task_struct存储了进程的页表，打开文件描述符表，内存描述符，通用寄存器，进程状态等
 进程状态 IO多路复用 select，poll，epoll实现和优劣
用户态和内核态区别 进程，线程间通信 什么时候多线程什么时候多进程 线程ID进程组ID 线程和进程的切换和调度，切换的时什么 多进程 - 数据共享复杂，需要进程间通信 - 相对于多线程占用更多的内存 - 进程间切换相对于多线程开销较大 - 编程调试较简单 - 进程间互相不影响 - 适用于多机，性能扩展性较好 多线程 - 数据共享较简单 - 线程间可能会互相影响 - 编程调试较复杂 - 可以利用多核的优势 - 多线程之间切换开销较小
 文件描述符表  网络 http https https相比较于http来说，在会话层加入了stl算法加密，过程如下 1.服务端发送来证书和公钥 2.客户端根据内置的颁发机构验证证书的真伪 3.如果证书为假，则报错 4.如果证书为真，则生成随机值，并用公钥加密传递给服务端 5.服务端收到后使用私钥进行解密，拿到随机值 6.之后的通信都使用随机值进行加密
http code 200 ok 301 moved permanly 302 Found 303 See Other 400 Bad Request 401 Nuauthorized 403 forbidden 404 Not Found 500 internal server error 502 bad gateway 503 service unavaliable 504 gateway timout</description>
    </item>
    
    <item>
      <title>sunday</title>
      <link>http://nber1994.github.io/posts/sun-day/</link>
      <pubDate>Tue, 11 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/sun-day/</guid>
      <description></description>
    </item>
    
    <item>
      <title>转 Innodb中的事务隔离级别和锁的关系</title>
      <link>http://nber1994.github.io/posts/%E8%BD%AC-innodb%E4%B8%AD%E7%9A%84%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E5%92%8C%E9%94%81%E7%9A%84%E5%85%B3%E7%B3%BB/</link>
      <pubDate>Wed, 15 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E8%BD%AC-innodb%E4%B8%AD%E7%9A%84%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E5%92%8C%E9%94%81%E7%9A%84%E5%85%B3%E7%B3%BB/</guid>
      <description>转自美团技术博客
  前言: 我们都知道事务的几种性质，数据库为了维护这些性质，尤其是一致性和隔离性，一般使用加锁这种方式。同时数据库又是个高并发的应用，同一时间会有大量的并发访问，如果加锁过度，会极大的降低并发处理能力。所以对于加锁的处理，可以说就是数据库对于事务处理的精髓所在。这里通过分析MySQL中InnoDB引擎的加锁机制，来抛砖引玉，让读者更好的理解，在事务处理中数据库到底做了什么。
 一次封锁or两段锁？ 因为有大量的并发访问，为了预防死锁，一般应用中推荐使用一次封锁法，就是在方法的开始阶段，已经预先知道会用到哪些数据，然后全部锁住，在方法运行之后，再全部解锁。这种方式可以有效的避免循环死锁，但在数据库中却不适用，因为在事务开始阶段，数据库并不知道会用到哪些数据。 数据库遵循的是两段锁协议，将事务分成两个阶段，加锁阶段和解锁阶段（所以叫两段锁）
 加锁阶段： 在该阶段可以进行加锁操作。在对任何数据进行读操作之前要申请并获得S锁（共享锁，其它事务可以继续加共享锁，但不能加排它锁），在进行写操作之前要申请并获得X锁（排它锁，其它事务不能再获得任何锁）。加锁不成功，则事务进入等待状态，直到加锁成功才继续执行。 解锁阶段： 当事务释放了一个封锁以后，事务进入解锁阶段，在该阶段只能进行解锁操作不能再进行加锁操作。     事务 加锁/解锁处理     begin；    insert into test &amp;hellip;.. 加insert对应的锁   update test set&amp;hellip; 加update对应的锁   delete from test &amp;hellip;. 加delete对应的锁   commit; 事务提交时，同时释放insert、update、delete对应的锁    这种方式虽然无法避免死锁，但是两段锁协议可以保证事务的并发调度是串行化（串行化很重要，尤其是在数据恢复和备份的时候）的。
事务中的加锁方式 事务的四种隔离级别 在数据库操作中，为了有效保证并发读取数据的正确性，提出的事务隔离级别。我们的数据库锁，也是为了构建这些隔离级别存在的。
   隔离级别 脏读（Dirty Read） 不可重复读（NonRepeatable Read） 幻读（Phantom Read）     未提交读（Read uncommitted） 可能 可能 可能   已提交读（Read committed） 不可能 可能 可能   可重复读（Repeatable read） 不可能 不可能 可能   可串行化（Serializable ） 不可能 不可能 不可能     未提交读(Read Uncommitted)：{允许脏读，也就是可能读取到其他会话中未提交事务修改的数据 提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读) 可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞  Read Uncommitted这种级别，数据库一般都不会用，而且任何操作都不会加锁，这里就不讨论了。</description>
    </item>
    
    <item>
      <title>一次tcp的交互细节</title>
      <link>http://nber1994.github.io/posts/tcp%E4%BA%A4%E4%BA%92%E7%BB%86%E8%8A%82/</link>
      <pubDate>Sun, 29 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/tcp%E4%BA%A4%E4%BA%92%E7%BB%86%E8%8A%82/</guid>
      <description>抓了一次tcp相关的交互细节，包括了建立连接，数据传输，断开连接
 11:03:11.802351 IP localhost.42740 &amp;gt; localhost.distinct: Flags [S], seq 2760393548, win 65495, options [mss 65495,sackOK,TS val 1215514771 ecr 0,nop,wscale 7], length 0 0x0000: 4500 003c 0bdf 4000 4006 30db 7f00 0001 E..&amp;lt;..@.@.0..... 0x0010: 7f00 0001 a6f4 270f a488 434c 0000 0000 ......&amp;#39;...CL.... 0x0020: a002 ffd7 0923 0000 0204 ffd7 0402 080a .....#.......... 0x0030: 4873 4893 0000 0000 0103 0307 HsH......... 11:03:11.802403 IP localhost.distinct &amp;gt; localhost.42740: Flags [S.], seq 1911463751, ack 2760393549, win 65483, options [mss 65495,sackOK,TS val 1215514771 ecr 1215514771,nop,wscale 7], length 0 0x0000: 4500 003c 0000 4000 4006 3cba 7f00 0001 E.</description>
    </item>
    
    <item>
      <title>tmux简单操作</title>
      <link>http://nber1994.github.io/posts/tmux%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</link>
      <pubDate>Mon, 16 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/tmux%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</guid>
      <description>简单记录一下tmux的应用
 tmux是啥 Tmux 是一个 BSD 协议发布的终端复用软件，用来在服务器端托管同时运行的 Shell。那么 Tmux 用起来是怎样的呢？看图： tmux能做啥 你是否曾经开过一大堆的 Terminal？有没有把它们都保存下来的冲动？Tmux 的Session就是做这件事情的！ 你可以随时退出或者进入任何一个 Session。每个 Session 有若干个 Window，每个 Window 又可以分成多个窗格（Pane）。 极大地满足 Terminal 用户的需求。
此外即使 iTerm/Terminal/Konsole 意外关闭也没关系，因为 Session 完全保存在 Tmux Server 中。 再次打开 Terminal 时只需 tmux attach 便可回到你的工作区，就像从未退出过一样。 如果希望重启电脑后仍然生效，你可能需要 动手写脚本 或者 使用插件。
安装使用 首先进行安装：
brew install tmux # OSX pacman -S tmux # archlinux apt-get install tmux # Ubuntu yum install tmux # Centos 强烈建议源码安装，使用最新版本 安装好后就可以启用一个Tmux Session了：
tmux new -s myname (可以指定Session名） tmux简单操作 在Tmux Session中，通过prefix + $可以重命名当前Session。其中 prefix 指的是tmux的前缀键，所有tmux快捷键都需要先按前缀键。它的默认值是Ctrl+b。</description>
    </item>
    
    <item>
      <title>Vim写的代码,每一行都是诗</title>
      <link>http://nber1994.github.io/posts/vim%E5%86%99%E7%9A%84%E4%BB%A3%E7%A0%81%E6%AF%8F%E4%B8%80%E8%A1%8C%E9%83%BD%E6%98%AF%E8%AF%97/</link>
      <pubDate>Sat, 10 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/vim%E5%86%99%E7%9A%84%E4%BB%A3%E7%A0%81%E6%AF%8F%E4%B8%80%E8%A1%8C%E9%83%BD%E6%98%AF%E8%AF%97/</guid>
      <description>Vim写的代码，每一行都是诗
 缘起 从我开始接触编码的第一天起，就一直在寻找一个趁手的编辑器, 从最初的notepad++,ultraedit,sublime，以及后来的phpstrom等一系列的编辑工具，虽然功能丰富，五花八门，我也一度在繁杂的编辑器之中意乱情迷，左顾右盼。但是当我第一次见到vim那丑陋的终端界面，贫乏的UI设计以及陡峭的吓人的学习曲线之后，我心想，就是它了!
Vi 早期的vi界面
作者 vim其实不是原创软件，而是从vi发展过来的，而vi的作者则另有其人:  ![bil joy](https://cdn.jsdelivr.net/gh/nber1994/fu0k@master/uPic/Bill_joy.jpg) 威廉·纳尔逊·乔伊（William Nelson Joy，1954年11月8日－），通称比尔·乔伊（Bill Joy），美国计算机科学家。与Vinod Khosla、Scott McNealy和Andy Bechtolsheim一起创立了太阳微系统公司，并作为首席科学家直到2003年。后来经营自己的风险投资公司HighBAR Ventures，也是知名投资公司Kleiner Perkins的合伙人。 主要成就：乔伊的童年是在密歇根州的乡村长大的，在密歇根大学获得电气工程学士学位之后，于1979年在加州大学伯克利分校获得电气工程与计算机科学硕士学位。学生期间，他开发了BSD操作系统。其他人以BSD为基础发展出了很多现代版本的BSD，最著名的有FreeBSD、OpenBSD和NetBSD，苹果电脑的Mac OS X操作系统也在很大程度上基于BSD。1986年，乔伊因他在BSD操作系统中所做的工作获得了Grace Murray Hopper奖。 除了BSD之外，他引人注目的贡献还包括TCP/IP、vi、NFS和C shell，如今这些软件都已经广泛的使用在Solaris、BSD、GNU/Linux等操作系统中，而且开放源代码给其他人无偿使用、改进，为自由软件的发展作出了极大的贡献。 ### 了解更多 [Bill Joy In TED](https://www.ted.com/speakers/bill_joy) 一些你可能感兴趣的 1.为什么是hjkl 为什么是这个键位呢，为什么不是wasd这四个键位呢? 当 Bill Joy 创建 Vi 文本编辑器时，他使用的机器机器是 ADM-3A 终端机，这机器就是把 HJKL 键作为方向键。自然而然，Bill Joy 也就用了相同的按键了。 
而wasd这样的现在比较经典的键位，首先出现是在1996年的电子游戏雷神之锤,而vi诞生与1976年
雷神之锤截图
2.为什么手指抽筋 为什么感觉Ctrl键，Esc键这么远，这么难用？ vi诞生与1976年，他的快捷键肯定不是为了现代电脑键盘布局设计的，所以使用起来肯定十分费劲，我们一起来看看ADM-3A的键盘布局
ADM-3A全貌 ADM-3A终端机的键盘 我们可以看到，esc在现在的tab键的位置，而ctrl键在caps lock键的位置上, 这也是unix键盘经典布局，ctrl在如此方便的位置上，这也就难怪vi会有很多的ctrl相关的快捷键了，更不用说另一个相同时期的emacs了.所以不要再抱怨vi每次ctrl组合键简直要把小指头按抽筋了，其实vi根本就不是为现代键位设计的
3.vi的衍生版本 由于bill joy是从 Ken Thompson 的ed编辑器基础上开发的,vi是衍生作品，所以除了拥有AT＆T源许可证的人之外，不能分发给其他人,所以直到1987年6月,才出现了实现部分vi功能的STEVIE，而我们现在的vim，则是从STEVIE发展来的
vi的局限性  vi此时还是没有buffer概念的，一次只能对一个文件进行编辑,并且功能单一 没有vim script的支持，无法语法高亮,自动缩进等 不支持插件,且不能跨平台  vim vim的启动页面</description>
    </item>
    
    <item>
      <title>lnmp报错too-big-header错误探究</title>
      <link>http://nber1994.github.io/posts/lnmp%E6%8A%A5%E9%94%99too-big-header%E9%94%99%E8%AF%AF%E6%8E%A2%E7%A9%B6/</link>
      <pubDate>Mon, 08 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/lnmp%E6%8A%A5%E9%94%99too-big-header%E9%94%99%E8%AF%AF%E6%8E%A2%E7%A9%B6/</guid>
      <description>之前遇到的一个偶发的错误，探讨下到底是怎么肥四
 1.背景 遇到nginx报出了如下的error，导致服务为502 bad gateway, 而且某些请求稳定复现，但是其他请求缺没有问题，正常返回,正常情况下，php的warning并不会导致流程的中断
2018/01/08 15:50:20 [error] 15477#0: *2941700922 upstream sent too big header while reading response header from upstream, client: xx.xx.xxx, server: test.com, request: &amp;#34;POST /test/test HTTP/1.1&amp;#34;, upstream: &amp;#34;fastcgi://127.0.0.1:xxxx&amp;#34;, host: &amp;#34;xxxxxx&amp;#34;, referrer: &amp;#34;xxxxxx&amp;#34; 一时之间不知道原因，唯一有异常的是warninig日志较多，推测可能是php-fpm会把warning日志加到response header头里,导致头部过大报错
php代码中存在类似与以下的错误片段：
&amp;lt;?php $a = [ &amp;#39;a&amp;#39; =&amp;gt; &amp;#39;123&amp;#39;, &amp;#39;b&amp;#39; =&amp;gt; &amp;#39;123&amp;#39;, &amp;#39;c&amp;#39; =&amp;gt; &amp;#39;123&amp;#39;, &amp;#39;d&amp;#39; =&amp;gt; &amp;#39;123&amp;#39;, ]; foreach ($a[&amp;#39;nber1994&amp;#39;] as $item) { /** do something... */ } 此时会报warning的错误，类似于
php message: php Warning: Invalid argument supplied for foreach() in XXXXX.</description>
    </item>
    
    <item>
      <title>vim无插件编程技巧</title>
      <link>http://nber1994.github.io/posts/%E6%97%A0%E6%8F%92%E4%BB%B6vim%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/</link>
      <pubDate>Wed, 13 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E6%97%A0%E6%8F%92%E4%BB%B6vim%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/</guid>
      <description>一般刚接触vim的时候，在熟悉了他的基本操作之后，一般都急于将自己的vim安装各种插件，已达到IDE的效果，个人认为，这些插件阻碍了vimer对vim的进一步学习，我也是这样，从熟悉了常用的vim操作之后，就迫不及待的将自己的vim堆砌插件改造成IDE，然后陷入无尽的关于vim与IDE那个好的无尽的争吵中,哈哈。但是过多的插件，反而会让你看不见vim真正的强大。突然有一天，我试着把vim的插件全部删除，探究如果没有插件，vim的使用是怎样的，后来发现，vim其实完全可以实现无插件编程，而且当你熟悉了这些操作之后，你会进一步领会vim的精妙。
 浏览代码 :E &amp;#34; ================================================================= &amp;#34; Netrw Directory Listing (n &amp;#34; /Users/jingtianyou &amp;#34; Sorted by name &amp;#34; Sort sequence: [\/]$,\&amp;lt;core\%(\.\d\+\)\=\&amp;gt;,\.h$,\.c$,\.cpp$,\~\ &amp;#34; Quick Help: &amp;lt;F1&amp;gt;:help -:go up dir D:delete R:rename s:sort- &amp;#34; ================================================================= ../ ./ .ShadowsocksX/ .Trash/ .bundle/ .cache/ .cheat/ .cisco/ .config/ .cups/ .gem/ .go/ .local/ .netease-musicbox/ .nvm/ .oh-my-zsh/ [netrw] format: unix; [1,3] :E  不用使用类似与Nerdtree插件，vim原生即可实现改功能
 这个界面中，你可以用 j, k 键上下移动，然后回车，进入一个目录，或是找开一个文件。你可以看到上面有一堆命令：
 【–】 到上级目录 【D】删除文件（大写） 【R】改文件名（大写） 【s】对文件排序（小写） 【x】执行文件 当然，打开的文件会把现有已打开的文件给冲掉——也就是说你只看到了一个文件。  补充命令 如果你要改变当前浏览的目录，或是查看当前浏览的目录，你可以使用和shell一样的命令：</description>
    </item>
    
    <item>
      <title>修改内核参数提高并发性能</title>
      <link>http://nber1994.github.io/posts/%E4%BF%AE%E6%94%B9%E5%86%85%E6%A0%B8%E5%8F%82%E6%95%B0%E6%8F%90%E9%AB%98%E5%B9%B6%E5%8F%91%E6%80%A7%E8%83%BD/</link>
      <pubDate>Mon, 11 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E4%BF%AE%E6%94%B9%E5%86%85%E6%A0%B8%E5%8F%82%E6%95%B0%E6%8F%90%E9%AB%98%E5%B9%B6%E5%8F%91%E6%80%A7%E8%83%BD/</guid>
      <description>如何修改linux内核参数提高并发数
 &amp;gt;修改用户进程可打开文件数限制  在Linux平台上，无论编写客户端程序还是服务端程序，在进行高并发TCP连接处理时，最高的并发数量都要受到系统对用户单一进程同时可打开文件数量的限制(这是因为系统为每个TCP连接都要创建一个socket句柄，每个socket句柄同时也是一个文件句柄)
 &amp;gt;查看 ~ ulimit -n 1024 这表示当前用户的每个进程最多允许同时打开1024个文件，这1024个文件中还得除去每个进程必然打开的标准输入，标准输出，标准错误，服务器监听 socket，进程间通讯的unix域socket等文件，那么剩下的可用于客户端socket连接的文件数就只有大概1024-10=1014个左右。也就是说缺省情况下，基于Linux的通讯程序最多允许同时1014个TCP并发连接。
 对于想支持更高数量的TCP并发连接的通讯处理程序，就必须修改Linux对当前用户的进程同时打开的文件数量的软限制(soft limit)和硬限制(hardlimit)。 其中软限制是指Linux在当前系统能够承受的范围内进一步限制用户同时打开的文件数； 硬限制则是根据系统硬件资源状况(主要是系统内存)计算出来的系统最多可同时打开的文件数量。通常软限制小于或等于硬限制。  &amp;gt;修改 vim /etc/security/limits.conf 添加如下行: username soft nofile 10240 username hard nofile 10240 如果对所有用户修改则将username改为 \* &amp;gt;修改网络内核对tcp的限制  当linux下Nginx达到并发数很高，TCP TIME_WAIT套接字数量会很高，这样服务器很容易被拖死。事实上，我们可以简单的通过修改Linux内核参数，可以减少Nginx服务器 的TIME_WAIT套接字数量，进而提高Nginx服务器并发性能。
 &amp;gt;执行 vim /etc/sysctl.conf &amp;gt;增加以下几行： net.ipv4.tcp_fin_timeout = 30 net.ipv4.tcp_keepalive_time = 1200 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_tw_recycle = 1 net.ipv4.ip_local_port_range = 1024 65000 net.ipv4.tcp_max_syn_backlog = 8192 net.ipv4.tcp_max_tw_buckets = 5000 &amp;gt;执行命令立即生效 /sbin/sysctl -p &amp;gt;说明   net.</description>
    </item>
    
    <item>
      <title>如何基于github pages搭建blog</title>
      <link>http://nber1994.github.io/posts/%E5%A6%82%E4%BD%95%E5%9F%BA%E4%BA%8Egithub-pages%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</link>
      <pubDate>Wed, 06 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/%E5%A6%82%E4%BD%95%E5%9F%BA%E4%BA%8Egithub-pages%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</guid>
      <description>胡乱的记载了如何在github-pages搭建bolg
 什么是github-pages github推出pages服务时是如下所说：
 GitHub Pages allow you to publish web content to a github.com subdomain named after your username. With Pages, publishing web content becomes as easy as pushing to your GitHub repository. If you create a repository named you.github.com, where you is your username, and push content to it, we’ll automatically publish that to http://you.github.com. No FTP, no scp, no rsync, nothing. Just a simple git push and you’re done.</description>
    </item>
    
    <item>
      <title>mysql的explain关键字</title>
      <link>http://nber1994.github.io/posts/mysql%E7%9A%84explain%E5%85%B3%E9%94%AE%E5%AD%97/</link>
      <pubDate>Fri, 27 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/mysql%E7%9A%84explain%E5%85%B3%E9%94%AE%E5%AD%97/</guid>
      <description>胡乱的记录了一些explain关键字的一些用法,以及相关的评判参数
 explain概述 EXPLAIN关键字一般放在SELECT查询语句的前面，用于描述MySQL如何执行查询操作、以及MySQL成功返回结果集需要执行的行数。explain 可以帮助我们分析 select 语句,让我们知道查询效率低下的原因,从而改进我们查询,让查询优化器能够更好的工作。
how to work MySQL 查询优化器有几个目标,但是其中最主要的目标是尽可能地使用索引,并且使用最严格的索引来消除尽可能多的数据行。最终目标是提交 SELECT 语句查找数据行,而不是排除数据行。优化器试图排除数据行的原因在于它排除数据行的速度越快,那么找到与条件匹配的数据行也就越快。如果能够首先进行最严格的测试,查询就可以执行地更快。
explain的各个参数的详解 id    项目 说明     id MySQL Query Optimizer 选定的执行计划中查询的序列号。表示查询中执行 select 子句或操作表的顺序,id 值越大优先级越高,越先被执行。id 相同,执行顺序由上至下    **id**SQL执行的顺利的标识,SQL从大到小的执行.例如:mysql&amp;gt;explainselect*from(select*from(select*fromt3whereid=3952602)a)b;+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+ |id|select_type|table|type|possible_keys|key|key_len|ref|rows|Extra|+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+ |1|PRIMARY|&amp;lt;derived2&amp;gt;|system|NULL|NULL|NULL|NULL|1|||2|DERIVED|&amp;lt;derived3&amp;gt;|system|NULL|NULL|NULL|NULL|1|||3|DERIVED|t3|const|PRIMARY,idx_t3_id|PRIMARY|4||1||+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+ 很显然这条SQL是从里向外的执行,就是从id=3向上执行.select_type select_type-SIMPLE 首先是select__type:将select查询分为简单(simple)和复杂两种类型复杂类型又分为子查询(subquery)和from列表中包含子查询(drived)
   select_type 查询类型 说明     SIMPLE 简单的 select 查询,不使用 union 及子查询    简单SELECT(不使用UNION或子查询等)例如:mysql&amp;gt;explainselect*fromt3whereid=3952602;+----+-------------+-------+-------+-------------------+---------+---------+-------+------+-------+ |id|select_type|table|type|possible_keys|key|key_len|ref|rows|Extra|+----+-------------+-------+-------+-------------------+---------+---------+-------+------+-------+ |1|SIMPLE|t3|const|PRIMARY,idx_t3_id|PRIMARY|4|const|1||+----+-------------+-------+-------+-------------------+---------+---------+-------+------+-------+ select_type-PEIMARY    select_type 查询类型 说明     PRIMARY 最外层的 select 查询    mysql&amp;gt;explainselect*from(select*fromt3whereid=3952602)a;+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+ |id|select_type|table|type|possible_keys|key|key_len|ref|rows|Extra|+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+ |1|PRIMARY|&amp;lt;derived2&amp;gt;|system|NULL|NULL|NULL|NULL|1|||2|DERIVED|t3|const|PRIMARY,idx_t3_id|PRIMARY|4||1||+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+ select_type-UNION    select_type 查询类型 说明     UNION UNION 中的第二个或随后的 select 查询,不依赖于外部查询的结果集    UNION中的第二个或后面的SELECT语句.</description>
    </item>
    
    <item>
      <title>shell常用的文本处理命令</title>
      <link>http://nber1994.github.io/posts/shell%E5%B8%B8%E7%94%A8%E7%9A%84%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Fri, 27 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/shell%E5%B8%B8%E7%94%A8%E7%9A%84%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4/</guid>
      <description>先挖个坑,还未完成
 sed 命令  SED的英文全称是 Stream EDitor，它是一个简单而强大的文本解析转换工具，在1973-1974年期间由贝尔实验室的Lee E. McMahon开发，今天，它已经运行在所有的主流操作系统上了。 McMahon创建了一个通用的行编辑器，最终变成为了SED。SED的很多语法和特性都借鉴了ed编辑器。设计之初，它就已经支持正则表达式，SED可以从文件中接受类似于管道的输入，也可以接受来自标准输入流的输入。  用途  文本替换 选择性的输出文本文件 从文本文件的某处开始编辑 无交互式的对文本文件进行编辑等  工作流  读取： SED从输入流（文件，管道或者标准输入）中读取一行并且存储到它叫做 模式空间（pattern buffer） 的内部缓冲区 执行： 默认情况下，所有的SED命令都在模式空间中顺序的执行，除非指定了行的地址，否则SED命令将会在所有的行上依次执行 显示： 发送修改后的内容到输出流。在发送数据之后，模式空间将会被清空。 在文件所有的内容都被处理完成之前，上述过程将会重复执行  需要注意的地点  模式空间 （pattern buffer） 是一块活跃的缓冲区，在sed编辑器执行命令时它会保存待检查的文本 默认情况下，所有的SED命令都是在模式空间中执行，因此输入文件并不会发生改变 还有另外一个缓冲区叫做 保持空间 （hold buffer），在处理模式空间中的某些行时，可以用保持空间来临时保存一些行。在每一个循环结束的时候，SED将会移除模式空间中的内容，但是该缓冲区中的内容在所有的循环过程中是持久存储的。SED命令无法直接在该缓冲区中执行，因此SED允许数据在 保持空间 和 模式空间之间切换 初始情况下，保持空间 和 模式空间 这两个缓冲区都是空的 如果没有提供输入文件的话，SED将会从标准输入接收请求 如果没有提供地址范围的话，默认情况下SED将会对所有的行进行操作  例子 写入文本
$ vi quote.txt 少一些以功利为目的的追求，对一些不为什么的坚持 --nber1994 $ sed &amp;#39;&amp;#39; quote.txt 少一些以功利为目的的追求，对一些不为什么的坚持 --nber1994  quote.txt是输入的文件名称，两个单引号是要执行的SED命令 首先，SED将会读取quote.txt文件中的一行内容存储到它的模式空间中，然后会在该缓冲区中执行SED命令。在这里，没有提供SED命令，因此对该缓冲区没有要执行的操作，最后它会删除模式空间中的内容并且打印该内容到标准输出，很简单的过程  基础语法 SED可以用下列两种方式调用： sed [-n] [-e] &amp;#39;command(s)&amp;#39; files sed [-n] -f scriptfile files 第一种方式在命令行中使用单引号指定要执行的命令，第二种方式则指定了包含SED命令的脚本文件。当然，这两种方法也可以同时使用，SED提供了很多参数用于控制这种行为。</description>
    </item>
    
    <item>
      <title>php数组合并的坑</title>
      <link>http://nber1994.github.io/posts/php%E6%95%B0%E7%BB%84%E5%90%88%E5%B9%B6%E7%9A%84%E5%9D%91/</link>
      <pubDate>Tue, 24 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/php%E6%95%B0%E7%BB%84%E5%90%88%E5%B9%B6%E7%9A%84%E5%9D%91/</guid>
      <description>胡乱记录了php合并数组时遇到的坑
 数组合并的 += 写法 坑 &amp;lt;?php $a = [ 1 =&amp;gt; &amp;#39;12312&amp;#39;, 2 =&amp;gt; &amp;#39;123&amp;#39;, ]; $b = [ 1 =&amp;gt; &amp;#39;a&amp;#39;, 2 =&amp;gt; &amp;#39;b&amp;#39;, ]; $c = [ 3 =&amp;gt; &amp;#39;a&amp;#39;, 4 =&amp;gt; &amp;#39;b&amp;#39;, ]; echo &amp;#39;两个数组索引相同:&amp;#39; . php_EOL; $a += $b; print_r($a); echo &amp;#39;两个数组索引不同:&amp;#39; . php_EOL; $b += $c; print_r($b); 返回的结果： 两个数组索引相同: Array ( [1] =&amp;gt; 12312 [2] =&amp;gt; 123 ) 两个数组索引不同: Array ( [1] =&amp;gt; a [2] =&amp;gt; b [3] =&amp;gt; a [4] =&amp;gt; b ) array_merge写法 坑 &amp;lt;?</description>
    </item>
    
    <item>
      <title>InnoDB各类语句的加锁方式与应用</title>
      <link>http://nber1994.github.io/posts/innodb%E5%90%84%E7%B1%BB%E8%AF%AD%E5%8F%A5%E5%8A%A0%E9%94%81%E6%96%B9%E5%BC%8F/</link>
      <pubDate>Fri, 20 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/innodb%E5%90%84%E7%B1%BB%E8%AF%AD%E5%8F%A5%E5%8A%A0%E9%94%81%E6%96%B9%E5%BC%8F/</guid>
      <description>胡乱探讨了mysql的InnoDB的简单的加锁机制与使用场景，同时也有加锁等级
 加锁机制 锁定读、UPDATE、DELETE通常在处理SQL语句的过程中在扫描到的每个索引记录上加锁，不关心WHERE条件中可能排除行的非索引条件。比如，A表有两列i和j，i列有索引，j列没索引，当前存在(1,1)，（1,2），（1,3），（1,4），（2,1），（2,2），（2,3），（2,4）……等记录，语句SELECT * FROM A WHERE i=1 AND j=3;会在所有i=1的索引记录上加锁，而不考虑j=3这个条件。如果查询中使用了辅助索引，InnoDB除了给扫描到的辅助索引加锁，还会查找到对应的聚集索引并在其上加锁。若语句用不到合适的索引，则MySQL会扫描整个表，每个表行都会被加锁，会阻塞其他用户的插入操作。
innoDB对不同的语句加不同的锁  SELECT&amp;hellip;FROM读数据库快照，不对记录加锁，除非使用的是SERIALLIZABE隔离级别，此时对索引记录加S Next-key Lock。 SELECT&amp;hellip;FROM&amp;hellip;IN SHARE MODE加S Next-key Lock。 SELECT&amp;hellip;FROM&amp;hellip;FOR UPDATR / UPDATE &amp;hellip; WHERE &amp;hellip; / DELETE FROM &amp;hellip; WHERE &amp;hellip; /加X Next-key Lock。 INSERT在插入的索引记录上加X锁，不会阻止其他事物在插入的记录前的“间隙”插入新的记录。插入记录前，会设置一把 insertion intention gap lock用以表明：不同的事务可以向同一索引“间隙”插入记录而无需相互等待，只要其插入的位置不同。一个事务中insert语句会在插入的行的索引记录上设置一把排它锁。如果有键重复的错误发生，则会在重复的索引记录上设置一把共享锁。在多个session同时插入同一行，且另外的某个session已经持有了该索引记录的排它锁时，共享锁的使用可能导致死锁的出现。  加锁方式 innoDB预设的事务隔离机制为REPEATABLE READ，在SELECT 的读取锁定主要分为两种方式:
 SELECT &amp;hellip; LOCK IN SHARE MODE SELECT &amp;hellip; FOR UPDATE 这两种方式在事务(Transaction) 进行当中SELECT 到同一个数据表时，都必须等待其它事务数据被提交(Commit)后才会执行。而主要的不同在于LOCK IN SHARE MODE 在有一方事务要Update 同一个表单时很容易造成死锁 。 简单的说，如果SELECT 后面若要UPDATE 同一个表单，最好使用SELECT &amp;hellip; UPDATE。  应用场景 假设商品表单products 内有一个存放商品数量的quantity ，在订单成立之前必须先确定quantity 商品数量是否足够(quantity&amp;gt;0) ，然后才把数量更新为1。</description>
    </item>
    
    <item>
      <title>mysql事务并发导致的问题</title>
      <link>http://nber1994.github.io/posts/mysql%E4%BA%8B%E5%8A%A1%E5%B9%B6%E5%8F%91%E5%AF%BC%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98/</link>
      <pubDate>Fri, 20 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/mysql%E4%BA%8B%E5%8A%A1%E5%B9%B6%E5%8F%91%E5%AF%BC%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98/</guid>
      <description>胡乱探讨了事务并发的问题与处理方法
 mysql的事务并发 事务并发问题  第一类丢失更新(lost update)： 在完全未隔离事务的情况下，两个事物更新同一条数据资源，某一事物异常终止，回滚造成第一个完成的更新也同时丢失。 脏读(dirty read)：如果第二个事务查询到第一个事务还未提交的更新数据，形成脏读。 虚读(phantom read)：一个事务执行两次查询，第二次查询比第一次多出或少一些数据，造成两次结果不一致。只是另一个事务在这两次查询中间插入或者删除了数据造成的。 不可重复读(unrepeated read)：一个事务两次读取同一行数据，结果得到不同状态结果，如中间正好另一个事务更新了该数据，两次结果相异，不可信任。 第二类丢失更新(second lost updates)：是不可重复读的特殊情况，如果两个事务都读取同一行，然后两个都进行写操作，并提交，第一个事务所做的改变就会丢失。  事务隔离级别 为了解决数据库事务并发运行时的各种问题数据库系统提供四种事务隔离级别：
 Serializable 串行化 Repeatable Read 可重复读 Read Commited 可读已提交 Read Uncommited 可读未提交  并发控制  数据库系统采用不同的锁类型来实现以上四种隔离级别，具体的实现过程对用户是透明的。用户应该关心的是如何选择合适的隔离级别。 对于多数应用程序，可以优先考虑把数据库系统的隔离级别设为Read Committed，它能够避免脏读，而且具有较好的并发性能。 每个数据库连接都有一个全局变量@@tx__isolation，表示当前的事务隔离级别。 每一种隔离级别对应着一个正整数。 当数据库系统采用Red Committed隔离级别时，会导致不可重复读和第二类丢失更新的并发问题，在可能出现这种问题的场合。可以在应用程序中采用悲观锁或乐观锁来避免这类问题。  常用的解决方法  罗列的技术有些是数据库系统已经实现，有些需要开发者自主完成。
 版本检查 在数据库中保留标识版本的字段，跟随数据同时读写，一次判断数据版本马版本可能是时间戳或者状态字段
UPDATEtableSETstatus=1WHEREid=1ANDstatus=0;版本检查能够作为乐观锁，解决更新丢失问题
锁 共享锁与排它锁 共享锁（Shared locks, S-locks）  基本锁类型之一。加共享锁的对象只允许被当前事务和其他事务读。也称读锁。 能给未加锁和添加了S锁的对象添加S锁。对象可以接受添加多把S锁。  排它锁（Exclusive locks, X-locks）  基本锁类型之一。加排它锁的对象只允许被当前事务读和写。也称独占锁，写锁。 只能给未加锁的对象添加X锁。对象只能接受一把X锁。加X锁的对象不能再加任何锁。  更新锁（Update locks, U-locks）  锁类型之一。引入它是因为多数数据库在实现加X锁时是执行了如下流程：先加S锁，添加成功后尝试更换为X锁。这时如果有两个事务同时加了S锁，尝试换X锁，就会发生死锁。因此增加U锁，U锁代表有更新意向，只允许有一个事务拿到U锁，该事务在发生写后U锁变X锁，未写时看做S锁。  临时锁与持续锁  锁的时效性。指明了加锁生效期是到当前语句结束还是当前事务结束。</description>
    </item>
    
    <item>
      <title>mysql的四种事务隔离级别</title>
      <link>http://nber1994.github.io/posts/mysql%E7%9A%84%E5%9B%9B%E7%A7%8D%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%8A%B6%E6%80%81/</link>
      <pubDate>Fri, 20 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/mysql%E7%9A%84%E5%9B%9B%E7%A7%8D%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%8A%B6%E6%80%81/</guid>
      <description>胡乱探讨了SQL标准定义了4类隔离级别，包括了一些具体规则，用来限定事务内外的哪些改变是可见的，哪些是不可见的。低级别的隔离级一般支持更高的并发处理，并拥有更低的系统开销。
 mysql的事务隔离级别 1.Read Uncommitted（读取未提交内容） 在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。
2.Read Committed（读取提交内容） 这是大多数数据库系统的默认隔离级别（但不是MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别 也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的commit，所以同一select可能返回不同结果。
3.Repeatable Read（可重读） 这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control）机制解决了该问题。
4.Serializable（可串行化） 这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。
产生的问题 这四种隔离级别采取不同的锁类型来实现，若读取的是同一个数据的话，就容易发生问题。例如：
 脏读(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。 不可重复读(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。 幻读(Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。  会产生的问题：
   隔离级别 脏读 不可重复读 幻读     读未提交 V V V   读已提交 X V V   可重复读 X X V   可串行化 X X X    实现的四种隔离级别，会导致如上问题</description>
    </item>
    
    <item>
      <title>mysql锁表for update</title>
      <link>http://nber1994.github.io/posts/mysql%E9%94%81%E8%A1%A8update/</link>
      <pubDate>Fri, 20 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/mysql%E9%94%81%E8%A1%A8update/</guid>
      <description>胡乱探讨了for update的语句应用与使用场景
 锁表 for update select for update 是为了在查询时,避免其他用户以该表进行插入,修改或删除等操作,造成表的不一致性.
一些例子 select*fromtforupdate会等待行锁释放之后，返回查询结果。select*fromtforupdatenowait不等待行锁释放，提示锁冲突，不返回结果select*fromtforupdatewait5等待5秒，若行锁仍未释放，则提示锁冲突，不返回结果select*fromtforupdateskiplocked查询返回查询结果，但忽略有行锁的记录语法 SELECT...FORUPDATE语句的语法如下：SELECT...FORUPDATE[OFcolumn_list][WAITn|NOWAIT][SKIPLOCKED];其中：OF子句用于指定即将更新的列，即锁定行上的特定列。WAIT子句指定等待其他用户释放锁的秒数，防止无限期的等待。优点 使用FOR UPDATE WAIT”子句的优点如下：
 防止无限期地等待被锁定的行； 允许应用程序中对锁的等待时间进行更多的控制。 对于交互式应用程序非常有用，因为这些用户不能等待不确定 若使用了skip locked，则可以越过锁定的行，不会报告由wait n 引发的‘资源忙’异常报告   当我们进行for update的操作时，与普通select存在很大不同。一般select是不需要考虑数据是否被锁定，最多根据多版本一致读的特性读取之前的版本。加入for update之后，Oracle就要求启动一个新事务，尝试对数据进行加锁。如果当前已经被加锁，默认的行为必然是block等待。使用nowait子句的作用就是避免进行等待，当发现请求加锁资源被锁定未释放的时候，直接报错返回。 在日常中，我们对for update的使用还是比较普遍的，特别是在如pl/sql developer中手工修改数据。此时只是觉得方便，而对for update真正的含义缺乏理解。 For update是Oracle提供的手工提高锁级别和范围的特例语句。Oracle的锁机制是目前各类型数据库锁机制中比较优秀的。所以，Oracle认为一般不需要用户和应用直接进行锁的控制和提升。甚至认为死锁这类锁相关问题的出现场景，大都与手工提升锁有关。所以，Oracle并不推荐使用for update作为日常开发使用。而且，在平时开发和运维中，使用了for update却忘记提交，会引起很多锁表故障。
 使用场景 就是那些需要业务层面数据独占时，可以考虑使用for update。场景上，比如火车票订票，在屏幕上显示邮票，而真正进行出票时，需要重新确定一下这个数据没有被其他客户端修改。所以，在这个确认过程中，可以使用for update。这是统一的解决方案方案问题，需要前期有所准备。</description>
    </item>
    
    <item>
      <title>php高级用法</title>
      <link>http://nber1994.github.io/posts/php%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/</link>
      <pubDate>Thu, 12 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/php%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/</guid>
      <description>胡乱探讨了包括autoload，异常处理，多进程，反射使用，trait代码复用，生成器等php语言的高级特性
 1.autoload自动加载  spl_autoload_register() 函数可以注册任意数量的自动加载器，当使用尚未被定义的类（class）和接口（interface）时自动去加载。通过注册自动加载器，脚本引擎在 php 出错失败前有了最后一个机会加载所需的类 尽管 __autoload() 函数也能自动加载类和接口，但更建议使用 spl_autoload_register() 函数。 spl_autoload_register() 提供了一种更加灵活的方式来实现类的自动加载（同一个应用中，可以支持任意数量的加载器，比如第三方库中的）。因此，不再建议使用 __autoload() 函数，在以后的版本中它可能被弃用。 自动加载不可用于 php 的 CLI 交互模式  自动加载简单实例 &amp;lt;?php spl_autoload_register(function ($class_name) { require_once $class_name . &amp;#39;.php&amp;#39;; }); $obj = new MyClass1(); $obj2 = new MyClass2(); ?&amp;gt;自动加载抛出异常 &amp;lt;?php spl_autoload_register(function ($name) { echo &amp;#34;Want to load $name.\n&amp;#34;; throw new Exception(&amp;#34;Unable to load $name.&amp;#34;); }); try { $obj = new NonLoadableClass(); } catch (Exception $e) { echo $e-&amp;gt;getMessage(), &amp;#34;\n&amp;#34;; } ?</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>http://nber1994.github.io/about/</link>
      <pubDate>Thu, 10 Nov 1994 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/about/</guid>
      <description>本站内容全部来自于个人或者网络，可随意转载~ 如发现内容错误，请联系我！     Blog: http://nber1994.github.io   Email: jingherego@gmail.com   Github: http://github.com/nber1994    Books Reading    书名 备注     Go语言学习笔记    Go语言设计与实现 https://draveness.me/golang/    Readed    书名 备注     深入理解计算机系统 https://hansimov.gitbook.io/csapp/ https://ihpm.cn/277/.html   高性能MySQL    MySQL技术内幕:InnoDB存储引擎 http://itmyhome.com/mysql-innodb/   Redis设计与实现 http://redisbook.com/   图解TCP/IP    图解HTTP     To Read    书名 备注     现代操作系统（原书第4版） https://ihpm.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>http://nber1994.github.io/pages/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/pages/about/</guid>
      <description>Me Mail: jingherego@gmail.com Github: nber1994 </description>
    </item>
    
  </channel>
</rss>
