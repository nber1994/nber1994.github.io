--- 
layout: post 
title: 我是谁 
date: 2019-01-08 01:24:24 
categories: else
---
# 我是谁
![](https://cdn.jsdelivr.net/gh/nber1994/fu0k@master/uPic/20190109203333346_122080671.png)
## self
你好，我叫荆天佑，毕业于西安电子科技大学信息工程专业，
虽然大学期间非计算机专业，但是因为个人兴趣自学了编程的相关知识，之后先后在同花顺和贝壳找房参与实习，现在就职于贝壳找房新房研发事业部，从事后端开发工作
刚入职链家网时参与了后端服务从单体应用到服务化的改造工作，对服务化的拆分和治理积累了一些经验
之后负责新房经纪人作业端后端api的迭代开发工作，支持整个新房经纪人线上的作业流程
工作期间也积极参与一些技术项目的开发，设计开发了流量回放系统，这是一个多线程的常驻进程，采用了golang语言
期间对于mysql的sql优化，innodb的索引原理，事务隔离级别，数据持久化等加深了了解
对于redis的内部实现细节有所了解，包括基本数据结构，数据持久化，集群等
同时对tcp/ip和http等网络知识也有一定基础
vim党
个人认为对技术有一定的热爱，并喜欢分享。同时具有一定的学习与沟通能力，也具有一定的抗压能力

## 流量回放平台项目
## what
这个平台可以将API的真实请求自动的回放在AB两套环境上，并得出返回结果的差异报告
## why
这个项目的缘起是因为在业务的稳定期，会有很多的诸如服务的拆分合并，DB的升级，全流程测试等需求，同时现有的开源项目并不能满足实际需求，才会着手做一个这个项目
## how
需要注意的点：
1. 由于是线上的流量回放，所以需要维护一个接口的白名单，并对请求控速
2. 多用户，需要考虑大量任务提交对资源的占用
3. 线上日志来源较多，且多是开放一台有权限的机器，要求灵活对接，部署简单
4. 十余个服务，近四五百个接口，需要设计合理的采样算法，控制数据数量
5. 由于每个diff任务执行的时间较长，所以单纯的http协议不能满足条件
基于以上的这些点，选定使用golang语言来实现，它并发能力较强，适合做常驻进程，可以实现异步，部署简单等
首先整个系统的结构大致是这样的
分为两个模块，一个是master，一个是miner模块，还有一个是webclient模块，
master模块主要负责任务的调度和执行，miner模块按照一定采样算法采集线上日志，webclient请求开始任务并实时将任务结果进行展示
为什么会分为master和miner是因为日志来源比较多，kafka，hive等，可以根据需要来定制相应的miner
各个模块之间通过tcp或者websocket协议交互，其中基于上面的几个问题，做了如下的设计
master模块内部维护一个白名单，并且通过tcp向miner模块下达采集命令
master内部还维护了一个协程池来统一调度协程，即使任务很多时，也能控制资源占用在一个稳定的值，同时在每个工作协程中使用定时器实现控速
但是协程池也会出现一些问题，
一个用户提交的diff请求，会按照接口请求参数的维度产生多个子任务，这些子任务和其他用户的子任务会混杂的运行在协程池中，如何监控这些子任务的执行状态，如何知道这个用户的子任务是否全部执行完毕，这里使用了信号量来做协程间的同步
同时由于每个用户提交的任务执行周期可能比较长，所以采用了websocket来实现master和client的通信，同时master内部的协程池会将所有协程的执行日志传递到消息管理模块中，由它来统一对日志进行分发
最后对于采样算法，我们需要对接口日志在时间上做到近似均匀，所以设计了一个比较简单的采样算法，每个接口采样比如30调请求日志，当新来一条日志时，先计算请求参数的md5值，如果库中现有的md5存在的话，则将该条舍弃，如果不存在的话，随机更新其中的一条

## 服务化改造
## why
这个是我刚参加工作时参加的一个项目，当时我们的后端API还是几个单体应用，存在很多的问题
业务代码互相耦合，同时RD的人数也在增加，多人维护一个项目，代码维护十分麻烦，常常是多个需求改动一个项目，每次都要处理很多的冲突
各种姿势的对外接口调用，并且不收敛，遇到第三方服务迁移时，排查工作量巨大
可用性差等
## how
所以基于以上这些缺点，我们希望对原来的单体应用进行服务化的拆分，
我们使用横向和纵向拆分结合的方式，将一些重要的业务流程进行纵向拆分，在业务上进行解耦，同时对于公共服务，例如调用第三方所有收敛于allinone，同理还有诸如所有H5收敛于一个服务等
同时服务拆分了以后，同时这就会暴露一些服务治理的问题，
1. 各个服务的行为标准如何统一
2. 服务如何监控
3. 如何实现链路追踪
4. 需要一个配置中心
为此，我们基于flcon框架封装了一套自己的framework，通过子仓库的形式关联到源仓库中去，在framework中我们实现了统一的logger，Dao，httprequest，util类等，来规范了每个服务的请求，日志和DB操作的行为
在统一规范的基础上，我们就可以做到监控和链路追踪了，日志的格式同意之后，服务监控就可以接入ELK
对于链路追踪，可以引用requestID和rpc_version来实现
现在的配置中心还未建立，服务注册中心未实现
