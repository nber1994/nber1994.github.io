<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>redis on jingtianyou&#39;s blog</title>
    <link>http://nber1994.github.io/categories/redis/</link>
    <description>Recent content in redis on jingtianyou&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 27 Mar 2020 00:00:00 +0000</lastBuildDate><atom:link href="http://nber1994.github.io/categories/redis/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>scan遇上rehash</title>
      <link>http://nber1994.github.io/posts/scan%E9%81%87%E4%B8%8Arehash/</link>
      <pubDate>Fri, 27 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/scan%E9%81%87%E4%B8%8Arehash/</guid>
      <description>缘起 面试时被问到，redis如果你想要找到所有test_开头的键值时，一般使用什么命令 我当时想也不想，keys命令啊 面试官一脸失望的问我，有没有用过scan命令 我赶紧说用过用过 但是当时心里特别害怕，生怕问这两者的区别，不过好在没有继续往下问，嘿嘿 不过面试后，我隐隐好奇，这两者到底有什么区别，为什么都推荐用scan这个命令？
背景 keys和scan的区别 KEYS parttern：查找所有符合给定模式pattern的key。  KEYS指令一次性返回所有匹配的key。 key的数量过大会使服务卡顿。  SCAN cursor [MATCH pattern] [COUNT count]：查找给定数量内个数的符合给定模式pattern的key。  基于游标的迭代器，需要基于上一次的游标延续之前的迭代过程。 以0作为游标开始一次新的迭代，直到命令返回游标0完成一次遍历。 不保证每次执行都返回给定数量的元素，支持模糊查询。 一次返回的数量不可控，只能是大概率符合COUNT参数。 返回的游标不一定是递增的，可能会获取到重复key，需要在外部程序去重。  keys会导致的问题 首先我们看下redis的网络模型IO多路复用
IO多路复用 简单来说，IO多路复用是一场一对多的群架，相较于多进程与多线程网络模型，io多路复用使用一个进程（一个线程）遍历处理多个socket的请求，准确来说，是交由操作系统来进行socket的遍历操作 总的来说分为三步：
 fd拷贝（用户空间 -&amp;gt; 系统空间） 遍历fd 返回就绪的fd 进程处理就绪fd请求  首先我们知道，redis是一个基于内存的单进程单线程（基于IO多路复用）的kv数据库 在redis2.8之前，能满足这一需求的是keys命令，但是他会导致两个问题：
 没有limit，只能一次性的获取所有符合条件的结果，换句话说如果你的命令输入错误，可能会有成百上千的输出 单进程单线程的redis，一个O(N)的算法，如果执行时间很长，很可能会直接导致redis服务的阻塞  这谁顶得住啊，我如果需要在线上执行一个查询命令，即使命令没有输错，但是如果结果集很大，都有可能导致redis的一个节点阻塞
问题 为什么实现不了limit （时间复杂度） 那么我就会问，为什么不能支持limit操作呢，这样即使我的操作是O(N)的，我可以通过把limit设置的比较小，循环多次取，这样可以减少对服务的影响。但是为什么实现不了呢，这与redis的底层结构有关，我们知道redis的键值对底层是以dict这一内部数据结构组织的，那我们就看看dict这一结构为什么不好实现这一功能
dict结构 dict结构 typedef struct dict { //类型特定函数  dictType *type; //私有数据  void *privData; //哈希表  dictht ht[2]; //rehash索引  //当rehash不进行时，值为-1  int trehashidx; }  可以看到，一个dict存在两个hash表结构（本质是数组）</description>
    </item>
    
    <item>
      <title>redis复制</title>
      <link>http://nber1994.github.io/posts/redis%E5%A4%8D%E5%88%B6/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E5%A4%8D%E5%88%B6/</guid>
      <description> redis通过slaveof命令，放一个服务器去复制另一个服务器，一个为主服务器，另一个为从服务器 主从服务器保存相同的数据称为一致  旧版本的复制实现  redis的复制功能分为同步和命令传播两个操作  同步用于将从服务器更新至与主服务器数据相同的数据库状态 命令传播用于当主服务器上存在修改，导致主从不一致的情况下，将主从服务器的数据库状态重回一致    同步  当从服务器收到salveof命令时，会向主服务器发生sync命令 主服务器收到sync命令行，会执行bgsave命令，生成RDB文件。并将RDB文件发生给从服务器 从服务器接收到RDB文件后，将RDB载入内存，将数据库状态更新至主服务器执行BGSAVE时的状态 主服务器将RDB重写缓冲区中的数据发送给从服务器执行 从服务器执行完重写缓冲区的命令后达到和主服务器相同的数据库状态  命令传播  同步完成后，主服务器的所有修改操作都会发送到从服务器 从服务器执行完修改命令后，重新达到数据库状态的一致性  问题  当出现连接断线时  从服务器重新发送sync命令，主服务器重新生成RDB文件，传送给从服务器载入 RDB文件包含了大量的从服务器已经存在的键值对，这种做法是十分低效的  主服务器生成RDB文件需要消耗CPU和磁盘IO资源 传送RDB文件耗费带宽 从服务器载入RDB文件，服务处于阻塞状态      新版本复制实现  新版采用了psync来代替sync命令 psync分文完整重同步和部分重同步  完整重同步和sync完全相同 部分重同步则会在断线之后，只发送在断线期间的写命令即可实现主从服务器数据库状态的    部分重同步的实现  部分重同步由三个部分构成  主服务器复制偏移量和从服务器复制偏移量 主服务器复制挤压缓冲区 runid    复制偏移量  主服务器每次向从服务器发送N个字节的数据时，复制偏移量加N 从服务器每次接收N个字节，复制偏移量会加N 两个偏移量不一致时，说明主从不一致  复制挤压缓冲区  redis会维护一个FIFO的大小为1MB的复制挤压缓冲区 当从服务器发送psync命令时，检查从复制的偏移量是否在复制挤压缓冲区中  在的话， 发送+COUNTINUE命令，将偏移量之后的数据发送给从服务器 不在的话则进行完整重同步    runid  每个服务器初始化时，都会生成一个唯一的runid 当从服务器首次复制主服务器时，执行完完整重同步之后，会保存主服务器的runid 从服务器重新连接主服务器时，会发送runid，如果runid和主服务器不一致则会导致完整重同步  psync命令实现  当首次接收到slaveof命令时，发送psync ？ -1 命令进行完整重同步 如果复制过主服务器，重新复制时，会发生psync runid offset命令  如果返回 +flulresync runid offset回复，标识需要进行完整重同步 返回+countinue，部分重同步操作，从服务器只需要等待主服务器发送复制积压缓冲区的数据即可 回复-ERR时，不识别psync，需要执行sync命令     复制的实现 步骤1：设置主服务器的地址和端口  slaveof是一个异步命令，在完成masterhost和masterport设置完成之后，就会向客户端恢复ok 实际的工作才刚刚开始  步骤2：建立套接字  建立套接字成功之后，从服务器会为套接字关联一个专门处理复制工作的文件事件处理器 主服务器接收到从服务器的连接之后，会为从服务器创建相应的客户端状态 从服务器作为主服务器的客户端  步骤3：ping  ping的两个作用  判断主从之间是否网络通畅 判断主服务器是否可以正常接收处理命令     步骤4：身份验证 步骤5：发送端口  从服务器会将自己监听的端口发送给主服务器  步骤6：同步  从服务器发送psync命令，根据主服务器的回复决定什么重同步方式  +FULLRESYNC runid offset 进行完整重同步 +CONTINUE 进行部分重同步 -ERR 不支持psync，使用sync同步    步骤7：命令传播  当完成同步之后，主服务器处理写命令之后，会将命令传播给从服务器，从而恢复一致性  心跳检测  在命令传播阶段，从服务器默认会以每秒一次的频率，向主服务器发送命令  REPLCONF ACK offset 从服务器当前读复制偏移量   心跳检测的作用  检测主从服务器之间网络的联通性  主从服务器之间会互发replconf ack，一定时间内没有收到回复则连接有问题   辅助实现min-slaves选项  min-slaves选项  min-slaves-to-write 3 从服务器小于三个时 min-slaves=max-lag 10 延时大于等于10秒时   当满足该条件时，主服务器就会拒绝执行写命令   检测命令丢失  当主服务器接收到replconf ack命令中从服务器的复制偏移量，发现少于主服务器的复制偏移量时，会检查复制挤压缓冲区是否包含该偏移量，有的话会将数据传输给从服务器 检测命令丢失是在没有断线的情况下进行检测，而部分重同步是在断线之后执行的      重点回顾 </description>
    </item>
    
    <item>
      <title>redis客户端</title>
      <link>http://nber1994.github.io/posts/redis%E5%AE%A2%E6%88%B7%E7%AB%AF/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E5%AE%A2%E6%88%B7%E7%AB%AF/</guid>
      <description>客户端  redis服务器中，保存着clients链表  struct redisServer { //一个链表，报错了所有客户端状态  list *clients; }  客户端种类  伪客户端，伪客户端的fd属性为-1。redis有两个地方用到伪客户端，一个是AOF载入时，一个是执行lua脚本  lua客户端在redis服务器期间都会一直存在   普通客户端，fd正整数   flag 标志主从服务器，lua客户端 输入输出缓冲区 命令与命令参数  服务器 serverCron函数   更新服务器时间缓存
 redis需要获取时间的场景，因为每次获取时间都是系统调用，比较费时，所以会将时间缓存    更新LRU时钟
 对象的lru属性，表明最后一次访问的时间    更新服务器的每秒执行命令次数
 每100毫秒抽样计算的方式    更新服务器内存峰值记录
  处理SIGTERM信号
 redis启动时，为SIGTERM信号关联信号处理器，该处理器会在接到信号后，打开服务器的标识位 serverCron函数会定期检查该标识，来决定是否关闭服务器    管理客户端资源
  管理数据库资源
  执行延迟的BGREWRITAOF
 BGSAVE期间，会阻塞GBWRITEAOF    检测持久化操作的允许状态</description>
    </item>
    
    <item>
      <title>redis常见问题</title>
      <link>http://nber1994.github.io/posts/redis%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</guid>
      <description> redis有哪些数据结构 redis分布式锁  scan命令 pipline和batch 数据淘汰策略 一致性hash  </description>
    </item>
    
    <item>
      <title>redis应用场景</title>
      <link>http://nber1994.github.io/posts/redis%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</guid>
      <description>127.0.0.1:6379&amp;gt; select 1 OK 字符串对象 常用命令 # 字符串对象  ## 设置 127.0.0.1:6379[1]&amp;gt; set a a OK ## 获取 127.0.0.1:6379[1]&amp;gt; get a &amp;#34;a&amp;#34; ## 删除 127.0.0.1:6379[1]&amp;gt; del testString (integer) 1 ## 设置并返回原值 127.0.0.1:6379[1]&amp;gt; get b &amp;#34;b&amp;#34; 127.0.0.1:6379[1]&amp;gt; getset b c &amp;#34;b&amp;#34; ## 增加 减少，追加 127.0.0.1:6379[1]&amp;gt; set testInt 1 OK 127.0.0.1:6379[1]&amp;gt; incr testInt (integer) 2 127.0.0.1:6379[1]&amp;gt; decr testInt (integer) 1 127.0.0.1:6379[1]&amp;gt; append a a (integer) 2 127.0.0.1:6379[1]&amp;gt; get a &amp;#34;aa&amp;#34; 127.0.0.1:6379[1]&amp;gt; incrby int 2 (integer) 3 127.</description>
    </item>
    
    <item>
      <title>redis数据结构--简单动态字符串</title>
      <link>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%80%E5%8D%95%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%80%E5%8D%95%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2/</guid>
      <description>redis自己构建了简单的字符串结构，c语言的字符串类型只用于一些字面量展示 SDS还被用于缓冲区，AOF模块的缓冲区就是SDS实现的
struct sdshdr { //记录buf已经使用的长度  int len; //记录buf数组未使用的字节数量  int free; //字节数组，用于保存字符串  char buf[]; } SDS通用遵循着\0结尾的方式，但是不会计入len，这样做的好处是可以使用部分C语言字符串函数
与c字符串的区别 常数复杂度的获取字符串长度  SDS获取字符串长度的时间复杂度是o(1) c字符串需要遍历所有的字符串O(n)  杜绝缓冲区溢出  c字符串由于不知道自己的长度，所以无法校验自身的长度，造成缓冲区溢出  对于SDS来说，每次append操作时，都会检查是否存在足够的空间，如果空间不够的话，则会提前分配空间  减少修改字符串带来的内存重新分配次数 c字符串存在的缺点： - 字符串拼接，如果不通过内存重分配扩展足够的空间，则会产生缓冲区溢出 - 字符串截断，如果不使用内存重新分配来释放字符串不用的空间的话，则会造成内存泄漏  对于c语言来说，偶尔的进行内存重新分配，其实是可以接受的，但是对于redis这种需要频繁修改的场景来说，内存重分配会占用一大部分时间，造成性能的降低
SDS的解决方案：  空间预分配 当需要对sds进行修改，并且需要对sds进行空间扩展时，  如果对SDS进行修改之后，SDS的大小小于1MB的话，则会给SDS分配相同大小的空闲空间， 即len和free相同 如果对SDS修改之后，SDS的大小大于1MB，则会给SDS分配1MB的空闲空间   在对SDS进行扩展操作时，会检查剩余空间是否足够，如果足够的话，则直接插入字符即可 这种空间与分配的策略，会将连续N次增长的情况下内存分配的次数从N次变为最多N次 惰性空间释放  对于SDS的字符串缩短操作，SDS并不会释放空闲出的空间，而是通过维护free，来等待将来的使用    二级制安全  c字符串使用\0表示字符串的结尾，这使得c字符串不能存储图像，音频视频等文件 而对于SDS来说，并不会对\0进行过滤截断等操作，所有的api都是用二进制的方法处理buf中的数据 即存入时是什么样，读取时就是什么样  兼容部分C字符串函数  由于SDS采用c语言的\0结尾的惯例，所以它可以使用一部分c语言字符串的处理函数  </description>
    </item>
    
    <item>
      <title>redis数据结构--链表</title>
      <link>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E9%93%BE%E8%A1%A8/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E9%93%BE%E8%A1%A8/</guid>
      <description> 链表提供了高效的节点重排的能力 顺序访问的能力 发布订阅，慢查询，监视器等都用到了链表  链表结构 typedef struct listNode { //前置节点  struct listNode *prev; //后置节点  struct listNode *next; //节点的值  void *value; } 多个listNode可以通过prev和next链接为双向链表 typdef struct list { //表头节点  listNode *head; //表尾节点  listNode *tail; //链表包含的节点数量  unsigned long len; //节点值复制函数  void *(*dup)(void *ptr); //节点值释放函数  void *(*free)(void *ptr); //节点值对比函数  void *(*match)(void *ptr， void *key); } redis链表实现的特性：  双端：每个节点都存在prev和next指针，获取某个节点前后指针为O(1) 无环：头节点和尾节点的prev和next为null，对链表的访问以null终止 带有表头和表尾指针，自带表头和表尾指针，查找表头和表尾指针为O(1) 待链表长度计数器：获取链表长度为O(1) 多态：链表的值为*void，而且可以通过绑定不同的dup，free，match函数，可以保存不同类型的值  重点回顾 </description>
    </item>
    
    <item>
      <title>redis数据结构-对象</title>
      <link>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%AF%B9%E8%B1%A1/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%AF%B9%E8%B1%A1/</guid>
      <description>redis并没有直接使用底层的数据结构，而是基于这些数据结构创建了一个对象系统 该系统包含了字符串对象，列表，hash表，集合，有序集合五种数据对象 带来的收益：  通过对象系统，可以在执行给出的命令来说，执行之前可以判断是否能执行该命令 同时可以根据不同的使用场景，来选择数据类型的不同的实现方式 通过引用计数，可以实现内存回收机制，当不再占用对象时，会对其回收。同时引用计数还可以实现对象共享，来节省内存 对象还记录了访问时间，以此来计算数据库键的空转时长    对象的类型与编码 当创建一个键值对时，至少会创建两个对象，一个是键的字符串对象，另一个是值的对象
typedef struct redisObject { //类型  unsigned type:4; //编码  unsigned encoding:4; //指向底层实现数据结构的指针  void *ptr; } robj; 类型 对象的type的值： 编码和底层实现 encoding来决定ptr指向哪种底层数据结构 不同的type对应的encoding  对于字符串对象，底层可以有三种实现方式，int，emstr和raw 对于列表对象，底层可以有链表，压缩表实现 对于hash表对象，底层可以有字典，压缩表实现 对于集合对象，底层可以有字典，整数集合实现 对于有序集合对象，底层可以有跳跃表，压缩表实现  不为某种对象绑定特定的数据结构，极大的提高了redis对象的灵活性
字符串对象  字符串对象可以有int，embstr和raw实现 当字符串的值可以用long类型标识时，字符串对象会使用int作为底层实现  ？？ 为什么  当字符串长度小于39字节时，采用embstr的方式来实现 当字符串长度大于39字节时，采用raw的方式来实现 为什么是39呢，因为redis采用的是jemalloc进行动态内存的申请，会申请8，16，32，64字节的内存，但是sds大小为33，而且redisObject为16字节，所以64-16-4-4-1 = 39   采用embstr的优势  embstr和raw的区别是，redisObject和SDS的内存地址是连续的，这样：  初始化时只需要一次内存分配 删除时也仅仅需要一次内存分配 由于是连续的，读取的时候只需要一次寻址，速度较快   embstr并没有实现操作函数，所以对embstr进行操作时，会先转化为raw再进行操作  ？？那为什么不都存为embstr 编码的转化 int编码和embstr编码有时会转化为raw，比如append命令</description>
    </item>
    
    <item>
      <title>redis数据结构-整数集合</title>
      <link>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%B4%E6%95%B0%E9%9B%86%E5%90%88/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%B4%E6%95%B0%E9%9B%86%E5%90%88/</guid>
      <description>一般集合键只保存整数且集合的大小不大时，采用整数集合作为其底层实现
结构 typedef struct intset { //编码方式  uint32_t encoding; //整数集合包含的元素数量  uint32_t length; //保存元素的数组  int8_t contents[]; } intset;  contents作为整数集合的底层实现，每个元素都是contents数组的一个项，各个节点从小到大排列，并且不会重复 contents的项的大小不一定为uint8_t，具体是根据encoding的值来决定  整数集合的升级  当整数集合中的添加的元素大于现有所有元素的类型都要长时，会将contents中元素的类型进行升级 步骤：  首先会根据新加入元素的大小为现有的元素重新分配数组代销 将原来的元素，通过类型转之后，放入新数组的对应位置 将新元素添加入新集合   因为每次新添加元素时，可能会发生升级，会遍历所有的元素进行类型转换，所有时间复杂度为O(n)  升级带来的好处  提高了灵活性，一般数组中我们都会存储相同类型的int值，集合添加元素时，我们不需要关心是插入uint64还是uint32，intset自动适类型的转化 节省了内存空间：当数组中不存在uint64的数时，没有比要把数组初始化为uint64-t类型，这样节约了空间  降级 整数集合不支持降级，整数一旦进行升级之后，不能进行降级
重点回顾 </description>
    </item>
    
    <item>
      <title>redis订阅</title>
      <link>http://nber1994.github.io/posts/redis%E8%AE%A2%E9%98%85/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E8%AE%A2%E9%98%85/</guid>
      <description> redis发布订阅相关的命令  publish，发布 subscribe，订阅 psubscribe，模式订阅    频道订阅和退订 struct redisServer { //保存所有频道的订阅关系  dict *publish_channels; }  频道的订阅信息由publish_channels保存  字典的键为频道名 字典的值为一个客户端的指针的链表     订阅频道 退订频道 模式的订阅和退订  所有模式订阅信息都保存在redsiServer中的pubsub_patterns属性里  struct redisServer { //保存所有模式订阅关系  list *pubsub_patterns; }  pubsub_patterns是一个链表，每个链表的节点结构为  struct pubsubPatterns { //订阅模式的客户端  redisClient *client; //被订阅的模式  robj *patterns; } 发送消息  publish channel message  首先将消息发送给channel的订阅者 表里pubsub_patterns列表，符合条件的客户端发送消息    重点回顾 </description>
    </item>
    
    <item>
      <title>redis问题</title>
      <link>http://nber1994.github.io/posts/redis%E9%97%AE%E9%A2%98/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E9%97%AE%E9%A2%98/</guid>
      <description>redis-问题 BRPOP，BLPOP
https://github.com/antirez/redis/issues/2576 why redis-cluster use 16384 slots? crc16() can have 2^16 -1=65535 different remainders。 原因是：
正常的心跳包携带节点的完整配置，可以用幂等方式替换旧节点以更新旧配置。这意味着它们包含原始形式的节点的插槽配置，它使用带有16k插槽的2k空间，但使用65k插槽将使用高达8k的空间。 同时，由于其他设计权衡，Redis Cluster不太可能扩展到超过1000个主节点。 因此，16k处于正确的范围内，以确保每个主站有足够的插槽，最多1000个主站，但足够小的数字可以轻松地将插槽配置传播为原始位图。请注意，在小型集群中，位图难以压缩，因为当N很小时，位图将设置插槽/ N位，这是设置的大部分位。</description>
    </item>
    
    <item>
      <title>redsi持久化-AOF</title>
      <link>http://nber1994.github.io/posts/redsi%E6%8C%81%E4%B9%85%E5%8C%96-aof/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redsi%E6%8C%81%E4%B9%85%E5%8C%96-aof/</guid>
      <description> redsi持久化-AOF
  除了RDB持久化之后，redis还提供了AOF持久化功能（append only file） AOF持久化使用过保存redis写命令来记录数据库状态的 在AOF文件中，除了指定数据库的select语句之外，其他的都是通过客户端发生的命令  AOF持久化实现  AOF持久化的实现是通过命令追加，文件写入，文件同步三个步骤实现的
 命令追加 struct redisServer { //aof缓冲区  sds aof_buf; }  在redisServer中保存了aof_buf的缓冲区，改缓冲区是由sds实现的 每次redis的写命令之后，都会讲命令追加到这个缓冲区中  文件写入和文件同步  对于redisserver来说，redis的服务进程就是一个事件循环 在每个时间循环的最后，都会调用flushAppendOnlyFile函数并评估是否需要将aof_buf中的内容写入文件 对于flushAppendOnlyFile函数来说，有三种行为：  现代操作系统中，文件写入操作并不会立即写入磁盘，而是会在文件缓存中，以一定频率写入到磁盘 默认是everysec，每次循环结束，会将aof_buf写入文件缓冲区，当上次flush时间已经距现在超过一秒，就将缓冲区同步到磁盘    文件同步的安全性  always 最多会丢失一个时间循环的命令 everysec 会丢失一秒的命令 no 以来操作系统何时将文件同步到磁盘  AOF的载入  当redis服务启动时，服务器会读入AOF文件，并还原数据库状态 步骤  由于命令需要运行在client的上下文，所以redis会创建一个伪客户端来执行命令 从AOF文件读取一行 伪客户端执行读出的命令 知道AOF被读完    AOF文件的重写  随着命令的执行，AOF文件会越来越大，会占用过多的服务器资源，如果不加以控制的话，会对宿主机造成影响 所以需要对AOF文件进行重写，redis服务器创建一个新的AOF文件替代就得AOF文件，两个文件包含的数据库状态完全相同，只是新的AOF文件不包含冗余的命令 实际上，redis并不会根据就得AOF文件进行重写，而是根据现有的数据库状态进行重写  后台重写任务  前台的AOF文件重写任务会带来大量的文件写入操作，所以导致单线程的redis阻塞 所以将AOF重写任务放入后台，bgRewriteAof会新起一个子进程来进行重写  这样在重写期间redis服务可以正常响应请求 而且相对于多线程来说，可以避免锁的使用    AOF重写缓冲区  后台重写任务期间，redis也会产生新的AOF文件，这一部分命令需要一块AOF重写缓冲区进行存储 在后台重写任务期间，redis服务器每条写命令执行完之后，会将命令分别写入AOF缓冲区和AOF重写缓冲区 当AOF重写完成之后，会想redis发送一个信号，父进程会将AOF重写缓冲区中的命令写入新的AOF文件中 之后原子性的将新的AOF文件替换就得AOF文件 整个过程中，只有信号处理函数会打断redis对请求的响应，其他都不会阻碍redis正常的响应  重点回顾 </description>
    </item>
    
    <item>
      <title>redis一致性hash算法</title>
      <link>http://nber1994.github.io/posts/redis%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%AE%97%E6%B3%95/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%AE%97%E6%B3%95/</guid>
      <description>redis-一致性hash算法 http://www.zsythink.net/archives/1182 https://zhuanlan.zhihu.com/p/34985026 一致性hash算法</description>
    </item>
    
    <item>
      <title>redis事件</title>
      <link>http://nber1994.github.io/posts/redis%E4%BA%8B%E4%BB%B6/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E4%BA%8B%E4%BB%B6/</guid>
      <description>redis是一个事件驱动程序
  他需要处理两类事件  文件事件  文件事件就是对套接字的抽象，服务器与客户端之间的通信会产生相应的时间事件，服务器通过监听这些事件完成网络操作   时间事件  时间事件就是一些操作需要在特定的时间完成      文件事件  redis通过reacter模式开发了自己的文件事件处理器  文件事件处理器通过IO多路复用程序来监听多个套接字，并为套接字绑定了多个事件处理程序 当一个套接字准备好accept，read，write，close等操作时，会产生相应的事件，这时事件处理程序就会调用相应的处理程序   使用IO多路复用模型，可以在实现高性能的网络响应模型的同时，保持了系统的简单性  文件事件处理器的构成  文件事件处理器包括套接字，IO多路复用处理程序，文件事件分派器，事件处理程序 文件事件其实是对套接字操作的抽象 IO多路复用程序监听多个套接字，多个文件事件可能并发的出现，IO多路复用程序会将并发事件放在一个队列中，有序的同步的传递给文件事件处理程序 只有处理完一个文件事件之后，IO多路复用才会去处理下一个文件事件 文件事件分派器会将不同的文件事件分派给不同的文件时间处理程序  IO多路复用实现 redis使用的是c标准的select，poll，epoll等标准函数库，同时为这些库实现了相同的API，所以底层是可以互换的
文件事件的类型  文件事件分为AE_READABLE事件和AE_WRITABLE事件
  当套接字可读时，即客户端准备对套接字进行write，或者有新的可应答套接字出现时，套接字产生AE_READABLE事件（write, close，accept） 当套接字变得可写时，客户端对套接字执行read操作，会产生AE_WRITEABLE事件（read） 同时IO多路复用还支持同时监听套接字两种事件，如果两种事件同时出现，优先处理AE_READABLE事件  文件事件处理器  redis为文件事件编写了多个处理器
  为了对客户端进行应答，服务器为客户端关联链接应答处理器 为了接收客户端的命令请求，服务器为客户端关联命令请求处理器 为了向客户端返回命令结果，服务器要为客户端关联命令回复处理器  连接应答处理器 当系统刚初始化完成时，redis会将连接应答处理器和AE_READABLE事件关联起来
命令请求处理器 在客户端连接服务器的整个过程中，服务器会一直讲命令请求服务器和AE_READABLE事件关联起来
命令回复处理器  当服务器有命令结果需要返回给客户端时，会将命令回复处理器和AE_WRITEABLE事件绑定起来 当套接字变为可写时，会产生AE_WRITEABLE事件，命令回复处理器会将结果返回给客户端 之后，会接触命令回复处理器和AE_WRITEABLE事件的绑定  一次完整的客户端和服务器链接过程 时间事件  定时时间和周期型事件 一个时间事件有三个属相组成  id，递增id，新事件比老的事件id大 when，记录了事件的到达时间 timeProc，时间事件处理函数    时间事件的实现  服务器将所有的时间事件都放在一个无需链表里，每当时间事件执行器运行时，就会便利这个链表   事件事件应用实例：serverCron函数  redis中的事件事件任务都有serverCron函数负责执行，他的任务包括  更新服务器的各类统计信息，比如时间，内存占用，数据库占用等 清理数据库过期的键值对 关闭和清理链接失效的客户端 尝试进行RDB和AOF持久化操作 如果是主服务器则对从服务器定期同步 集群模式则对集群定期进行同步和连接测试    主循环处理文件事件和时间事件的伪代码  获取最接近的时间事件的还有多久到达 将该秒数传入IO监听函数，两个条件满足一个会向下执行  时间事件到达 IO多路复用监听到文件事件产生   然后先执行文件事件 后执行时间事件   因为文件事件在时间事件之前执行，所以时间事件往往会比设定事件稍晚一点执行</description>
    </item>
    
    <item>
      <title>redis事务</title>
      <link>http://nber1994.github.io/posts/redis%E4%BA%8B%E5%8A%A1/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E4%BA%8B%E5%8A%A1/</guid>
      <description> redis通过multi，exec，watch等命令实现事务功能 事务提供了一种将多个命令打包，一次性顺序执行的多个命令的机制  事务实现  事务开始 命令入队 事务执行  事务开始  multi命令可以将执行该命令的客户端从非事务状态切换为事务状态  将客户端的flag属性变为redis_multi    命令入队  当处于非事务状态下，客户端发送的命令会立即执行 当处于事务状态下，  客户端发送的exec，discard，watch，multi命令会立即执行 除了以上命令，服务器并不执行，而是放入一个事务队列中，返回quneued    事务队列  每个客户端都有一个事务状态，  typedef struct redisClient { //事务状态  multiState mstate; } redisClient;  每个事务状态包含一个事务队列，一个已入队命令计数器  typedef struct multiState { //事务队列，FIFO顺序  multiCmd *commands; //已入队命令计数  int count; } 事务对列是一个multiCmd的数组
typedef struct multiCmd { //参数  robj **argv; //参数数量  int argc; //命令指针  struct redisCommand *cmd; } 执行事务  当服务器收到客户端传来的exec命令时，会立即执行事务队列中的命令 并将执行结果返回给客户端  watch命令  watch是一个乐观锁，可以在exec执行之前，监视任意数量的数据库键 当exec执行时，如果监视的键被修改了，则事务就会拒绝提交   watch命令监听数据库键 typedef struct redisDb { //正在被watch命令监听的键  dict *watched_keys; } RedisDB;  watched_keys的键为键名， 而值则是一个链表，每个链表代表一个监听该键的客户端  监听的触发  对数据库的修改命令，set lpush sadd等，会检查watched_keys字典 如果有客户端正在监听键时，会遍历watched_keys[key]对应的client的REDIS_DIRTY_CAS标识打开，标识事务安全性已被破坏 当事务exec时，会根据REDIS_DIRTY_CAS是否打开，来决定事务是否能提交  事务的ACID  原子性 ok  redis的事务不支持回滚，有一条命令出错后，其他的命令继续执行   一致性  事务提交之后，不包含非法或者无效的错误数据 redis通过错误检查和简单的设计来避免一致性  入队错误：命令入队时，命令不存在或者不正确，redis拒绝执行事务 执行错误：执行中发生了错误，服务器也不会终端事务，其他的命令并不会受错误命令的影响     隔离性 ok 单线程 持久性  无持久化：不具有持久性 RDB持久化：不具有耐久性 AOF持久化，appendsync为always时具有    重点回顾 </description>
    </item>
    
    <item>
      <title>redis持久化-RDB</title>
      <link>http://nber1994.github.io/posts/redis%E6%8C%81%E4%B9%85%E5%8C%96-rdb/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%8C%81%E4%B9%85%E5%8C%96-rdb/</guid>
      <description> redis持久化-RDB
  二进制文件 一个服务器的所有非空数据库的所有的键值对成为数据库状态 redis是一个内存型数据库，为了解决持久化问题，引入了RDB持久化和AOF持久化  RDB文件的创建与载入  创建  RDB文件可以由save和bgsave命令生成 save会阻塞服务器进程，知道save命令结束，否则不会接受任何请求 gbsave命令则不同，他会派生一个子进程来进行任务，并不会阻碍redis的正常请求   载入  RDB文件的载入是在服务器启动时，检测到存在RDB文件的话就会自动载入RDB文件   值得一提的是，由于AOF文件更新的频率比RDB更快，所以redis会优先选择AOF文件来还原数据库状态 当没有开启AOF持久化功能时，才会采用RDB文件来恢复  save和bgsave的互斥性  在bgsave期间，bgsave和save服务器会拒绝，这是因为为了防止竞争产生 bgsave和bgrewariteaof也不能同时执行，虽然没有什么冲突，但是为了性能考虑  载入状态下服务器的状态  阻塞  对自动保存的设置  redis允许用户对bgsave的频率进行设置 其中设置频率会设置两个指标  dirty计数器表示了上次save之后修改的键的数目 lastsave 上次bgsave的时间   serverCron会定期的检查是否满足save的条件，从而进行保存  RDB文件的结构  REDIS是最开头的部分，保存着REDIS来标识是否是RDB文件 db_version标识RDB版本 databases包含着0或多个数据库的键值对数据 EOF标识着RDB文件结束 check_sum是根据其他部分计算出来的，用来校验RDB文件是否有损坏  database部分  每个databases包含着三个部分  selectdb 标志着是一个database段的开始 db_number标识出是哪个数据库 key_valud_pairs 存储着键值对    key_value_pairs部分  type标识是哪种对象和实现方式 EXPIRETIME 标志位，标识接下来读入的是一个到期时间 ms 到期的时间戳  重点回顾 </description>
    </item>
    
    <item>
      <title>redis数据库</title>
      <link>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E5%BA%93/</guid>
      <description>struct redisServer { //一个数组，保存所有数据库  redisDb *db; //数据库的数量  int dbnum; }  在数据库初始化时，会根据服务器状态属性dbnum来决定初始化多少的数据库 默认情况下时16个  切换数据库  在服务器上，每个客户端都会有一个对应的数据结构，记录客户端的状态  typedef struct redisClient { //记录当前的数据库  redisDb *db; }  默认情况下会使用0号数据库 select 命令的实现就是通过切换redisDb指针的值来切换数据库  数据库键空间  redis是一个键值对数据库，每个数据库都有对应的redisDb结构 所有的键值对都保存在redisDb中的dict中  typedef struct redisDb { //数据库键空间，存储所有的键值对  dict *dict; //过期字典  dist *expire; } redisDb;  键空间和用户所见的键值对是直接对应的 其对键值对的操作都对应字典对于键值对的操作 其他对于数据库的操作  比如flushDB就是直接删除键空间 randomkey就是在键空间中随机返回一个键 dbsize直接返回键空间的大小    读写键空间时的维护操作  读写一个键之后，会更新键空间中的hit和miss属性 更新该键对象的lru时间 判断是否过期，过期则删除改建 如果使用了watch命令监视了该键，则会将该键标记为dirty 修改一个键之后，会对dirty计数器加一，从而引发持久化和复制操作 如果开启了消息通知功能，则会发送相关的消息  键值的过期时间  设置过期命令  expire 设置生存时间为多少秒 pexpire 设置生存时间为多少毫秒 expireat 将过期时间设置为xxxs pexpireat 将过期时间设置为xxxms   其实四个命令都是以pexpireat实现的  保存过期时间  保存过期时间都是通过expire子弹实现的  键是一个指向了dict中对象的地址 键值为一个时间戳     移除过期时间  persist 命令就是讲某个键值在expire字典中删除即可  过期键的删除策略  常见的国期间删除策略  定时删除  在一定时间间隔后，将键空间的过期键全部删除 优点：对内存比较友好，定期删除节省内存空间 缺点：对cpu不友好，当有大量的过期键需要删除时，会造成服务的中断   惰性删除  每次读写某个键之前判断是否已经过期 优点：对cpu较友好，不会占用太多的cpu资源 缺点：对于内存不友好，如果大量的过期键没有访问，则会占用大量的内存资源   定期删除  每隔一段时间，会对数据库键进行检查，删除一部分的过期键 定时并以一定量删除的方式，减少了cpu的占用 同时也解决了过期键带来的内存浪费      redis的过期删除策略  配合使用定期删除和惰性删除两种策略 定期删除策略  由serverCron函数执行，在规定的时间内，分多次便利所有数据库，随机的删除过期键 全局便利current_db记录了当前的进度，到达16之后会归0    AOF和RDB以及复制功能对过期键的处理 RDB  save和bgsave生存RDB文件时，会进行检查，不会讲过期键存入RDB文件中 载入RDB文件时  主服务器模式下，会对键值进行检查，舍弃过期键 从服务器模式下，不会检查，全部载入。但是一般复制时会将数据库全部删除，所以一般不会造成影响    AOF  在AOF持久化时，不会对过期键值过滤，因为当惰性删除和定期删除之后，会写入一条del AOF重写时，会对过期键进行过滤  复制  主服务器删除一个键之后，会显示的向所有从服务器发生del命令 从服务器在执行客户端命令时，并不会判断键是否过期，而是返回结果 只有得到主服务器的del命令，才会删除 这种方式，可以保持主从的一致性  重点回顾 </description>
    </item>
    
    <item>
      <title>redis数据结构-压缩列表</title>
      <link>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8/</guid>
      <description>压缩列表是列表建和哈希键的底层实现之一 压缩表是一系列有特殊编码组成的顺序型的数据结，可以保存字节数组和整数值  压缩表结构  zlbytes：记录整个压缩表的字节长度 zltail：记录尾节点的距离列表起始地址有多少字节 zllen：记录存在节点的数目 entryX：压缩表包含的节点，长度由保存内容决定 zlend：特殊值，标明压缩表的结尾  压缩表节点结构  prev_entry_length 前一个节点的长度，prev_entry_length可以是1字节或者5字节  当前一个节点的长度小于254字节时，prev_entry_length为一个字节 当前一个节点的长度大于254字节时，prev_entry_length为5字节 遍历：当想要遍历一个压缩表时，会根据zltail首先跳转到最后的节点，然后根据prev_entry_length节点向前遍历   encoding 编码  encoding记录着节点content的长度和数据类型   content 内容  content的值的类型由encoding来决定    连锁更新  如果存在这一一种情况的数组，每个节点的长度都在250到254之间时，当向前一个节点的插入一个大于254长度的节点，后一个节点会更新期prev_entry_length的长度，使该节点的长度也大于了254，这样将导致一系列的内存重分配操作 除了插入操作，删除操作也会导致连续更新的操作 在连续更新的情况下，最坏为O（N^2） 连续更新操作大量出现的概率比较小，所以压缩表的平均还是为O(N)  重点回顾 ？？压缩表优点 内存中以连续快存放，载入速度更快</description>
    </item>
    
    <item>
      <title>redis数据结构-字典</title>
      <link>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%AD%97%E5%85%B8/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%AD%97%E5%85%B8/</guid>
      <description>字典是一个用于保存键值对的数据结构 字典的键为独一无二的 redis的数据库就是使用字典实现的 hash键的底层实现  hash表结构 哈希表结构 typedef struct dictht { //哈希表数组  dictEntry **table; //哈希表大小  unsigned long size； //哈希表大小掩码，用于计算索引值，总之等于size-1  unsigned long sizemask; //该哈希表已有节点的数量  unsigned long used; } table是一个数组，数组中的每个元素都是指向dictEntry结构的指针，每个dictEntry保存这一个键值对 hash节点 typedef struct dictEntry { //键  void *key; //值  union { void *val; uint64_tu64; int64_ts64; }v; //指向下一个hash节点，形成链表  struct dictEntry *next; } dictEntry; 其中next可以连接相同的节点，可以通过这个指针将相同哈希值的多个键值对节点连接起来，来解决哈希冲突的问题 字典结构 字典由如下结构表示：
typedef struct dict { //类型特定函数  dictType *type; //私有数据  void *privData; //哈希表  dictht ht[2]; //rehash索引  //当rehash不进行时，值为-1  int trehashidx; }  ht属性是一个包含两个项的数组，一般情况下，使用ht[0],ht[1]只用来进行rehash操作 trehashidx记录了rehash的进度   hash算法 hash算法根据键值，计算出哈希值，在结合sizemask的值，计算出索引值 向hash表添加一个键值对时，先根据hash算法计算出键值对的哈希值和索引值 再根据索引值确定新的哈希表节点放到指定索引上</description>
    </item>
    
    <item>
      <title>redis数据结构-跳跃表</title>
      <link>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E8%B7%B3%E8%B7%83%E8%A1%A8/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E8%B7%B3%E8%B7%83%E8%A1%A8/</guid>
      <description> 跳跃表通过每个节点位置多个指向其他节点的指针来实现快速访问 跳跃表可以实现最好O(logN)，最坏O(N)的节点查找，同时可以顺序操作批量处理 redis的应用，一个是在有序集合中使用了跳跃表，同时在集群节点中作为内部数据结构使用  结构 跳跃表由zskiplistNode和zskiplist结构组成 对于跳跃表结构: typedef strut zskiplist { //表头节点和表尾节点  struct zskiplistNode *header, *tail;; //表节点的数量  unsigned long length； //表中层数最大值  int level } zskilplist;  header: 指向表头节点的指针 level：跳跃表中level最大的level值，不包括表头结点 length：跳跃表中包含节点的个数，不包含表头  对于跳跃表节点结构： typedef struct zskiplistNode { //层  struct zskiplistLevel { //前进指针  struct zskiplistNode *forward; //跨度  unsigned int span; } level[]; //后退指针  struct zskiplistNode *backward; //分值  double score; //成员对象  robj *obj; } zskiplistNode;  level：每个节点在初始化时，会分配给其一个1-32之间的level，每个level包含一个前进指针和跨度，前进指针用于访问队尾其他的节点，而跨度记录了本节点到前进指针所指节点的距离；一般来说层数越多，访问其他节点的速度越快  对于跨度，其实是用来计算某个节点在列表中的排位的   bw：后退指针，后退指针用于访问该节点的前一个节点。 score：分值，保存各个节点的分值。跳跃表中的节点是按照分值从小到大排列的。score是一个double型 obj：保存成员对象， 成员对象指向一个字符串对象，其保存一个SDS 注意：头节点同样存在后退指针，分值和成员对象，但是一般不使用 注意：当节点的score值相同时，但是成员变量不能重复，会按照成员对象在字典中的大小进行排序  重点回顾 </description>
    </item>
    
    <item>
      <title>Redis概述</title>
      <link>http://nber1994.github.io/posts/redis%E6%A6%82%E8%BF%B0/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E6%A6%82%E8%BF%B0/</guid>
      <description>redis是一个key-value形式的单线程的内存型数据库
数据结构与对象 redis每个键值对都是由对象组成的
 数据库键总是一个字符串对象 数据库的键值可以是字符串对象，列表对象，哈希对象，集合对象，有序集合对象其中的一种  单机数据库的实现  服务器保存键值对的原理，对过期的方法，自动删除过期键值的方法 持久化 RDB持久化和AOF持久化， 生成方法和恢复方式 bgsave和bgwriteaof实现原理 事件  文件事件 时间事件   管理客户端  妈的，什么也没有看，写这个真的蛋疼，待续吧</description>
    </item>
    
    <item>
      <title>redis相关资源</title>
      <link>http://nber1994.github.io/posts/redis%E7%9B%B8%E5%85%B3%E8%B5%84%E6%BA%90/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E7%9B%B8%E5%85%B3%E8%B5%84%E6%BA%90/</guid>
      <description>redis相关资源 掘金-常见问题 https://zhuanlan.zhihu.com/p/32540678 https://www.jianshu.com/p/85d55f2ffd0a</description>
    </item>
    
    <item>
      <title>redis集群</title>
      <link>http://nber1994.github.io/posts/redis%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nber1994.github.io/posts/redis%E9%9B%86%E7%BE%A4/</guid>
      <description>redis集群通过分片来进行数据共享，并且提供复制和故障转移的功能  节点  一个集群是由多个节点组成 CLUSTER MEET ip port 命令用于将节点加入自己的集群中 集群中每个节点会维护的数据结构  clusterNode 保存了节点的状态，比如创建时间，名字，配置纪元，节点ip port等 clusterLink clusterState    clusterNode struct clusterNode { //创建时间  mstimer_t ctime; //节点的名字  char name[REDIS_CLUSTER_NAMELEN]; //节点标识  //主从节点，上线下线  int flags; //当前配置纪元，用于故障转移  uint64_t configEpoch; //节点IP  char ip[REDIS_IP_STR_LEN]; //节点端口  int port; //保存连接节点所需的信息  clusterLink *link; //保存节点的槽指派信息  unsigned char slots[16384/8]; //槽指派的个数  int numslots； //复制的节点  struct clusterNode *slaveof; } clusterLink  clusterLink保存了连接节点所需的信息  typedef struct clusterLink { //连接创建时间  mstime_t time; //TCP套接字描述符  int fd; //输出缓冲区,保存待发给其他节点的消息  sds sndbuf; //输入缓冲区，保存着从其他节点接收到的消息  sds revbuf; //与这个连接相关联的节点，没有就为null  struct clusterNode *node; } clusterLink;  redisClinet和clusterLink结构很像，但是redsiClient对应的是客户端的链接信息，而clusterLink对应的是和其他节点的连接信息  clusterState  该结构保存了在当前节点的视角下，整个集群的状态  typedef struct clusterState { //指向当前节点的指针  clusterNode *self; //集群当前的配置纪元，用于实现故障转移  uint64_t currentEpoch; //集群当前状态：上线还是下线  int state; //集群中至少处理一个槽的节点的数量  int size; //集群单节点名单（包括自己）  dict *nodes; //记录了集群中槽的指派情况  clusterNode *slot[16384]; //正在导入的槽的节点  clusterNode importing_slots_from[16384]; } clusterState; 集群 cluster meet实现  当cluster meet ip port指向B  节点A会为B在自己的clusterState.</description>
    </item>
    
  </channel>
</rss>
